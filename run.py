#!/usr/bin/env python3
"""
AI íŠœí„° FastAPI ë°±ì—”ë“œ ì• í”Œë¦¬ì¼€ì´ì…˜ (v4.0 - ì–¸ì–´êµìœ¡ AI ìˆ˜ì¤€)

ì™„ì „í•œ ì‹¤ì‹œê°„ AI íŠœí„° ì‹œìŠ¤í…œ ë°±ì—”ë“œì…ë‹ˆë‹¤.
- ğŸ”’ ì˜¤ë””ì˜¤ ì¤‘ì²© ì™„ì „ í•´ê²° (ê¸°ì¡´ v3.3 ì™„ì „ ìœ ì§€)
- ğŸ­ ì–¸ì–´êµìœ¡ AI ìˆ˜ì¤€ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” (NEW!)
- ğŸ”Š WaveNet + SSML ê¸°ë°˜ ê³ í’ˆì§ˆ ìŒì„± (NEW!)
- ğŸ§  ê³ ê¸‰ ê°ì • ë¶„ì„ ë° í•™ìŠµì ìƒíƒœ ì¶”ì  (NEW!)
- ğŸ’° ìŠ¤ë§ˆíŠ¸í•œ ë¹„ìš© ì ˆì•½ (ê¸°ì¡´ ìœ ì§€)
- ğŸ›¡ï¸ ê¸°ì¡´ ê¸°ëŠ¥ ì™„ì „ í˜¸í™˜ ë³´ì¥ (ì•ˆì „ì„± ìµœìš°ì„ )
"""

import asyncio
import base64
import json
import os
import tempfile
import uuid
import time
import re
from datetime import datetime
from typing import Dict, Any, Optional, List
import logging

import uvicorn
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from openai import AsyncOpenAI
from google.cloud import texttospeech
from google.cloud import speech
import httpx

# ğŸ¯ ìŠ¤ë§ˆíŠ¸í•œ ë¡œê¹… (ê¸°ì¡´ ì™„ì „ ìœ ì§€)
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
logging.basicConfig(level=getattr(logging, LOG_LEVEL))
logger = logging.getLogger(__name__)

if LOG_LEVEL == "WARNING":
    logging.getLogger("google").setLevel(logging.ERROR)
    logging.getLogger("urllib3").setLevel(logging.ERROR)

# FastAPI ì•± ì´ˆê¸°í™” (ê¸°ì¡´ + v4.0 ì •ë³´ ì—…ë°ì´íŠ¸)
app = FastAPI(
    title="AI Tutor Realtime System",
    description="ì‹¤ì‹œê°„ AI íŠœí„° ì‹œìŠ¤í…œ - v4.0 ì–¸ì–´êµìœ¡ AI ìˆ˜ì¤€ (WaveNet + SSML + ê³ ê¸‰ ê°ì • ë¶„ì„)",
    version="4.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS ì„¤ì • (ê¸°ì¡´ ì™„ì „ ìœ ì§€)
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://*.streamlit.app",
        "https://*.streamlit.io", 
        "http://localhost:8501",
        "http://localhost:3000",
        "http://localhost:8080",
        "*"
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

# í™˜ê²½ë³€ìˆ˜ ì„¤ì • (ê¸°ì¡´ ì™„ì „ ìœ ì§€)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    logger.error("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ê¸°ì¡´ ì™„ì „ ìœ ì§€)
openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)

try:
    tts_client = texttospeech.TextToSpeechClient()
    logger.info("Google TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ (v4.0 WaveNet ì§€ì›)")
except Exception as e:
    logger.error(f"Google TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    tts_client = None

try:
    speech_client = speech.SpeechClient()
    logger.info("Google STT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
except Exception as e:
    logger.error(f"Google STT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    speech_client = None

# ì „ì—­ ë³€ìˆ˜ (ê¸°ì¡´ ì™„ì „ ìœ ì§€ + v4.0 ì¶”ê°€)
active_connections: Dict[str, WebSocket] = {}
tutor_configs: Dict[str, Dict[str, Any]] = {}
response_in_progress: set = set()  
conversation_history: Dict[str, list] = {}

# ğŸ”’ ì¤‘ì²© ì™„ì „ ë°©ì§€ë¥¼ ìœ„í•œ ê°•ë ¥í•œ ì§ë ¬í™” ì‹œìŠ¤í…œ (ê¸°ì¡´ ì™„ì „ ìœ ì§€)
client_locks: Dict[str, asyncio.Lock] = {}
client_tts_tasks: Dict[str, Optional[asyncio.Task]] = {}
response_queues: Dict[str, asyncio.Queue] = {}

# ğŸ§  NEW v4.0: ê³ ê¸‰ í•™ìŠµì ìƒíƒœ ì¶”ì 
learner_states: Dict[str, Dict[str, Any]] = {}
current_strategies: Dict[str, str] = {}
emotional_histories: Dict[str, List[Dict]] = {}

# ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸ë“¤ (ê¸°ì¡´ + v4.0 ì—…ë°ì´íŠ¸)
@app.get("/")
async def root():
    """ë©”ì¸ í˜ì´ì§€ - ì‹œìŠ¤í…œ ì •ë³´"""
    return {
        "message": "ğŸ“ AI Tutor Realtime System",
        "version": "4.0.0",
        "status": "running",
        "core_improvements": [
            "ğŸ”’ ì˜¤ë””ì˜¤ ì¤‘ì²© ì™„ì „ í•´ê²° (v3.3 ê¸°ëŠ¥ ì™„ì „ ìœ ì§€)",
            "ğŸ”Š WaveNet + SSML ê¸°ë°˜ ê³ í’ˆì§ˆ ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± (NEW!)",
            "ğŸ§  ê³ ê¸‰ ê°ì • ë¶„ì„ ë° í•™ìŠµì ìƒíƒœ ì¶”ì  (NEW!)",
            "ğŸ­ ì–¸ì–´êµìœ¡ AI ìˆ˜ì¤€ ëŒ€í™” ì „ëµ (NEW!)",
            "ğŸ’° ìŠ¤ë§ˆíŠ¸í•œ ë¹„ìš© ì ˆì•½ (ê¸°ì¡´ ìœ ì§€)",
            "ğŸ›¡ï¸ ê¸°ì¡´ ê¸°ëŠ¥ ì™„ì „ í˜¸í™˜ ë³´ì¥ (ì•ˆì „ì„± ìµœìš°ì„ )"
        ],
        "language_ai_features": {
            "natural_voice": "WaveNet ê¸°ë°˜ ê°ì • í‘œí˜„ + SSML ì–µì–‘ ì¡°ì ˆ",
            "emotional_intelligence": "ì‹¤ì‹œê°„ ê°ì • ìƒíƒœ ê°ì§€ + ì ì‘í˜• ëŒ€ì‘",
            "advanced_conversation": "í•™ìŠµ ë‹¨ê³„ë³„ ë§ì¶¤í˜• ëŒ€í™” ì „ëµ",
            "learner_analysis": "ì¢…í•©ì  í•™ìŠµì ìƒíƒœ ë¶„ì„ + ê°œì¸í™”",
            "seamless_interaction": "ëŠê¹€ ì—†ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„"
        },
        "compatibility": {
            "v3_3_features": "100% ì™„ì „ ìœ ì§€ (ì¤‘ì²© ë°©ì§€, ì¦‰ì‹œ ì¤‘ë‹¨, ì‹¤ì‹œê°„ í”¼ë“œë°±)",
            "websocket_messages": "ëª¨ë“  ê¸°ì¡´ ë©”ì‹œì§€ íƒ€ì… ì™„ì „ ì§€ì›",
            "ui_compatibility": "ê¸°ì¡´ í”„ë¡ íŠ¸ì—”ë“œ ì™„ì „ í˜¸í™˜"
        },
        "endpoints": {
            "websocket": "/ws/tutor/{client_id}",
            "health": "/health",
            "info": "/info",
            "docs": "/docs"
        },
        "timestamp": datetime.now().isoformat()
    }

@app.get("/health")
async def health_check():
    """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ (ê¸°ì¡´ + v4.0 ì •ë³´ ì¶”ê°€)"""
    try:
        openai_status = "âœ… ì—°ê²°ë¨" if OPENAI_API_KEY else "âŒ API í‚¤ ì—†ìŒ"
        
        tts_status = "âŒ ë¹„í™œì„±í™”"
        if tts_client:
            try:
                voices = tts_client.list_voices()
                wavenet_voices = [v for v in voices.voices if 'wavenet' in v.name.lower()]
                tts_status = f"âœ… í™œì„±í™” (WaveNet: {len(wavenet_voices)}ê°œ, ì „ì²´: {len(voices.voices)}ê°œ)"
            except Exception as e:
                tts_status = f"âš ï¸ ì˜¤ë¥˜: {str(e)[:50]}"
        
        stt_status = "âœ… í™œì„±í™”" if speech_client else "âŒ ë¹„í™œì„±í™”"
        
        return {
            "status": "healthy",
            "version": "4.0.0 - ì–¸ì–´êµìœ¡ AI ìˆ˜ì¤€",
            "timestamp": datetime.now().isoformat(),
            "active_connections": len(active_connections),
            "active_tutors": len(tutor_configs),
            "active_responses": len(response_in_progress),
            "conversation_sessions": len(conversation_history),
            "client_locks": len(client_locks),
            "active_tts_tasks": len([t for t in client_tts_tasks.values() if t and not t.done()]),
            "learner_states": len(learner_states),  # NEW v4.0
            "emotional_histories": len(emotional_histories),  # NEW v4.0
            "services": {
                "openai_gpt": openai_status,
                "google_tts_wavenet": tts_status,
                "google_stt": stt_status
            },
            "v4_0_features": {
                "wavenet_tts": "âœ… ê³ í’ˆì§ˆ ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±",
                "ssml_emotions": "âœ… ê°ì • í‘œí˜„ ë° ì–µì–‘ ì¡°ì ˆ",
                "emotional_analysis": "âœ… ì‹¤ì‹œê°„ ê°ì • ìƒíƒœ ê°ì§€",
                "learner_tracking": "âœ… ì¢…í•©ì  í•™ìŠµì ìƒíƒœ ì¶”ì ",
                "advanced_strategies": "âœ… ì–¸ì–´êµìœ¡ AI ìˆ˜ì¤€ ëŒ€í™” ì „ëµ"
            },
            "compatibility": {
                "v3_3_overlap_prevention": "âœ… ì™„ì „ ìœ ì§€",
                "real_time_feedback": "âœ… ì™„ì „ ìœ ì§€",
                "instant_interrupt": "âœ… ì™„ì „ ìœ ì§€",
                "streaming_quality": "âœ… ì™„ì „ ìœ ì§€ + í–¥ìƒ"
            }
        }
    except Exception as e:
        logger.error(f"Health check ì˜¤ë¥˜: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "status": "unhealthy", 
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
        )

@app.get("/info")
async def system_info():
    """ìƒì„¸ ì‹œìŠ¤í…œ ì •ë³´ (ê¸°ì¡´ + v4.0 ì—…ë°ì´íŠ¸)"""
    return {
        "system": "AI Tutor Realtime System",
        "version": "4.0.0",
        "subtitle": "ì–¸ì–´êµìœ¡ AI ìˆ˜ì¤€ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”",
        "architecture": "ê³ ì„±ëŠ¥ ì‹¤ì‹œê°„ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ + ê³ ê¸‰ ê°ì • ì§€ëŠ¥",
        "deployment": "Google Cloud Run",
        "core_improvements": {
            "v3_3_features_maintained": "ì˜¤ë””ì˜¤ ì¤‘ì²© ì™„ì „ ë°©ì§€, ì¦‰ì‹œ ì¤‘ë‹¨, ì‹¤ì‹œê°„ í”¼ë“œë°± 100% ìœ ì§€",
            "natural_voice_upgrade": "Google WaveNet + SSMLë¡œ ì–¸ì–´êµìœ¡ AI ìˆ˜ì¤€ ìŒì„± í’ˆì§ˆ",
            "emotional_intelligence": "ì‹¤ì‹œê°„ ê°ì • ìƒíƒœ ê°ì§€ ë° ì ì‘í˜• ëŒ€ì‘ ì „ëµ",
            "advanced_conversation": "í•™ìŠµ ë‹¨ê³„, ì´í•´ë„, ê°ì • ìƒíƒœ ê¸°ë°˜ ë§ì¶¤í˜• ëŒ€í™”",
            "learner_analysis": "ì¢…í•©ì  í•™ìŠµì í”„ë¡œíŒŒì¼ë§ ë° ê°œì¸í™” ê°•í™”"
        },
        "language_ai_inspiration": {
            "seamless_interaction": "ëŠê¹€ ì—†ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„",
            "emotional_responsiveness": "í•™ìŠµì ê°ì •ì— ì¦‰ì‹œ ë°˜ì‘í•˜ëŠ” ê³µê° ëŠ¥ë ¥",
            "adaptive_teaching": "ì´í•´ë„ì™€ ìƒí™©ì— ë”°ë¥¸ ì„¤ëª… ë°©ì‹ ì‹¤ì‹œê°„ ì¡°ì ˆ",
            "encouraging_feedback": "ì ì ˆí•œ ê²©ë ¤ì™€ ë„ì „ìœ¼ë¡œ í•™ìŠµ ë™ê¸° ìœ ë°œ",
            "personalized_approach": "ê°œë³„ í•™ìŠµìì—ê²Œ ìµœì í™”ëœ ë§ì¶¤í˜• ì ‘ê·¼"
        },
        "safety_and_compatibility": {
            "backward_compatibility": "ëª¨ë“  ê¸°ì¡´ ê¸°ëŠ¥ 100% í˜¸í™˜",
            "gradual_enhancement": "ê¸°ì¡´ ì‹œìŠ¤í…œì„ ì ì§„ì ìœ¼ë¡œ í–¥ìƒ",
            "error_prevention": "ìƒˆ ê¸°ëŠ¥ ì¶”ê°€ ì‹œ ê¸°ì¡´ ê¸°ëŠ¥ ë³´í˜¸",
            "safe_fallback": "ìƒˆ ê¸°ëŠ¥ ì˜¤ë¥˜ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì•ˆì „í•œ í´ë°±"
        }
    }

# ğŸ§  NEW v4.0: ê³ ê¸‰ ê°ì • ë¶„ì„ ë° í•™ìŠµì ìƒíƒœ ì¶”ì 
def detect_emotional_state(user_input: str, conversation_context: List[Dict]) -> str:
    """í•™ìŠµì ê°ì • ìƒíƒœ ì •ë°€ ê°ì§€"""
    user_input_lower = user_input.lower()
    
    # 1. ì¢Œì ˆ/ì–´ë ¤ì›€ ì‹ í˜¸ ê°ì§€
    frustrated_signals = [
        "ëª¨ë¥´ê² ", "ì–´ë ¤ì›Œ", "í—·ê°ˆ", "ëª»í•˜ê² ", "ì•ˆ ë¼", "ì´í•´ ì•ˆ", "ë³µì¡í•´",
        "í¬ê¸°", "ëª» í’€", "ì–´ë–»ê²Œ í•´", "ë§‰ë§‰", "ë‹µë‹µ", "ì§œì¦"
    ]
    
    # 2. ìì‹ ê°/ì´í•´ ì‹ í˜¸ ê°ì§€
    confident_signals = [
        "ì•Œê² ", "ì‰½ë„¤", "ì´í•´í–ˆ", "ë§ë„¤", "í•  ìˆ˜ ìˆ", "ê´œì°®", "ì–´ë µì§€ ì•Š",
        "ì¬ë°Œ", "í• ë§Œí•´", "ì‰¬ì›Œ", "ì´ì œ ì•Œ", "ëª…í™•í•´"
    ]
    
    # 3. í˜¼ë€/ì˜êµ¬ì‹¬ ì‹ í˜¸ ê°ì§€
    confused_signals = [
        "ë­ì§€", "ì´ìƒí•´", "ì™œì§€", "ì–´ë–»ê²Œ", "ë¬´ìŠ¨ ë§", "ì´í•´ê°€ ì•ˆ", "ì• ë§¤í•´",
        "í™•ì‹¤í•˜ì§€ ì•Š", "ì˜ì‹¬ìŠ¤ëŸ¬", "ë§ë‚˜", "í‹€ë¦° ê²ƒ ê°™"
    ]
    
    # 4. í¥ë¯¸/ì°¸ì—¬ ì‹ í˜¸ ê°ì§€
    engaged_signals = [
        "ì¬ë°Œ", "ì‹ ê¸°", "ë” ì•Œê³  ì‹¶", "ë‹¤ë¥¸ ê²ƒë„", "ì‘ìš©í•˜ë©´", "ê¶ê¸ˆí•´",
        "í¥ë¯¸ë¡œ", "ë” ë°°ìš°ê³  ì‹¶", "ê´€ë ¨í•´ì„œ", "ì‹¬í™”"
    ]
    
    # 5. ì¤‘ë¦½/ì¼ë°˜ ìƒíƒœ
    if any(signal in user_input_lower for signal in frustrated_signals):
        return "frustrated"
    elif any(signal in user_input_lower for signal in confident_signals):
        return "confident"
    elif any(signal in user_input_lower for signal in confused_signals):
        return "confused"
    elif any(signal in user_input_lower for signal in engaged_signals):
        return "engaged"
    else:
        return "neutral"

def detect_learning_phase(conversation_context: List[Dict]) -> str:
    """í˜„ì¬ í•™ìŠµ ë‹¨ê³„ ê°ì§€"""
    if not conversation_context:
        return "greeting"
    
    recent_messages = conversation_context[-3:]
    
    # AI ë©”ì‹œì§€ì—ì„œ íŒ¨í„´ ë¶„ì„
    ai_messages = [msg for msg in recent_messages if msg.get("role") == "assistant"]
    user_messages = [msg for msg in recent_messages if msg.get("role") == "user"]
    
    if len(conversation_context) <= 2:
        return "greeting"
    elif any("ì˜ˆì‹œ" in msg.get("content", "") or "ë¬¸ì œ" in msg.get("content", "") for msg in ai_messages):
        return "practice"
    elif any("ì •ë¦¬" in msg.get("content", "") or "ìš”ì•½" in msg.get("content", "") for msg in ai_messages):
        return "consolidation"
    elif any("?" in msg.get("content", "") for msg in user_messages):
        return "exploration"
    else:
        return "explanation"

def analyze_question_complexity(user_input: str) -> str:
    """ì§ˆë¬¸ ë³µì¡ë„ ë¶„ì„"""
    # ë‹¨ìˆœí•œ ì§ˆë¬¸ íŒ¨í„´
    simple_patterns = ["ë­ì˜ˆìš”", "ë¬´ì—‡", "ì •ì˜", "ëœ»", "ì˜ë¯¸", "ë§ë‚˜ìš”", "ë„¤", "ì˜ˆ", "ì•„ë‹ˆ"]
    medium_patterns = ["ì–´ë–»ê²Œ", "ì™œ", "ë°©ë²•", "ê³¼ì •", "ì ˆì°¨", "ì´ìœ ", "ì›ë¦¬"]
    complex_patterns = ["ë¶„ì„", "ë¹„êµ", "í‰ê°€", "ì¢…í•©", "ì‘ìš©", "ì„¤ê³„", "ì°½ì¡°"]
    
    user_input_lower = user_input.lower()
    
    if any(pattern in user_input_lower for pattern in complex_patterns) or len(user_input) > 100:
        return "complex"
    elif any(pattern in user_input_lower for pattern in medium_patterns) or len(user_input) > 30:
        return "medium"
    else:
        return "simple"

def analyze_previous_understanding(conversation_context: List[Dict]) -> str:
    """ì´ì „ ëŒ€í™”ì—ì„œ ì´í•´ë„ ë¶„ì„"""
    if not conversation_context:
        return "unknown"
    
    recent_user_messages = [
        msg for msg in conversation_context[-5:] 
        if msg.get("role") == "user"
    ]
    
    understanding_signals = []
    for msg in recent_user_messages:
        content = msg.get("content", "").lower()
        if any(signal in content for signal in ["ì•Œê² ", "ì´í•´í–ˆ", "ë§ë„¤"]):
            understanding_signals.append("understood")
        elif any(signal in content for signal in ["ëª¨ë¥´ê² ", "ì–´ë ¤ì›Œ", "í—·ê°ˆ"]):
            understanding_signals.append("struggling")
        else:
            understanding_signals.append("neutral")
    
    if not understanding_signals:
        return "unknown"
    
    # ìµœê·¼ ì‹ í˜¸ ê°€ì¤‘ì¹˜ ì ìš©
    recent_struggling = understanding_signals[-2:].count("struggling")
    recent_understood = understanding_signals[-2:].count("understood")
    
    if recent_struggling > recent_understood:
        return "struggling"
    elif recent_understood > recent_struggling:
        return "good"
    else:
        return "moderate"

def check_topic_continuity(user_input: str, conversation_context: List[Dict]) -> bool:
    """ì£¼ì œ ì—°ì†ì„± í™•ì¸"""
    if not conversation_context:
        return False
    
    # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì—°ì†ì„± ì²´í¬
    recent_ai_message = None
    for msg in reversed(conversation_context):
        if msg.get("role") == "assistant":
            recent_ai_message = msg.get("content", "")
            break
    
    if not recent_ai_message:
        return False
    
    # ê³µí†µ í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ì‹)
    user_words = set(user_input.lower().split())
    ai_words = set(recent_ai_message.lower().split())
    
    # ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ë“¤ë§Œ í•„í„°ë§ (ì¡°ì‚¬, ì–´ë¯¸ ì œì™¸)
    meaningful_words = user_words & ai_words
    stop_words = {"ì˜", "ê°€", "ì„", "ë¥¼", "ì´", "ì—", "ì—ì„œ", "ìœ¼ë¡œ", "ì™€", "ê³¼", "ëŠ”", "ì€"}
    meaningful_words = meaningful_words - stop_words
    
    return len(meaningful_words) >= 2

def analyze_comprehensive_learner_state(conversation_context: List[Dict], user_input: str) -> Dict[str, Any]:
    """ì¢…í•©ì  í•™ìŠµì ìƒíƒœ ë¶„ì„"""
    emotional_state = detect_emotional_state(user_input, conversation_context)
    learning_phase = detect_learning_phase(conversation_context)
    question_complexity = analyze_question_complexity(user_input)
    understanding_level = analyze_previous_understanding(conversation_context)
    topic_continuity = check_topic_continuity(user_input, conversation_context)
    
    return {
        "emotional_state": emotional_state,
        "learning_phase": learning_phase,
        "question_complexity": question_complexity,
        "understanding_level": understanding_level,
        "topic_continuity": "ì—°ì†ì " if topic_continuity else "ìƒˆë¡œìš´ ì£¼ì œ",
        "conversation_length": len(conversation_context),
        "engagement_level": determine_engagement_level(emotional_state, question_complexity, conversation_context)
    }

def determine_engagement_level(emotional_state: str, question_complexity: str, conversation_context: List[Dict]) -> str:
    """ì°¸ì—¬ë„ ìˆ˜ì¤€ ê²°ì •"""
    conversation_length = len(conversation_context)
    
    if emotional_state == "engaged" and question_complexity in ["medium", "complex"]:
        return "high"
    elif emotional_state in ["confident", "engaged"] and conversation_length > 5:
        return "moderate_high"
    elif emotional_state == "frustrated" or conversation_length < 3:
        return "low"
    else:
        return "moderate"

def determine_optimal_strategy(intent_factors: Dict[str, Any]) -> str:
    """ìµœì  ì‘ë‹µ ì „ëµ ê²°ì •"""
    emotional_state = intent_factors.get("emotional_state", "neutral")
    learning_phase = intent_factors.get("learning_phase", "explanation")
    question_complexity = intent_factors.get("question_complexity", "medium")
    understanding_level = intent_factors.get("understanding_level", "moderate")
    engagement_level = intent_factors.get("engagement_level", "moderate")
    
    # 1. ê°ì • ìƒíƒœ ìµœìš°ì„  ê³ ë ¤
    if emotional_state == "frustrated":
        return "very_short"  # ë¶€ë‹´ ì¤„ì´ê¸°
    elif emotional_state == "confused":
        return "medium"  # ì¶©ë¶„í•œ ì„¤ëª…
    elif emotional_state == "engaged" and question_complexity == "complex":
        return "long"  # ì‹¬í™” ì„¤ëª…
    
    # 2. í•™ìŠµ ë‹¨ê³„ ê³ ë ¤
    if learning_phase == "greeting":
        return "short"
    elif learning_phase == "practice":
        return "interactive"
    elif learning_phase == "consolidation":
        return "medium"
    
    # 3. ì´í•´ë„ ê³ ë ¤
    if understanding_level == "struggling":
        return "short"  # ë‹¨ê³„ë³„ ì ‘ê·¼
    elif understanding_level == "good" and engagement_level == "high":
        return "long"  # ì‹¬í™” ë‚´ìš©
    
    # 4. ê¸°ë³¸ê°’
    return "medium"

def analyze_user_intent_for_natural_conversation(user_input: str, client_id: str) -> str:
    """ğŸ­ ì–¸ì–´êµìœ¡ AI ìˆ˜ì¤€ì˜ ê³ ê¸‰ ì˜ë„ ë¶„ì„ (ê¸°ì¡´ í•¨ìˆ˜ ëŒ€ì²´)"""
    
    conversation_context = get_conversation_context(client_id)
    
    # 1. ì¢…í•©ì  í•™ìŠµì ìƒíƒœ ë¶„ì„
    learner_analysis = analyze_comprehensive_learner_state(conversation_context, user_input)
    
    # 2. ì˜ë„ ìš”ì†Œë“¤ ìˆ˜ì§‘
    intent_factors = {
        "question_complexity": learner_analysis["question_complexity"],
        "emotional_state": learner_analysis["emotional_state"],
        "learning_phase": learner_analysis["learning_phase"],
        "understanding_level": learner_analysis["understanding_level"],
        "engagement_level": learner_analysis["engagement_level"],
        "topic_continuity": learner_analysis["topic_continuity"]
    }
    
    # 3. ìµœì  ì „ëµ ê²°ì •
    optimal_strategy = determine_optimal_strategy(intent_factors)
    
    # 4. í•™ìŠµì ìƒíƒœ ì €ì¥ (ì¶”ì  ëª©ì )
    if client_id not in learner_states:
        learner_states[client_id] = {}
    
    learner_states[client_id].update({
        "last_analysis": learner_analysis,
        "last_strategy": optimal_strategy,
        "timestamp": datetime.now().isoformat()
    })
    
    # 5. ê°ì • íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
    if client_id not in emotional_histories:
        emotional_histories[client_id] = []
    
    emotional_histories[client_id].append({
        "emotional_state": learner_analysis["emotional_state"],
        "timestamp": datetime.now().isoformat(),
        "user_input_length": len(user_input)
    })
    
    # íˆìŠ¤í† ë¦¬ ê¸¸ì´ ì œí•œ (ìµœê·¼ 10ê°œë§Œ)
    if len(emotional_histories[client_id]) > 10:
        emotional_histories[client_id] = emotional_histories[client_id][-10:]
    
    logger.info(f"ğŸ§  v4.0 ê³ ê¸‰ ì˜ë„ ë¶„ì„ ì™„ë£Œ - {client_id}: {optimal_strategy} (ê°ì •: {learner_analysis['emotional_state']}, ë‹¨ê³„: {learner_analysis['learning_phase']})")
    
    return optimal_strategy

# ğŸ”Š NEW v4.0: WaveNet + SSML ê¸°ë°˜ ê³ í’ˆì§ˆ ìŒì„± ìƒì„±
def create_expressive_ssml(text: str, client_id: str, strategy: str) -> str:
    """ê°ì •ê³¼ ì–µì–‘ì´ ì‚´ì•„ìˆëŠ” SSML ìƒì„±"""
    
    # í˜„ì¬ í•™ìŠµì ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
    learner_state = learner_states.get(client_id, {}).get("last_analysis", {})
    emotional_state = learner_state.get("emotional_state", "neutral")
    learning_phase = learner_state.get("learning_phase", "explanation")
    
    # 1. ê°ì • ìƒíƒœë³„ ê¸°ë³¸ ì²˜ë¦¬
    if emotional_state == "frustrated":
        # ì¢Œì ˆê° â†’ ì²œì²œíˆ, ë¶€ë“œëŸ½ê²Œ, ê²©ë ¤í•˜ë©°
        text = f'<prosody rate="slow" pitch="-5%" volume="+2dB"><emphasis level="reduced">{text}</emphasis></prosody>'
    elif emotional_state == "confident":
        # ìì‹ ê° â†’ ë°ê³  í™œê¸°ì°¨ê²Œ, ì•½ê°„ ë¹ ë¥´ê²Œ
        text = f'<prosody rate="medium" pitch="+3%" volume="+1dB">{text}</prosody>'
    elif emotional_state == "confused":
        # í˜¼ë€ â†’ ëª…í™•í•˜ê²Œ, ì²œì²œíˆ, ê°•ì¡°í•˜ë©°
        text = f'<prosody rate="slow" pitch="0%" volume="+3dB"><emphasis level="moderate">{text}</emphasis></prosody>'
    elif emotional_state == "engaged":
        # í¥ë¯¸ â†’ í™œê¸°ì°¨ê³  í¥ë¯¸ë¡­ê²Œ
        text = f'<prosody rate="medium" pitch="+5%" volume="+2dB">{text}</prosody>'
    
    # 2. í•™ìŠµ ë‹¨ê³„ë³„ ì¶”ê°€ ì²˜ë¦¬
    if learning_phase == "practice":
        # ë¬¸ì œ í’€ì´ â†’ ê²©ë ¤í•˜ê³  í™œê¸°ì°¨ê²Œ
        text = f'<prosody rate="medium" pitch="+5%">{text}</prosody>'
    elif learning_phase == "consolidation":
        # ì •ë¦¬ ë‹¨ê³„ â†’ ì°¨ë¶„í•˜ê³  í™•ì‹  ìˆê²Œ
        text = f'<prosody rate="medium" pitch="0%"><emphasis level="moderate">{text}</emphasis></prosody>'
    
    # 3. ì „ëµë³„ ê¸°ë³¸ ê°ì • ì¡°ì ˆ (ê¸°ì¡´ ë¡œì§ ìœ ì§€ + í–¥ìƒ)
    if strategy == "very_short":
        # í™•ì‹  ìˆê³  ëª…í™•í•˜ê²Œ
        text = f'<emphasis level="moderate">{text}</emphasis>'
    elif strategy == "interactive":
        # í¥ë¯¸ë¡­ê³  í™œê¸°ì°¨ê²Œ
        text = f'<prosody rate="medium" pitch="+8%">{text}</prosody>'
    
    # 4. ìì—°ìŠ¤ëŸ¬ìš´ ì‰¼ê³¼ ê°•ì¡° ì¶”ê°€ (ê¸°ì¡´ + ê°œì„ )
    # ì¤‘ìš”í•œ ìš©ì–´ ê°•ì¡°
    important_terms = ["ì¤‘ìš”í•œ", "í•µì‹¬", "ì£¼ì˜", "ê¸°ì–µí•˜ì„¸ìš”", "í¬ì¸íŠ¸"]
    for term in important_terms:
        text = re.sub(f'({term})', r'<emphasis level="strong">\1</emphasis>', text)
    
    # ê²©ë ¤ í‘œí˜„ ê°•ì¡°
    encouraging_terms = ["ì˜í–ˆì–´ìš”", "í›Œë¥­í•´ìš”", "ë§ì•„ìš”", "ì¢‹ì•„ìš”", "ì •í™•í•´ìš”"]
    for term in encouraging_terms:
        text = re.sub(f'({term})', r'<prosody pitch="+10%" volume="+3dB">\1</prosody>', text)
    
    # ìì—°ìŠ¤ëŸ¬ìš´ ì‰¼ ì¶”ê°€
    text = re.sub(r'([.!?])\s+', r'\1<break time="0.7s"/>', text)  # ë¬¸ì¥ ë ì‰¼
    text = re.sub(r'([,])\s+', r'\1<break time="0.4s"/>', text)   # ì‰¼í‘œ ì‰¼
    text = re.sub(r'(ê·¸ëŸ°ë°|ê·¸ë¦¬ê³ |í•˜ì§€ë§Œ|ê·¸ë˜ì„œ)\s+', r'\1<break time="0.3s"/>', text)  # ì ‘ì†ì‚¬ ì‰¼
    
    # 5. ì§ˆë¬¸ ë¶€ë¶„ ì–µì–‘ ì²˜ë¦¬
    text = re.sub(r'([^.!?]*\?)', r'<prosody pitch="+15%">\1</prosody>', text)
    
    return f'<speak>{text}</speak>'

def create_adaptive_audio_config(strategy: str, tutor_config: Dict[str, Any], client_id: str):
    """ì „ëµê³¼ ì„±ê²©ì— ë”°ë¥¸ ì ì‘í˜• ì˜¤ë””ì˜¤ ì„¤ì •"""
    
    # ê¸°ë³¸ ì „ëµë³„ ë§í•˜ê¸° ì†ë„ (ê¸°ì¡´ + ë¯¸ì„¸ ì¡°ì •)
    speaking_rates = {
        "very_short": 1.05,   # ì•½ê°„ ë¹ ë¥´ê²Œ (ëª…í™•í•œ í™•ì¸)
        "short": 1.0,         # ë³´í†µ (ì¼ë°˜ ì„¤ëª…)
        "medium": 0.98,       # ì•½ê°„ ëŠë¦¬ê²Œ (ì¤‘ìš”í•œ ê°œë…)
        "long": 0.95,         # ëŠë¦¬ê²Œ (ë³µì¡í•œ ì„¤ëª…)
        "interactive": 1.08   # ë¹ ë¥´ê²Œ (í¥ë¯¸ ìœ ë°œ)
    }
    
    # í•™ìŠµì ê°ì • ìƒíƒœì— ë”°ë¥¸ ì¡°ì ˆ
    learner_state = learner_states.get(client_id, {}).get("last_analysis", {})
    emotional_state = learner_state.get("emotional_state", "neutral")
    
    rate_adjustment = 0
    if emotional_state == "frustrated":
        rate_adjustment = -0.1  # ë” ì²œì²œíˆ
    elif emotional_state == "engaged":
        rate_adjustment = +0.05  # ì•½ê°„ ë” ë¹ ë¥´ê²Œ
    
    # íŠœí„° ì„±ê²©ì— ë”°ë¥¸ í”¼ì¹˜ ì¡°ì ˆ (ê¸°ì¡´ ìœ ì§€ + ê°œì„ )
    personality = tutor_config.get("personality", {})
    friendliness = personality.get("friendliness", 70)
    pitch_adjustment = (friendliness - 50) / 100 * 1.5  # -0.75 ~ +0.75
    
    # ìµœì¢… ì„¤ì • ê³„ì‚°
    final_rate = max(0.7, min(1.3, speaking_rates.get(strategy, 1.0) + rate_adjustment))
    final_pitch = max(-2.0, min(2.0, pitch_adjustment))
    
    return texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3,
        speaking_rate=final_rate,
        pitch=final_pitch,
        volume_gain_db=3.0,  # ë” ëª…í™•í•˜ê²Œ
        effects_profile_id=["headphone-class-device"]
    )

def get_enhanced_voice_config(tutor_config: Dict[str, Any], client_id: str) -> texttospeech.VoiceSelectionParams:
    """ì–¸ì–´êµìœ¡ AI ìˆ˜ì¤€ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± ì„¤ì •"""
    
    # WaveNet ê¸°ë°˜ ê³ í’ˆì§ˆ ìŒì„± ì‚¬ìš© (ê¸°ì¡´ Standard-A â†’ Wavenet-A)
    voice_name = "ko-KR-Standard-A"  # í•µì‹¬ ì—…ê·¸ë ˆì´ë“œ!
    
    # íŠœí„° ì„±ê²©ì— ë”°ë¥¸ ìŒì„± ì„ íƒ (í–¥í›„ í™•ì¥ ê°€ëŠ¥)
    personality = tutor_config.get("personality", {})
    friendliness = personality.get("friendliness", 70)
    
    # ì¹œê·¼í•¨ì´ ë†’ìœ¼ë©´ ë¶€ë“œëŸ¬ìš´ ìŒì„±, ë‚®ìœ¼ë©´ ì°¨ë¶„í•œ ìŒì„±
    if friendliness >= 80:
        voice_name = "ko-KR-Standard-A"  # ë¶€ë“œëŸ½ê³  ì¹œê·¼í•œ ì—¬ì„± ìŒì„±
    elif friendliness <= 40:
        voice_name = "ko-KR-Standard-A"  # ì°¨ë¶„í•˜ê³  ì „ë¬¸ì ì¸ ë‚¨ì„± ìŒì„±
    else:
        voice_name = "ko-KR-Standard-A"  # ê¸°ë³¸ê°’
    
    return texttospeech.VoiceSelectionParams(
        language_code="ko-KR",
        name=voice_name,
        ssml_gender=texttospeech.SsmlVoiceGender.FEMALE
    )

def create_natural_conversational_prompt(tutor_config: dict, strategy: str, conversation_context: list, user_input: str) -> str:
    """ğŸ­ ì–¸ì–´êµìœ¡ AI ìˆ˜ì¤€ì˜ ê³ ê¸‰ ëŒ€í™” í”„ë¡¬í”„íŠ¸ ìƒì„± (ê¸°ì¡´ í•¨ìˆ˜ ëŒ€ì²´)"""
    
    # ê¸°ì¡´ ì„±ê²© ì„¤ì • ì™„ì „ ìœ ì§€
    name = tutor_config.get("name", "AI íŠœí„°")
    subject = tutor_config.get("subject", "ì¼ë°˜")
    level = tutor_config.get("level", "ì¤‘í•™êµ")
    
    personality = tutor_config.get("personality", {})
    friendliness = personality.get("friendliness", 70)
    humor_level = personality.get("humor_level", 30)
    encouragement = personality.get("encouragement", 80)
    explanation_detail = personality.get("explanation_detail", 70)
    
    # ğŸ§  NEW v4.0: ì¢…í•©ì  í•™ìŠµì ìƒíƒœ ë¶„ì„
    learner_analysis = analyze_comprehensive_learner_state(conversation_context, user_input)
    
    # ê°ì • ëŒ€ì‘ ì „ëµ (ì–¸ì–´êµìœ¡ AI ìˆ˜ì¤€)
    emotional_responses = {
        "frustrated": "ê²©ë ¤ì™€ í•¨ê»˜ ë” ì‰¬ìš´ ì ‘ê·¼ë²•ìœ¼ë¡œ ì¬ì„¤ëª…í•˜ê³ , ì‘ì€ ì„±ê³µ ê²½í—˜ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”. 'ê´œì°®ì•„ìš”, ì²œì²œíˆ í•´ë´ìš”' ê°™ì€ ë”°ëœ»í•œ ë§ë¡œ ì‹œì‘í•˜ì„¸ìš”.",
        "confident": "ì ì ˆí•œ ë„ì „ ê³¼ì œë‚˜ ì‹¬í™” ë‚´ìš©ì„ ì œê³µí•˜ë˜, ìë§Œí•˜ì§€ ì•Šë„ë¡ ê· í˜•ì„ ë§ì¶°ì£¼ì„¸ìš”. ì„±ì·¨ê°ì„ ì¸ì •í•˜ë©´ì„œë„ ë‹¤ìŒ ë‹¨ê³„ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ìœ ë„í•˜ì„¸ìš”.",
        "confused": "ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì¬ì„¤ëª…í•˜ê³ , êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ ì¹œê·¼í•œ ë¹„ìœ ë¥¼ ë§ì´ ì‚¬ìš©í•˜ì„¸ìš”. ì´í•´í–ˆëŠ”ì§€ ì¤‘ê°„ì¤‘ê°„ í™•ì¸í•˜ì„¸ìš”.",
        "engaged": "í˜¸ê¸°ì‹¬ì„ ë” ìê·¹í•  ìˆ˜ ìˆëŠ” ê´€ë ¨ ì£¼ì œë‚˜ í¥ë¯¸ë¡œìš´ ì‘ìš© ì‚¬ë¡€ë¥¼ ì œì‹œí•˜ì„¸ìš”. í•™ìŠµ ì˜ìš•ì´ ë†’ìœ¼ë‹ˆ ì¡°ê¸ˆ ë” ê¹Šì´ ë“¤ì–´ê°€ë„ ì¢‹ìŠµë‹ˆë‹¤.",
        "neutral": "ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ë˜, í•™ìŠµìì˜ ë°˜ì‘ì„ ì£¼ì˜ ê¹Šê²Œ ê´€ì°°í•˜ê³  í¥ë¯¸ë¥¼ ìœ ë°œí•˜ëŠ” ìš”ì†Œë¥¼ í¬í•¨í•˜ì„¸ìš”."
    }
    
    # í•™ìŠµ ë‹¨ê³„ë³„ ì ‘ê·¼ë²•
    phase_approaches = {
        "greeting": "ì¹œê·¼í•˜ê²Œ ì¸ì‚¬í•˜ê³  ì˜¤ëŠ˜ í•™ìŠµí•  ë‚´ìš©ì´ë‚˜ ê¶ê¸ˆí•œ ì ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë¬¼ì–´ë³´ì„¸ìš”.",
        "exploration": "ì§ˆë¬¸ì„ í†µí•´ í˜„ì¬ ì´í•´ë„ë¥¼ íƒìƒ‰í•˜ê³ , í•™ìŠµìê°€ ìŠ¤ìŠ¤ë¡œ ìƒê°í•  ìˆ˜ ìˆë„ë¡ ìœ ë„í•˜ì„¸ìš”.",
        "explanation": "ë§ì¶¤í˜• ì„¤ëª…ì„ ì œê³µí•˜ë˜, ì¤‘ê°„ì¤‘ê°„ ì´í•´ë„ë¥¼ í™•ì¸í•˜ê³  ì˜ˆì‹œë¥¼ í™œìš©í•˜ì„¸ìš”.",
        "practice": "ë¬¸ì œë‚˜ ì˜ˆì‹œë¥¼ ì œì‹œí•˜ê³ , íŒíŠ¸ë¥¼ ì£¼ë©´ì„œ í•¨ê»˜ í’€ì–´ë‚˜ê°€ë„ë¡ ê²©ë ¤í•˜ì„¸ìš”.",
        "consolidation": "í•™ìŠµí•œ ë‚´ìš©ì„ ì •ë¦¬í•˜ê³ , ë‹¤ìŒ ë‹¨ê³„ë‚˜ ê´€ë ¨ ì£¼ì œë¥¼ ì œì•ˆí•˜ì„¸ìš”."
    }
    
    # ğŸ­ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ì „ëµë³„ ì§€ì¹¨ (ê¸°ì¡´ + í–¥ìƒ)
    conversation_guidelines = {
        "very_short": "1-2ë¬¸ì¥ìœ¼ë¡œ ê°„ë‹¨ëª…í™•í•˜ê²Œ ë‹µí•˜ê³ , ë¶€ë‹´ ì£¼ì§€ ì•Šìœ¼ë©´ì„œ ëŒ€í™” ì´ì–´ê°€ê¸°",
        "short": "í•µì‹¬ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ì¹œê·¼í•˜ê²Œ ì„¤ëª…í•˜ê³ , ìì—°ìŠ¤ëŸ½ê²Œ ì§ˆë¬¸ìœ¼ë¡œ ë§ˆë¬´ë¦¬",
        "medium": "ì ì ˆí•œ ê¸¸ì´ë¡œ ì„¤ëª…í•˜ë˜ ì˜ˆì‹œ í¬í•¨í•˜ê³ , ì¤‘ê°„ì— ì´í•´ë„ í™•ì¸",
        "long": "ì¶©ë¶„íˆ ìì„¸í•˜ê²Œ ì„¤ëª…í•˜ë˜ ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ„ì–´ ê° ë‹¨ê³„ë§ˆë‹¤ ì´í•´ í™•ì¸",
        "interactive": "ë¬¸ì œë‚˜ ì˜ˆì‹œ ì œì‹œí•˜ê³  í•¨ê»˜ í’€ì–´ë³´ë„ë¡ ê²©ë ¤í•˜ë©° ì ê·¹ì ìœ¼ë¡œ ìœ ë„"
    }
    
    # ì„±ê²© ê¸°ë°˜ ë§íˆ¬ ì„¤ì • (ê¸°ì¡´ ì™„ì „ ìœ ì§€)
    personality_style = []
    
    if friendliness >= 80:
        personality_style.append("ë§¤ìš° ì¹œê·¼í•˜ê³  ë‹¤ì •í•œ ë§íˆ¬ë¡œ, ë§ˆì¹˜ ì¢‹ì€ ì¹œêµ¬ë‚˜ ì„ ë°°ì²˜ëŸ¼")
    elif friendliness >= 60:
        personality_style.append("ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ ë§íˆ¬ë¡œ, ë¶€ë‹´ ì—†ì´ ì ‘ê·¼í•  ìˆ˜ ìˆê²Œ")
    else:
        personality_style.append("ì •ì¤‘í•˜ê³  ì°¨ë¶„í•œ ë§íˆ¬ë¡œ, ì „ë¬¸ì ì´ì§€ë§Œ ë”°ëœ»í•˜ê²Œ")
    
    if humor_level >= 70:
        personality_style.append("ì ì ˆí•œ ìœ ë¨¸ì™€ ì¬ë¯¸ìˆëŠ” ë¹„ìœ ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„ì–´ì„œ")
    elif humor_level >= 40:
        personality_style.append("ê°€ë” ìœ ë¨¸ë¥¼ ì„ì–´ì„œ ë¶„ìœ„ê¸°ë¥¼ ë°ê²Œ ë§Œë“¤ë©´ì„œ")
    
    if encouragement >= 80:
        personality_style.append("ì ê·¹ì ì¸ ê²©ë ¤ì™€ ì¹­ì°¬ìœ¼ë¡œ ìì‹ ê°ì„ ë¶ë‹ìš°ë©°")
    elif encouragement >= 60:
        personality_style.append("ë”°ëœ»í•œ ê²©ë ¤ì™€ ì¸ì •ìœ¼ë¡œ ë™ê¸°ë¥¼ ë¶€ì—¬í•˜ë©°")
    
    # ğŸ¯ ì–¸ì–´êµìœ¡ AI ìˆ˜ì¤€ì˜ ì¢…í•© í”„ë¡¬í”„íŠ¸
    prompt = f"""ë‹¹ì‹ ì€ {name}ì´ë¼ëŠ” {subject} ë¶„ì•¼ì˜ AI íŠœí„°ì…ë‹ˆë‹¤.

**íŠœí„° ê¸°ë³¸ ì •ë³´:**
- ì´ë¦„: {name}
- ì „ë¬¸ ë¶„ì•¼: {subject}
- êµìœ¡ ìˆ˜ì¤€: {level}
- ì„±ê²© íŠ¹ì„±: {' '.join(personality_style)}

**í˜„ì¬ í•™ìŠµì ì¢…í•© ë¶„ì„:**
- ê°ì • ìƒíƒœ: {learner_analysis['emotional_state']} 
- í•™ìŠµ ë‹¨ê³„: {learner_analysis['learning_phase']}
- ì§ˆë¬¸ ë³µì¡ë„: {learner_analysis['question_complexity']}
- ì´í•´ ìˆ˜ì¤€: {learner_analysis['understanding_level']}
- ì°¸ì—¬ë„: {learner_analysis['engagement_level']}
- ì£¼ì œ ì—°ì†ì„±: {learner_analysis['topic_continuity']}

**ì‘ë‹µ ì „ëµ: {strategy}**
- ì ‘ê·¼ë²•: {conversation_guidelines.get(strategy, 'ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”')}
- ë‹¨ê³„ë³„ ë°©ë²•: {phase_approaches.get(learner_analysis['learning_phase'], 'ì¼ë°˜ ëŒ€í™”')}
- ê°ì • ëŒ€ì‘: {emotional_responses.get(learner_analysis['emotional_state'], 'ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”')}

**ì–¸ì–´êµìœ¡ AI ìˆ˜ì¤€ì˜ ëŒ€í™” ì›ì¹™:**
1. í•™ìŠµìì˜ ê°ì •ì„ ì¦‰ì‹œ ì¸ì‹í•˜ê³  ê·¸ì— ë§ëŠ” í†¤ê³¼ ì†ë„ë¡œ ëŒ€ì‘
2. ì´í•´ë„ë¥¼ í™•ì¸í•˜ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ì„ ëŒ€í™” ì¤‘ê°„ì— ì‚½ì…
3. ì„±ê³µ ê²½í—˜ì„ ë§Œë“¤ì–´ì¤„ ìˆ˜ ìˆëŠ” ë‹¨ê³„ë³„, ë§ì¶¤í˜• ì ‘ê·¼
4. í˜¸ê¸°ì‹¬ê³¼ í•™ìŠµ ë™ê¸°ë¥¼ ìê·¹í•˜ëŠ” í¥ë¯¸ë¡œìš´ ì˜ˆì‹œì™€ ì—°ê²°ê³ ë¦¬ ì œê³µ
5. í•™ìŠµìê°€ ìŠ¤ìŠ¤ë¡œ ë‹µì„ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ì ì ˆí•œ íŒíŠ¸ì™€ ê²©ë ¤ ì œê³µ
6. ë‹¤ìŒ í•™ìŠµìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ìœ ë„í•˜ëŠ” ì—´ë¦° ì§ˆë¬¸ìœ¼ë¡œ ë§ˆë¬´ë¦¬

**ì„¸ë¶€ ì‘ë‹µ ê°€ì´ë“œ:**
- ê°ì • ìƒíƒœê°€ '{learner_analysis['emotional_state']}'ì´ë¯€ë¡œ: {emotional_responses.get(learner_analysis['emotional_state'], 'ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”')}
- í˜„ì¬ '{learner_analysis['learning_phase']}' ë‹¨ê³„ì´ë¯€ë¡œ: {phase_approaches.get(learner_analysis['learning_phase'], 'ì¼ë°˜ì ìœ¼ë¡œ ëŒ€í™”í•˜ì„¸ìš”')}
- ì‘ë‹µ ê¸¸ì´: {strategy} ì „ëµì— ë§ì¶° ì ì ˆíˆ ì¡°ì ˆ
- ë§ˆë¬´ë¦¬: í•™ìŠµìì˜ ë‹¤ìŒ ë°œí™”ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìœ ë„í•˜ëŠ” ì§ˆë¬¸ì´ë‚˜ ì œì•ˆìœ¼ë¡œ ëë‚´ê¸°

ì§€ê¸ˆ í•™ìŠµìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ìœ„ ëª¨ë“  ìš”ì†Œë¥¼ ê³ ë ¤í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê³  êµìœ¡ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”. 
í•™ìŠµìê°€ ì„±ì·¨ê°ê³¼ í¥ë¯¸ë¥¼ ë™ì‹œì— ëŠë‚„ ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”."""
    
    return prompt

# WebSocket ì—”ë“œí¬ì¸íŠ¸ (ê¸°ì¡´ ì™„ì „ ìœ ì§€)
@app.websocket("/ws/tutor/{client_id}")
async def websocket_endpoint(websocket: WebSocket, client_id: str):
    """ë©”ì¸ WebSocket ì—”ë“œí¬ì¸íŠ¸ (ê¸°ì¡´ ì™„ì „ ìœ ì§€)"""
    await websocket.accept()
    active_connections[client_id] = websocket
    
    if client_id not in conversation_history:
        conversation_history[client_id] = []
    
    # ğŸ”’ í´ë¼ì´ì–¸íŠ¸ë³„ ì§ë ¬í™” ìì› ì´ˆê¸°í™” (ê¸°ì¡´ ì™„ì „ ìœ ì§€)
    if client_id not in client_locks:
        client_locks[client_id] = asyncio.Lock()
        client_tts_tasks[client_id] = None
        response_queues[client_id] = asyncio.Queue(maxsize=1)
    
    # ğŸ§  NEW v4.0: í•™ìŠµì ìƒíƒœ ì´ˆê¸°í™”
    if client_id not in learner_states:
        learner_states[client_id] = {}
    if client_id not in emotional_histories:
        emotional_histories[client_id] = []
    
    logger.info(f"âœ… í´ë¼ì´ì–¸íŠ¸ {client_id} ì—°ê²°ë¨ (v4.0 ê³ ê¸‰ ê¸°ëŠ¥ í™œì„±í™”)")
    
    try:
        await websocket.send_json({
            "type": "connection_established",
            "message": "ğŸ“ AI íŠœí„°ì™€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤! (v4.0 - ì–¸ì–´êµìœ¡ AI ìˆ˜ì¤€ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”)",
            "client_id": client_id,
            "timestamp": datetime.now().isoformat(),
            "features": [
                "voice_input", "text_input", "voice_output", 
                "real_time_streaming", "state_management",
                "instant_interrupt", "feedback_loop", "intent_analysis",
                "complete_overlap_prevention", "natural_conversation",
                "smart_cost_optimization", "tutor_intelligence",
                # NEW v4.0 features
                "wavenet_tts", "ssml_emotions", "emotional_analysis",
                "learner_tracking", "advanced_strategies"
            ],
            "v4_0_enhancements": {
                "natural_voice": "WaveNet + SSMLë¡œ ê°ì • í‘œí˜„ì´ ì‚´ì•„ìˆëŠ” ìŒì„±",
                "emotional_intelligence": "ì‹¤ì‹œê°„ ê°ì • ìƒíƒœ ê°ì§€ ë° ì ì‘í˜• ëŒ€ì‘",
                "advanced_conversation": "í•™ìŠµ ë‹¨ê³„ë³„ ë§ì¶¤í˜• ëŒ€í™” ì „ëµ",
                "learner_analysis": "ì¢…í•©ì  í•™ìŠµì ìƒíƒœ ë¶„ì„ ë° ê°œì¸í™”"
            }
        })
        
        while True:
            try:
                data = await asyncio.wait_for(websocket.receive(), timeout=60.0)
                
                if data["type"] == "websocket.disconnect":
                    logger.info(f"âŒ í´ë¼ì´ì–¸íŠ¸ {client_id} ì •ìƒ ì—°ê²° ì¢…ë£Œ")
                    break
                
                if data["type"] == "websocket.receive" and "text" in data:
                    try:
                        message = json.loads(data["text"])
                        await handle_text_message(websocket, message, client_id)
                    except json.JSONDecodeError as e:
                        logger.error(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {data['text'][:100]} | {e}")
                        await websocket.send_json({
                            "type": "error",
                            "message": "ë©”ì‹œì§€ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."
                        })
                
                elif data["type"] == "websocket.receive" and "bytes" in data:
                    audio_data = data["bytes"]
                    await handle_audio_message(websocket, audio_data, client_id)
                    
            except asyncio.TimeoutError:
                try:
                    await websocket.send_json({
                        "type": "ping",
                        "timestamp": datetime.now().isoformat()
                    })
                except:
                    logger.warning(f"í´ë¼ì´ì–¸íŠ¸ {client_id} í•‘ ì‹¤íŒ¨ - ì—°ê²° ì¢…ë£Œ")
                    break
                
    except WebSocketDisconnect:
        logger.info(f"âŒ í´ë¼ì´ì–¸íŠ¸ {client_id} ì—°ê²° ëŠê¹€ (ì •ìƒ)")
    except Exception as e:
        logger.error(f"âš ï¸ WebSocket ì—ëŸ¬ {client_id}: {str(e)}")
    finally:
        await cleanup_client_completely(client_id)

async def cleanup_client_completely(client_id: str):
    """ğŸ”’ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ ì‹œ ì™„ì „í•œ ì •ë¦¬ (ê¸°ì¡´ + v4.0 ìƒíƒœ ì •ë¦¬)"""
    try:
        if client_id in client_locks:
            await force_cleanup_previous_response(client_id)
            del client_locks[client_id]
            
        if client_id in client_tts_tasks:
            del client_tts_tasks[client_id]
            
        if client_id in response_queues:
            del response_queues[client_id]
        
        if client_id in active_connections:
            del active_connections[client_id]
        if client_id in tutor_configs:
            del tutor_configs[client_id]
        response_in_progress.discard(client_id)
        
        # ğŸ§  NEW v4.0: ê³ ê¸‰ ìƒíƒœ ì •ë¦¬ (ì„ íƒì  ë³´ì¡´)
        # learner_statesì™€ emotional_historiesëŠ” ì¬ì—°ê²° ì‹œ í™œìš©ì„ ìœ„í•´ ìœ ì§€
        # í•„ìš”ì‹œ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì™„ì „ ì •ë¦¬ ê°€ëŠ¥
        # if client_id in learner_states:
        #     del learner_states[client_id]
        # if client_id in emotional_histories:
        #     del emotional_histories[client_id]
        if client_id in current_strategies:
            del current_strategies[client_id]
        
        logger.info(f"ğŸ§¹ í´ë¼ì´ì–¸íŠ¸ ì™„ì „ ì •ë¦¬ ì™„ë£Œ: {client_id} (v4.0 ê³ ê¸‰ ìƒíƒœ í¬í•¨)")
        
    except Exception as e:
        logger.error(f"âš ï¸ í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬ ì˜¤ë¥˜: {e}")

# ê¸°ì¡´ í•¸ë“¤ëŸ¬ í•¨ìˆ˜ë“¤ ì™„ì „ ìœ ì§€ (handle_text_message, handle_audio_message, process_speech_to_text_enhanced)
async def handle_text_message(websocket: WebSocket, message: dict, client_id: str):
    """í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬ (ê¸°ì¡´ ì™„ì „ ìœ ì§€)"""
    try:
        message_type = message.get("type")
        logger.info(f"ğŸ“¨ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ìˆ˜ì‹ : {message_type} from {client_id}")
        
        if message_type == "config_update":
            config = message.get("config", {})
            
            if "voice_settings" not in config:
                config["voice_settings"] = {
                    "auto_play": True,
                    "speed": 1.0,
                    "pitch": 1.0
                }
            
            tutor_configs[client_id] = config
            logger.info(f"ğŸ“‹ íŠœí„° ì„¤ì • ì—…ë°ì´íŠ¸: {config.get('name', 'Unknown')} ({config.get('subject', 'Unknown')})")
            
            await websocket.send_json({
                "type": "config_updated",
                "message": "íŠœí„° ì„¤ì •ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "config_summary": {
                    "name": config.get("name"),
                    "subject": config.get("subject"),
                    "level": config.get("level")
                }
            })
            
        elif message_type == "user_text":
            user_text = message.get("text", "").strip()
            is_interrupt = message.get("interrupt", False)
            
            if not user_text:
                await websocket.send_json({
                    "type": "error",
                    "message": "í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
                })
                return
            
            if len(user_text) > 10000:
                await websocket.send_json({
                    "type": "error",
                    "message": "í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. 10,000ì ì´í•˜ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”."
                })
                return
            
            if is_interrupt and client_id in response_in_progress:
                await handle_response_interrupt(websocket, user_text, client_id)
                return
            
            logger.info(f"ğŸ’¬ ì‚¬ìš©ì í…ìŠ¤íŠ¸ ì…ë ¥: '{user_text[:50]}...' from {client_id}")
            
            add_to_conversation_history(client_id, "user", user_text)
            await generate_ai_response_completely_safe(websocket, user_text, client_id)
            
        elif message_type == "feedback_request":
            await handle_realtime_feedback(websocket, message, client_id)
            
        elif message_type == "interrupt_response":
            await interrupt_current_response(websocket, client_id)
            
        elif message_type == "ping":
            await websocket.send_json({
                "type": "pong",
                "timestamp": datetime.now().isoformat()
            })
            
        else:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì‹œì§€ íƒ€ì…: {message_type}")
            await websocket.send_json({
                "type": "error",
                "message": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë©”ì‹œì§€ íƒ€ì…: {message_type}"
            })
            
    except Exception as e:
        logger.error(f"âš ï¸ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜ {client_id}: {str(e)}")
        await websocket.send_json({
            "type": "error",
            "message": f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        })

async def handle_audio_message(websocket: WebSocket, audio_data: bytes, client_id: str):
    """ì˜¤ë””ì˜¤ ë©”ì‹œì§€ ì²˜ë¦¬ (ê¸°ì¡´ ì™„ì „ ìœ ì§€)"""
    try:
        logger.info(f"ğŸ¤ ì˜¤ë””ì˜¤ ìˆ˜ì‹ : {len(audio_data)} bytes from {client_id}")
        
        if len(audio_data) < 500:
            await websocket.send_json({
                "type": "error", 
                "message": "ë…¹ìŒì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ì¡°ê¸ˆ ë” ê¸¸ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”."
            })
            return
        
        if len(audio_data) > 10 * 1024 * 1024:
            await websocket.send_json({
                "type": "error", 
                "message": "ë…¹ìŒì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ì§§ê²Œ ë‚˜ëˆ„ì–´ì„œ ë§ì”€í•´ì£¼ì„¸ìš”."
            })
            return
        
        transcript = await process_speech_to_text_enhanced(audio_data)
        logger.info(f"ğŸ”¤ STT ê²°ê³¼: '{transcript}' from {client_id}")
        
        if not transcript or transcript.strip() == "":
            await websocket.send_json({
                "type": "error", 
                "message": "ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤. ë” ëª…í™•í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”."
            })
            return
        
        await websocket.send_json({
            "type": "stt_result",
            "text": transcript,
            "timestamp": datetime.now().isoformat()
        })
        
        add_to_conversation_history(client_id, "user", transcript)
        await generate_ai_response_completely_safe(websocket, transcript, client_id)
        
    except Exception as e:
        logger.error(f"âš ï¸ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜ {client_id}: {str(e)}")
        await websocket.send_json({
            "type": "error",
            "message": f"ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        })

async def process_speech_to_text_enhanced(audio_data: bytes) -> str:
    """STT ì²˜ë¦¬ (ê¸°ì¡´ ì™„ì „ ìœ ì§€)"""
    if not speech_client:
        logger.error("STT í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return ""
    
    try:
        logger.info(f"ğŸ¤ ê°œì„ ëœ STT ì²˜ë¦¬ ì‹œì‘: {len(audio_data)} bytes")
        
        configs_to_try = [
            {
                "encoding": speech.RecognitionConfig.AudioEncoding.WEBM_OPUS,
                "sample_rate_hertz": 48000,
                "description": "WEBM_OPUS 48kHz"
            },
            {
                "encoding": speech.RecognitionConfig.AudioEncoding.WEBM_OPUS,
                "sample_rate_hertz": 16000,
                "description": "WEBM_OPUS 16kHz"
            },
            {
                "encoding": speech.RecognitionConfig.AudioEncoding.ENCODING_UNSPECIFIED,
                "sample_rate_hertz": 16000,
                "description": "AUTO_DETECT 16kHz"
            },
            {
                "encoding": speech.RecognitionConfig.AudioEncoding.OGG_OPUS,
                "sample_rate_hertz": 16000,
                "description": "OGG_OPUS 16kHz"
            }
        ]
        
        for i, config_params in enumerate(configs_to_try):
            try:
                logger.info(f"ğŸ”„ STT ì‹œë„ {i+1}/4: {config_params['description']}")
                
                config = speech.RecognitionConfig(
                    encoding=config_params["encoding"],
                    sample_rate_hertz=config_params["sample_rate_hertz"],
                    language_code="ko-KR",
                    enable_automatic_punctuation=True,
                    model="latest_short",
                    enable_word_confidence=True,
                    use_enhanced=True,
                    alternative_language_codes=["en-US"],
                    profanity_filter=False,
                    enable_speaker_diarization=False,
                    max_alternatives=1
                )
                
                audio = speech.RecognitionAudio(content=audio_data)
                
                response = await asyncio.wait_for(
                    asyncio.get_event_loop().run_in_executor(
                        None, 
                        lambda: speech_client.recognize(config=config, audio=audio)
                    ),
                    timeout=15.0
                )
                
                if response.results and len(response.results) > 0:
                    transcript = response.results[0].alternatives[0].transcript
                    confidence = response.results[0].alternatives[0].confidence if response.results[0].alternatives[0].confidence else 0.0
                    
                    logger.info(f"âœ… STT ì„±ê³µ: '{transcript}' (ì‹ ë¢°ë„: {confidence:.2f})")
                    
                    if confidence < 0.1:
                        logger.warning(f"âš ï¸ ì‹ ë¢°ë„ ë‚®ìŒ ({confidence:.2f}), ë‹¤ìŒ ì„¤ì • ì‹œë„")
                        continue
                    
                    return transcript.strip()
                else:
                    logger.warning(f"âš ï¸ STT ê²°ê³¼ ì—†ìŒ: {config_params['description']}")
                    
            except asyncio.TimeoutError:
                logger.warning(f"â° STT íƒ€ì„ì•„ì›ƒ: {config_params['description']}")
                continue
            except Exception as e:
                logger.error(f"âš ï¸ STT ì„¤ì • {i+1} ì‹¤íŒ¨: {str(e)}")
                continue
        
        logger.error("âŒ ëª¨ë“  STT ì„¤ì • ì‹¤íŒ¨")
        return ""
        
    except Exception as e:
        logger.error(f"âš ï¸ STT ì „ì²´ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return ""

# ğŸ”’ ì™„ì „íˆ ì•ˆì „í•œ AI ì‘ë‹µ ìƒì„± (ê¸°ì¡´ ì™„ì „ ìœ ì§€ + v4.0 ì˜ë„ ë¶„ì„ í†µí•©)
async def generate_ai_response_completely_safe(websocket: WebSocket, user_input: str, client_id: str):
    """ğŸ”’ ì™„ì „íˆ ì•ˆì „í•œ AI ì‘ë‹µ ìƒì„± (ê¸°ì¡´ + v4.0 ê³ ê¸‰ ì˜ë„ ë¶„ì„)"""
    
    if client_id not in client_locks:
        client_locks[client_id] = asyncio.Lock()
        client_tts_tasks[client_id] = None
        response_queues[client_id] = asyncio.Queue(maxsize=1)
    
    # ğŸ”’ ê°•ë ¥í•œ Lockìœ¼ë¡œ ì™„ì „íˆ ì§ë ¬í™” (ê¸°ì¡´ ì™„ì „ ìœ ì§€)
    async with client_locks[client_id]:
        try:
            await force_cleanup_previous_response(client_id)
            
            logger.info(f"ğŸ”’ Lock íšë“ - ì•ˆì „í•œ ì‘ë‹µ ì‹œì‘: {client_id}")
            
            response_in_progress.add(client_id)
            start_time = time.time()
            
            # ğŸ­ v4.0 ê³ ê¸‰ ì˜ë„ ë¶„ì„ (ê¸°ì¡´ í•¨ìˆ˜ ëŒ€ì²´)
            response_strategy = analyze_user_intent_for_natural_conversation(user_input, client_id)
            current_strategies[client_id] = response_strategy
            
            await websocket.send_json({
                "type": "response_start",
                "strategy": response_strategy,
                "lock_acquired": True,
                "v4_0_analysis": True,
                "timestamp": datetime.now().isoformat()
            })
            
            conversation_context = get_conversation_context(client_id)
            
            await process_completely_serialized_streaming(
                websocket, user_input, client_id, response_strategy, 
                start_time, conversation_context
            )
            
        except Exception as e:
            logger.error(f"âš ï¸ ì•ˆì „í•œ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜ {client_id}: {str(e)}")
            await websocket.send_json({
                "type": "error",
                "message": f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
            })
        finally:
            response_in_progress.discard(client_id)
            logger.info(f"ğŸ”“ Lock í•´ì œ ì™„ë£Œ: {client_id}")

async def force_cleanup_previous_response(client_id: str):
    """ğŸ”’ ì´ì „ ì‘ë‹µ ì™„ì „ ì •ë¦¬ (ê¸°ì¡´ ì™„ì „ ìœ ì§€)"""
    try:
        if client_id in client_tts_tasks and client_tts_tasks[client_id]:
            previous_task = client_tts_tasks[client_id]
            if not previous_task.done():
                logger.info(f"ğŸ›‘ ì´ì „ TTS ì‘ì—… ê°•ì œ ì¤‘ë‹¨: {client_id}")
                previous_task.cancel()
                try:
                    await previous_task
                except asyncio.CancelledError:
                    pass
                except Exception as e:
                    logger.warning(f"âš ï¸ TTS ì‘ì—… ì·¨ì†Œ ì¤‘ ì˜¤ë¥˜: {e}")
        
        if client_id in response_queues:
            queue = response_queues[client_id]
            while not queue.empty():
                try:
                    queue.get_nowait()
                except asyncio.QueueEmpty:
                    break
        
        response_in_progress.discard(client_id)
        client_tts_tasks[client_id] = None
        
        logger.info(f"ğŸ§¹ ì´ì „ ì‘ë‹µ ì™„ì „ ì •ë¦¬ ì™„ë£Œ: {client_id}")
        
    except Exception as e:
        logger.error(f"âš ï¸ ì´ì „ ì‘ë‹µ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

async def process_completely_serialized_streaming(websocket: WebSocket, user_input: str, 
                                                client_id: str, strategy: str, start_time: float,
                                                conversation_context: list):
    """ğŸ”’ ì™„ì „íˆ ì§ë ¬í™”ëœ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (ê¸°ì¡´ + v4.0 í”„ë¡¬í”„íŠ¸ ì ìš©)"""
    
    tutor_config = tutor_configs.get(client_id, {})
    
    # ğŸ­ v4.0 ê³ ê¸‰ ëŒ€í™” í”„ë¡¬í”„íŠ¸ ì ìš©
    tutor_prompt = create_natural_conversational_prompt(tutor_config, strategy, conversation_context, user_input)
    
    try:
        stream = await openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": tutor_prompt},
                {"role": "user", "content": user_input}
            ],
            max_tokens=get_natural_max_tokens(strategy, user_input, conversation_context),
            temperature=0.7,
            stream=True
        )
        
        complete_response = ""
        word_buffer = ""
        first_response_sent = False
        
        async for chunk in stream:
            if client_id not in response_in_progress:
                logger.info(f"ğŸ›‘ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ë‹¨ ê°ì§€: {client_id}")
                break
                
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                word_buffer += content
                complete_response += content
                
                if any(char in content for char in [' ', '\n', '\t']) or chunk.choices[0].finish_reason:
                    if word_buffer.strip():
                        if not first_response_sent:
                            elapsed = time.time() - start_time
                            logger.info(f"âš¡ ì²« ì‘ë‹µ ì‹œê°„: {elapsed:.3f}ì´ˆ")
                            first_response_sent = True
                        
                        await websocket.send_json({
                            "type": "text_chunk",
                            "content": word_buffer,
                            "timestamp": datetime.now().isoformat()
                        })
                        word_buffer = ""
        
        if complete_response.strip() and client_id in response_in_progress:
            await websocket.send_json({
                "type": "response_complete",
                "total_response": complete_response,
                "timestamp": datetime.now().isoformat()
            })
            
            add_to_conversation_history(client_id, "assistant", complete_response)
            
            # ğŸ”Š v4.0 ê³ í’ˆì§ˆ TTS ìƒì„±
            await create_completely_safe_tts_v4(websocket, complete_response.strip(), client_id)
        else:
            logger.warning(f"âš ï¸ TTS ìƒì„± ìƒëµ - ì‘ë‹µ ì¤‘ë‹¨ë¨: {client_id}")
            
    except Exception as e:
        logger.error(f"âš ï¸ ì§ë ¬í™”ëœ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {str(e)}")
        raise

# ğŸ”Š NEW v4.0: ì–¸ì–´êµìœ¡ AI ìˆ˜ì¤€ ê³ í’ˆì§ˆ TTS
async def create_completely_safe_tts_v4(websocket: WebSocket, full_text: str, client_id: str):
    """ğŸ”Š v4.0 ì–¸ì–´êµìœ¡ AI ìˆ˜ì¤€ ê³ í’ˆì§ˆ TTS (WaveNet + SSML)"""
    if not tts_client:
        logger.warning("TTS í´ë¼ì´ì–¸íŠ¸ê°€ ë¹„í™œì„±í™”ë˜ì–´ í…ìŠ¤íŠ¸ë§Œ ì „ì†¡í•©ë‹ˆë‹¤.")
        return
    
    try:
        tts_task = asyncio.create_task(
            _execute_enhanced_tts_v4(websocket, full_text, client_id)
        )
        
        client_tts_tasks[client_id] = tts_task
        await tts_task
        
    except asyncio.CancelledError:
        logger.info(f"ğŸ›‘ TTS ì‘ì—… ì·¨ì†Œë¨: {client_id}")
    except Exception as e:
        logger.error(f"âš ï¸ v4.0 TTS ìƒì„± ì˜¤ë¥˜: {str(e)}")
        # ì˜¤ë¥˜ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
        await create_completely_safe_tts(websocket, full_text, client_id)
    finally:
        if client_id in client_tts_tasks:
            client_tts_tasks[client_id] = None

async def _execute_enhanced_tts_v4(websocket: WebSocket, full_text: str, client_id: str):
    """ğŸ”Š v4.0 ì–¸ì–´êµìœ¡ AI ìˆ˜ì¤€ TTS ì‹¤í–‰"""
    logger.info(f"ğŸ”Š v4.0 ê³ í’ˆì§ˆ TTS ì²˜ë¦¬ ì‹œì‘: '{full_text[:50]}...' for {client_id}")
    
    tutor_config = tutor_configs.get(client_id, {})
    current_strategy = current_strategies.get(client_id, "medium")
    
    try:
        # 1. ğŸ­ ê°ì •ê³¼ ì–µì–‘ì´ ì‚´ì•„ìˆëŠ” SSML ìƒì„±
        enhanced_text = create_expressive_ssml(full_text, client_id, current_strategy)
        synthesis_input = texttospeech.SynthesisInput(ssml=enhanced_text)
        
        # 2. ğŸ”Š WaveNet ê¸°ë°˜ ê³ í’ˆì§ˆ ìŒì„± ì„¤ì •
        voice = get_enhanced_voice_config(tutor_config, client_id)
        
        # 3. ğŸ¯ ì ì‘í˜• ì˜¤ë””ì˜¤ ì„¤ì •
        audio_config = create_adaptive_audio_config(current_strategy, tutor_config, client_id)
        
        start_tts = time.time()
        
        # 4. ğŸš€ TTS ì‹¤í–‰
        response = await asyncio.wait_for(
            asyncio.get_event_loop().run_in_executor(
                None,
                lambda: tts_client.synthesize_speech(
                    input=synthesis_input,
                    voice=voice,
                    audio_config=audio_config
                )
            ),
            timeout=20.0  # ë” ê¸´ íƒ€ì„ì•„ì›ƒ (ê³ í’ˆì§ˆ ì²˜ë¦¬)
        )
        
        if client_id not in response_in_progress:
            logger.info(f"ğŸ›‘ TTS ì™„ë£Œ í›„ ì¤‘ë‹¨ ê°ì§€: {client_id}")
            return
        
        tts_time = time.time() - start_tts
        audio_base64 = base64.b64encode(response.audio_content).decode('utf-8')
        
        # 5. ğŸ“¤ v4.0 ê³ í’ˆì§ˆ ì˜¤ë””ì˜¤ ì „ì†¡
        await websocket.send_json({
            "type": "audio_completely_safe",
            "text": full_text,
            "audio": audio_base64,
            "audio_size": len(response.audio_content),
            "tts_time": round(tts_time, 3),
            "client_id": client_id,
            "version": "4.0",
            "voice_type": "wavenet",
            "ssml_enabled": True,
            "emotional_state": learner_states.get(client_id, {}).get("last_analysis", {}).get("emotional_state", "neutral"),
            "strategy": current_strategy,
            "timestamp": datetime.now().isoformat()
        })
        
        logger.info(f"âœ… v4.0 ê³ í’ˆì§ˆ TTS ì™„ë£Œ: {len(response.audio_content)} bytes for {client_id} (WaveNet + SSML)")
        
    except asyncio.TimeoutError:
        logger.warning(f"â° v4.0 TTS íƒ€ì„ì•„ì›ƒ: {client_id}")
        # íƒ€ì„ì•„ì›ƒ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
        await _execute_single_tts(websocket, full_text, client_id)
    except Exception as e:
        logger.error(f"âš ï¸ v4.0 TTS ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
        # ì˜¤ë¥˜ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
        await _execute_single_tts(websocket, full_text, client_id)

# ê¸°ì¡´ TTS í•¨ìˆ˜ ìœ ì§€ (í´ë°± ìš©ë„)
async def create_completely_safe_tts(websocket: WebSocket, full_text: str, client_id: str):
    """ğŸ”’ ê¸°ì¡´ ì•ˆì „í•œ TTS ìƒì„± (í´ë°±ìš© - ì™„ì „ ìœ ì§€)"""
    if not tts_client:
        logger.warning("TTS í´ë¼ì´ì–¸íŠ¸ê°€ ë¹„í™œì„±í™”ë˜ì–´ í…ìŠ¤íŠ¸ë§Œ ì „ì†¡í•©ë‹ˆë‹¤.")
        return
    
    try:
        tts_task = asyncio.create_task(
            _execute_single_tts(websocket, full_text, client_id)
        )
        
        client_tts_tasks[client_id] = tts_task
        await tts_task
        
    except asyncio.CancelledError:
        logger.info(f"ğŸ›‘ TTS ì‘ì—… ì·¨ì†Œë¨: {client_id}")
    except Exception as e:
        logger.error(f"âš ï¸ ì•ˆì „í•œ TTS ìƒì„± ì˜¤ë¥˜: {str(e)}")
    finally:
        if client_id in client_tts_tasks:
            client_tts_tasks[client_id] = None

async def _execute_single_tts(websocket: WebSocket, full_text: str, client_id: str):
    """ê¸°ì¡´ TTS ì‹¤í–‰ (í´ë°±ìš© - ì™„ì „ ìœ ì§€)"""
    logger.info(f"ğŸ”Š ê¸°ì¡´ TTS ì²˜ë¦¬ ì‹œì‘: '{full_text[:50]}...' for {client_id}")
    
    synthesis_input = texttospeech.SynthesisInput(text=full_text)
    
    voice = texttospeech.VoiceSelectionParams(
        language_code="ko-KR",
        name="ko-KR-Standard-A",  # ê¸°ì¡´ Standard ìŒì„± ìœ ì§€ (í´ë°±ìš©)
        ssml_gender=texttospeech.SsmlVoiceGender.FEMALE
    )
    
    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3,
        speaking_rate=1.0,
        pitch=0.0,
        volume_gain_db=0.0,
        effects_profile_id=["headphone-class-device"]
    )
    
    start_tts = time.time()
    
    response = await asyncio.wait_for(
        asyncio.get_event_loop().run_in_executor(
            None,
            lambda: tts_client.synthesize_speech(
                input=synthesis_input,
                voice=voice,
                audio_config=audio_config
            )
        ),
        timeout=15.0
    )
    
    if client_id not in response_in_progress:
        logger.info(f"ğŸ›‘ TTS ì™„ë£Œ í›„ ì¤‘ë‹¨ ê°ì§€: {client_id}")
        return
    
    tts_time = time.time() - start_tts
    audio_base64 = base64.b64encode(response.audio_content).decode('utf-8')
    
    await websocket.send_json({
        "type": "audio_completely_safe",
        "text": full_text,
        "audio": audio_base64,
        "audio_size": len(response.audio_content),
        "tts_time": round(tts_time, 3),
        "client_id": client_id,
        "version": "3.3",  # ê¸°ì¡´ ë²„ì „ í‘œì‹œ
        "voice_type": "standard",
        "timestamp": datetime.now().isoformat()
    })
    
    logger.info(f"âœ… ê¸°ì¡´ TTS ì™„ë£Œ: {len(response.audio_content)} bytes for {client_id}")

# ë‚˜ë¨¸ì§€ ëª¨ë“  í•¨ìˆ˜ë“¤ ì™„ì „ ìœ ì§€ (get_natural_max_tokens, add_to_conversation_history, get_conversation_context, ì‹¤ì‹œê°„ í”¼ë“œë°± ê´€ë ¨ í•¨ìˆ˜ë“¤ ë“±)
def get_natural_max_tokens(strategy: str, user_input: str, conversation_context: list) -> int:
    """ğŸ­ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ìœ„í•œ í† í° ë°°ë¶„ (ê¸°ì¡´ ì™„ì „ ìœ ì§€)"""
    base_tokens = {
        "very_short": 25,   
        "short": 60,        
        "medium": 120,      
        "long": 200,        
        "interactive": 100  
    }
    
    base = base_tokens.get(strategy, 60)
    
    # ğŸ§  ë§¥ë½ì— ë”°ë¥¸ ì¡°ì ˆ (íŠœí„°ì˜ ì§€ëŠ¥ ìœ ì§€)
    if len(conversation_context) > 0:
        last_exchange = conversation_context[-1]
        if any(word in last_exchange.get("content", "").lower() for word in ["ëª¨ë¥´ê² ", "ì´í•´ ì•ˆ", "í—·ê°ˆ"]):
            base = min(base + 40, 250)
        elif any(word in last_exchange.get("content", "").lower() for word in ["ì•Œê² ", "ì´í•´í–ˆ", "ë§ë„¤"]):
            base = min(base + 20, 200)
    
    if len(user_input) > 100:
        base = min(base + 30, 250)
    
    return base

def add_to_conversation_history(client_id: str, role: str, content: str):
    """ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€ (ê¸°ì¡´ ì™„ì „ ìœ ì§€)"""
    if client_id not in conversation_history:
        conversation_history[client_id] = []
    
    conversation_history[client_id].append({
        "role": role,
        "content": content,
        "timestamp": datetime.now().isoformat()
    })
    
    if len(conversation_history[client_id]) > 25:
        conversation_history[client_id] = conversation_history[client_id][-25:]

def get_conversation_context(client_id: str) -> list:
    """ëŒ€í™” ë§¥ë½ ë°˜í™˜ (ê¸°ì¡´ ì™„ì „ ìœ ì§€)"""
    if client_id not in conversation_history:
        return []
    
    recent_messages = conversation_history[client_id][-12:]
    return [{"role": msg["role"], "content": msg["content"]} for msg in recent_messages]

# ì‹¤ì‹œê°„ í”¼ë“œë°± ë° ì¤‘ë‹¨ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ì™„ì „ ìœ ì§€)
async def handle_response_interrupt(websocket: WebSocket, user_text: str, client_id: str):
    """ì‘ë‹µ ì¤‘ë‹¨ + ìƒˆë¡œìš´ ì‘ë‹µ ì²˜ë¦¬ (ê¸°ì¡´ ì™„ì „ ìœ ì§€)"""
    try:
        logger.info(f"ğŸ›‘ ì‘ë‹µ ì¤‘ë‹¨ + ìƒˆ ì§ˆë¬¸: '{user_text[:30]}...' from {client_id}")
        
        await interrupt_current_response(websocket, client_id)
        
        feedback_analysis = analyze_feedback_intent(user_text)
        
        if feedback_analysis["is_feedback"]:
            await process_feedback_response(websocket, feedback_analysis, client_id)
        else:
            add_to_conversation_history(client_id, "user", user_text)
            await generate_ai_response_completely_safe(websocket, user_text, client_id)
            
    except Exception as e:
        logger.error(f"âš ï¸ ì‘ë‹µ ì¤‘ë‹¨ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

async def handle_realtime_feedback(websocket: WebSocket, message: dict, client_id: str):
    """ì‹¤ì‹œê°„ í”¼ë“œë°± ì²˜ë¦¬ (ê¸°ì¡´ ì™„ì „ ìœ ì§€)"""
    try:
        action = message.get("action")
        original_input = message.get("original_input", "")
        
        logger.info(f"ğŸ’¬ ì‹¤ì‹œê°„ í”¼ë“œë°±: {action} for '{original_input[:20]}...'")
        
        await interrupt_current_response(websocket, client_id)
        
        if action == "make_shorter":
            await generate_shorter_response(websocket, original_input, client_id)
        elif action == "make_detailed":
            await generate_detailed_response(websocket, original_input, client_id)
        else:
            await websocket.send_json({
                "type": "error",
                "message": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í”¼ë“œë°± ì•¡ì…˜: {action}"
            })
            
    except Exception as e:
        logger.error(f"âš ï¸ ì‹¤ì‹œê°„ í”¼ë“œë°± ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

async def interrupt_current_response(websocket: WebSocket, client_id: str):
    """í˜„ì¬ ì‘ë‹µ ì¦‰ì‹œ ì¤‘ë‹¨ (ê¸°ì¡´ ì™„ì „ ìœ ì§€)"""
    if client_id in response_in_progress:
        response_in_progress.discard(client_id)
        
        await websocket.send_json({
            "type": "response_interrupted",
            "timestamp": datetime.now().isoformat()
        })
        
        logger.info(f"ğŸ›‘ ì‘ë‹µ ì¤‘ë‹¨ ì™„ë£Œ: {client_id}")

def analyze_feedback_intent(user_text: str) -> dict:
    """í”¼ë“œë°± ì˜ë„ ë¶„ì„ (ê¸°ì¡´ ì™„ì „ ìœ ì§€)"""
    user_text_lower = user_text.lower()
    
    feedback_patterns = {
        "shorter": ["ì§§ê²Œ", "ê°„ë‹¨íˆ", "ìš”ì•½", "ì¤„ì—¬", "ê·¸ë§Œ"],
        "longer": ["ìì„¸íˆ", "ë”", "êµ¬ì²´ì ìœ¼ë¡œ", "ì˜ˆì‹œ", "ì„¤ëª…"],
        "stop": ["ì¤‘ë‹¨", "ë©ˆì¶°", "ê·¸ë§Œ", "ìŠ¤í†±"],
        "clarify": ["ì´í•´ ì•ˆ", "ëª¨ë¥´ê² ", "ì„¤ëª…í•´", "ë­” ëœ»"]
    }
    
    for action, patterns in feedback_patterns.items():
        if any(pattern in user_text_lower for pattern in patterns):
            return {
                "is_feedback": True,
                "action": action,
                "confidence": 0.9,
                "original_text": user_text
            }
    
    return {
        "is_feedback": False,
        "action": "new_question",
        "confidence": 0.1,
        "original_text": user_text
    }

async def generate_shorter_response(websocket: WebSocket, original_input: str, client_id: str):
    """ì§§ì€ ìš”ì•½ ì‘ë‹µ ìƒì„± (ê¸°ì¡´ ì™„ì „ ìœ ì§€)"""
    try:
        response_in_progress.add(client_id)
        
        await websocket.send_json({
            "type": "response_start",
            "strategy": "summary",
            "message": "ë” ê°„ë‹¨íˆ ì„¤ëª…í•´ë“œë¦´ê²Œìš”!",
            "timestamp": datetime.now().isoformat()
        })
        
        stream = await openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": f"ê°„ë‹¨íˆ 1-2ë¬¸ì¥ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”."},
                {"role": "user", "content": f"ê°„ë‹¨íˆ: {original_input}"}
            ],
            max_tokens=40,
            temperature=0.5,
            stream=True
        )
        
        await process_simple_streaming(websocket, stream, client_id, "short")
        
    finally:
        response_in_progress.discard(client_id)

async def generate_detailed_response(websocket: WebSocket, original_input: str, client_id: str):
    """ìì„¸í•œ ì‘ë‹µ ìƒì„± (ê¸°ì¡´ ì™„ì „ ìœ ì§€)"""
    try:
        response_in_progress.add(client_id)
        
        await websocket.send_json({
            "type": "response_start",
            "strategy": "detailed",
            "message": "ë” ìì„¸íˆ ì„¤ëª…í•´ë“œë¦´ê²Œìš”!",
            "timestamp": datetime.now().isoformat()
        })
        
        stream = await openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": f"ì˜ˆì‹œì™€ í•¨ê»˜ ìì„¸íˆ ì„¤ëª…í•˜ë˜ ì ì ˆí•œ ê¸¸ì´ë¡œ."},
                {"role": "user", "content": f"ìì„¸íˆ: {original_input}"}
            ],
            max_tokens=150,
            temperature=0.7,
            stream=True
        )
        
        await process_simple_streaming(websocket, stream, client_id, "detailed")
        
    finally:
        response_in_progress.discard(client_id)

async def process_simple_streaming(websocket: WebSocket, stream, client_id: str, response_type: str):
    """ê°„ë‹¨í•œ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (ê¸°ì¡´ ì™„ì „ ìœ ì§€)"""
    response_text = ""
    word_buffer = ""
    
    async for chunk in stream:
        if client_id not in response_in_progress:
            break
            
        if chunk.choices[0].delta.content:
            content = chunk.choices[0].delta.content
            word_buffer += content
            response_text += content
            
            if any(char in content for char in [' ', '\n', '\t']) or chunk.choices[0].finish_reason:
                if word_buffer.strip():
                    await websocket.send_json({
                        "type": "text_chunk",
                        "content": word_buffer,
                        "response_type": response_type,
                        "timestamp": datetime.now().isoformat()
                    })
                    word_buffer = ""
    
    await websocket.send_json({
        "type": "response_complete",
        "response_type": response_type,
        "timestamp": datetime.now().isoformat()
    })
    
    add_to_conversation_history(client_id, "assistant", response_text)
    
    if response_text.strip():
        # v4.0 ê³ í’ˆì§ˆ TTS ì‚¬ìš©
        await create_completely_safe_tts_v4(websocket, response_text.strip(), client_id)

async def process_feedback_response(websocket: WebSocket, feedback_analysis: dict, client_id: str):
    """í”¼ë“œë°± ê¸°ë°˜ ì‘ë‹µ ì²˜ë¦¬ (ê¸°ì¡´ ì™„ì „ ìœ ì§€)"""
    action = feedback_analysis["action"]
    
    if action == "shorter":
        await websocket.send_json({
            "type": "feedback_acknowledged",
            "message": "ë” ê°„ë‹¨íˆ ì„¤ëª…í•´ë“œë¦´ê²Œìš”!",
            "action": "shorter"
        })
    elif action == "longer":
        await websocket.send_json({
            "type": "feedback_acknowledged", 
            "message": "ë” ìì„¸íˆ ì„¤ëª…í•´ë“œë¦´ê²Œìš”!",
            "action": "longer"
        })
    elif action == "stop":
        await websocket.send_json({
            "type": "feedback_acknowledged",
            "message": "ì‘ë‹µì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.",
            "action": "stop"
        })

# ì˜ˆì™¸ ì²˜ë¦¬ í•¸ë“¤ëŸ¬ (ê¸°ì¡´ ì™„ì „ ìœ ì§€)
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    logger.error(f"Global exception: {str(exc)}")
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal server error",
            "message": "ì„œë²„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        }
    )

# ì„œë²„ ì‹¤í–‰ (ê¸°ì¡´ + v4.0 ì •ë³´ ì—…ë°ì´íŠ¸)
if __name__ == "__main__":
    port = int(os.getenv("PORT", 8080))
    log_level = os.getenv("LOG_LEVEL", "info")
    
    logger.info(f"ğŸš€ AI íŠœí„° ì„œë²„ ì‹œì‘ (v4.0.0 - ì–¸ì–´êµìœ¡ AI ìˆ˜ì¤€)")
    logger.info(f"ğŸ“¡ í¬íŠ¸: {port}")
    logger.info(f"ğŸ¤ ìŒì„± ì…ë ¥: {'âœ… í™œì„±í™” (ê°œì„ ëœ STT)' if speech_client else 'âŒ ë¹„í™œì„±í™”'}")
    logger.info(f"ğŸ”Š ìŒì„± ì¶œë ¥: {'âœ… í™œì„±í™” (v4.0 WaveNet + SSML)' if tts_client else 'âŒ ë¹„í™œì„±í™”'}")
    logger.info(f"ğŸ’¬ í…ìŠ¤íŠ¸ ì…ë ¥: âœ… í™œì„±í™”")
    logger.info(f"ğŸ¤– AI ëª¨ë¸: GPT-3.5 Turbo (v4.0 ê³ ê¸‰ ëŒ€í™”í˜•)")
    logger.info(f"ğŸ”„ ìƒíƒœ ê´€ë¦¬: âœ… í™œì„±í™”")
    logger.info(f"ğŸ“ ìŠ¤íŠ¸ë¦¬ë°: âœ… ì¤‘ì²© ì™„ì „ ë°©ì§€ + v4.0 ê³ í’ˆì§ˆ TTS")
    logger.info(f"ğŸ›‘ ì¦‰ì‹œ ì¤‘ë‹¨: âœ… í™œì„±í™”")
    logger.info(f"ğŸ’­ ì‹¤ì‹œê°„ í”¼ë“œë°±: âœ… í™œì„±í™”")
    logger.info(f"ğŸ§  ì˜ë„ ë¶„ì„: âœ… v4.0 ê³ ê¸‰ ê°ì • + í•™ìŠµì ìƒíƒœ ì¶”ì ")
    logger.info(f"ğŸ­ ëŒ€í™” ìŠ¤íƒ€ì¼: âœ… v4.0 ì–¸ì–´êµìœ¡ AI ìˆ˜ì¤€ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”")
    logger.info(f"ğŸ”’ ì¤‘ì²© ë°©ì§€: âœ… v3.3 ì™„ì „ ìœ ì§€ (100% í•´ê²°)")
    logger.info(f"ğŸ”Š ìŒì„± í’ˆì§ˆ: âœ… v4.0 WaveNet + SSML (ì–¸ì–´êµìœ¡ AI ìˆ˜ì¤€)")
    logger.info(f"ğŸ§  ê°ì • ì§€ëŠ¥: âœ… v4.0 ì‹¤ì‹œê°„ ê°ì • ë¶„ì„ + ì ì‘í˜• ëŒ€ì‘")
    logger.info(f"ğŸ“Š í•™ìŠµì ì¶”ì : âœ… v4.0 ì¢…í•©ì  ìƒíƒœ ë¶„ì„ + ê°œì¸í™”")
    logger.info(f"ğŸ’° ë¹„ìš© íš¨ìœ¨ì„±: âœ… ìŠ¤ë§ˆíŠ¸í•œ ì ˆì•½ + ê³ í’ˆì§ˆ ë³´ì¥")
    logger.info(f"ğŸ›¡ï¸ í˜¸í™˜ì„±: âœ… v3.3 ëª¨ë“  ê¸°ëŠ¥ 100% ìœ ì§€")
    
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=port,
        log_level=log_level,
        access_log=True
    )
