#!/usr/bin/env python3
"""
AI íŠœí„° FastAPI ë°±ì—”ë“œ ì• í”Œë¦¬ì¼€ì´ì…˜

ì™„ì „í•œ ì‹¤ì‹œê°„ AI íŠœí„° ì‹œìŠ¤í…œ ë°±ì—”ë“œì…ë‹ˆë‹¤.
- ìŒì„± ì…ë ¥ (STT) + í…ìŠ¤íŠ¸ ì…ë ¥ ì§€ì›
- ì‹¤ì‹œê°„ WebSocket í†µì‹ 
- GPT-3.5 Turbo ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
- Google TTS ìŒì„± ì¶œë ¥
- ìŒì„± ì¤‘ì²© ë¬¸ì œ í•´ê²°
- íŠœí„° ê°œì„±í™” ì‹œìŠ¤í…œ
- ëŒ€í™” ìƒíƒœ ê´€ë¦¬ ë° ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤íŠ¸ë¦¬ë°
"""

import asyncio
import base64
import json
import os
import tempfile
import uuid
from datetime import datetime
from typing import Dict, Any, Optional
import logging

import uvicorn
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from openai import AsyncOpenAI
from google.cloud import texttospeech
from google.cloud import speech
import httpx

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="AI Tutor Realtime System",
    description="ì‹¤ì‹œê°„ AI íŠœí„° ì‹œìŠ¤í…œ - ìŒì„± ë° í…ìŠ¤íŠ¸ ì…ë ¥ ì§€ì›",
    version="2.1.1",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://*.streamlit.app",
        "https://*.streamlit.io", 
        "http://localhost:8501",
        "http://localhost:3000",
        "http://localhost:8080",
        "*"  # ê°œë°œ í™˜ê²½ìš©
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    logger.error("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)

try:
    tts_client = texttospeech.TextToSpeechClient()
    logger.info("Google TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
except Exception as e:
    logger.error(f"Google TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    tts_client = None

try:
    speech_client = speech.SpeechClient()
    logger.info("Google STT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
except Exception as e:
    logger.error(f"Google STT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    speech_client = None

# ì „ì—­ ë³€ìˆ˜
active_connections: Dict[str, WebSocket] = {}
tutor_configs: Dict[str, Dict[str, Any]] = {}
response_in_progress: set = set()  # ì‘ë‹µ ìƒíƒœ ê´€ë¦¬

# ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸ë“¤
@app.get("/")
async def root():
    """ë©”ì¸ í˜ì´ì§€ - ì‹œìŠ¤í…œ ì •ë³´"""
    return {
        "message": "ğŸ“ AI Tutor Realtime System",
        "version": "2.1.1",
        "status": "running",
        "features": [
            "ìŒì„± ì…ë ¥ (STT)",
            "í…ìŠ¤íŠ¸ ì…ë ¥", 
            "ìŒì„± ì¶œë ¥ (TTS)",
            "ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°",
            "íŠœí„° ê°œì„±í™”",
            "ë‹¤ì¤‘ ì…ë ¥ ë°©ì‹",
            "ëŒ€í™” ìƒíƒœ ê´€ë¦¬",
            "ìì—°ìŠ¤ëŸ¬ìš´ ì²­í‚¹"
        ],
        "config": "ì„±ëŠ¥ê³¼ ë¹„ìš© ê· í˜• êµ¬ì„±",
        "endpoints": {
            "websocket": "/ws/tutor/{client_id}",
            "health": "/health",
            "info": "/info",
            "docs": "/docs"
        },
        "timestamp": datetime.now().isoformat()
    }

@app.get("/health")
async def health_check():
    """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    try:
        # OpenAI API ìƒíƒœ í™•ì¸
        openai_status = "âœ… ì—°ê²°ë¨" if OPENAI_API_KEY else "âŒ API í‚¤ ì—†ìŒ"
        
        # Google TTS ìƒíƒœ í™•ì¸
        tts_status = "âŒ ë¹„í™œì„±í™”"
        if tts_client:
            try:
                voices = tts_client.list_voices()
                tts_status = f"âœ… í™œì„±í™” ({len(voices.voices)}ê°œ ìŒì„±)"
            except Exception as e:
                tts_status = f"âš ï¸ ì˜¤ë¥˜: {str(e)[:50]}"
        
        # Google STT ìƒíƒœ í™•ì¸
        stt_status = "âœ… í™œì„±í™”" if speech_client else "âŒ ë¹„í™œì„±í™”"
        
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "active_connections": len(active_connections),
            "active_tutors": len(tutor_configs),
            "active_responses": len(response_in_progress),
            "services": {
                "openai_gpt": openai_status,
                "google_tts": tts_status,
                "google_stt": stt_status
            },
            "system": {
                "python_version": f"{os.sys.version_info.major}.{os.sys.version_info.minor}.{os.sys.version_info.micro}",
                "environment": os.getenv("ENVIRONMENT", "production")
            }
        }
    except Exception as e:
        logger.error(f"Health check ì˜¤ë¥˜: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "status": "unhealthy", 
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
        )

@app.get("/info")
async def system_info():
    """ìƒì„¸ ì‹œìŠ¤í…œ ì •ë³´"""
    return {
        "system": "AI Tutor Realtime System",
        "version": "2.1.1",
        "architecture": "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜",
        "deployment": "Google Cloud Run",
        "input_methods": {
            "voice": {
                "engine": "Google Cloud Speech-to-Text",
                "supported_formats": ["WEBM_OPUS", "OGG_OPUS"],
                "languages": ["ko-KR", "en-US"],
                "features": ["ìë™ êµ¬ë‘ì ", "ì‹ ë¢°ë„ ì ìˆ˜", "ë‹¤ì¤‘ ì„¤ì • ì‹œë„"]
            },
            "text": {
                "method": "WebSocket ì‹¤ì‹œê°„ ì „ì†¡",
                "encoding": "UTF-8",
                "max_length": "10000ì"
            }
        },
        "output_methods": {
            "text": {
                "streaming": True,
                "real_time": True,
                "format": "ìì—°ìŠ¤ëŸ¬ìš´ ë‹¨ì–´ ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°"
            },
            "voice": {
                "engine": "Google Cloud Text-to-Speech",
                "voice": "ko-KR-Standard-A",
                "format": "MP3",
                "features": ["ë‹¨ì¼ ì˜¤ë””ì˜¤ ì¶œë ¥", "ì¤‘ì²© ë°©ì§€"]
            }
        },
        "ai_model": {
            "provider": "OpenAI",
            "model": "GPT-3.5 Turbo",
            "streaming": True,
            "max_tokens": 300,
            "temperature": 0.7
        },
        "communication": {
            "protocol": "WebSocket",
            "real_time": True,
            "auto_reconnect": True,
            "timeout": "60ì´ˆ"
        },
        "tutor_system": {
            "personalization": True,
            "personality_traits": [
                "ì¹œê·¼í•¨", "ìœ ë¨¸ ìˆ˜ì¤€", "ê²©ë ¤ ìˆ˜ì¤€", 
                "ì„¤ëª… ìƒì„¸ë„", "ìƒí˜¸ì‘ìš© ë¹ˆë„"
            ],
            "subjects": "ë¬´ì œí•œ",
            "education_levels": ["ì¤‘í•™êµ", "ê³ ë“±í•™êµ", "ëŒ€í•™êµ", "ëŒ€í•™ì›"]
        }
    }

@app.get("/stats")
async def get_statistics():
    """ì‹¤ì‹œê°„ í†µê³„"""
    return {
        "connections": {
            "active": len(active_connections),
            "total_connected": len(active_connections)
        },
        "tutors": {
            "active": len(tutor_configs),
            "configurations": list(tutor_configs.keys())
        },
        "responses": {
            "in_progress": len(response_in_progress),
            "active_clients": list(response_in_progress)
        },
        "timestamp": datetime.now().isoformat()
    }

# WebSocket ì—”ë“œí¬ì¸íŠ¸
@app.websocket("/ws/tutor/{client_id}")
async def websocket_endpoint(websocket: WebSocket, client_id: str):
    """ë©”ì¸ WebSocket ì—”ë“œí¬ì¸íŠ¸"""
    await websocket.accept()
    active_connections[client_id] = websocket
    logger.info(f"âœ… í´ë¼ì´ì–¸íŠ¸ {client_id} ì—°ê²°ë¨")
    
    try:
        # ì—°ê²° í™•ì¸ ë©”ì‹œì§€ ì „ì†¡
        await websocket.send_json({
            "type": "connection_established",
            "message": "ğŸ“ AI íŠœí„°ì™€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤! (ìŒì„± + í…ìŠ¤íŠ¸ ì§€ì›)",
            "client_id": client_id,
            "timestamp": datetime.now().isoformat(),
            "features": ["voice_input", "text_input", "voice_output", "real_time_streaming", "state_management"]
        })
        
        # ë©”ì¸ ë©”ì‹œì§€ ë£¨í”„
        while True:
            try:
                data = await asyncio.wait_for(websocket.receive(), timeout=60.0)
                
                if data["type"] == "websocket.disconnect":
                    logger.info(f"âŒ í´ë¼ì´ì–¸íŠ¸ {client_id} ì •ìƒ ì—°ê²° ì¢…ë£Œ")
                    break
                
                # JSON ë©”ì‹œì§€ ì²˜ë¦¬
                if data["type"] == "websocket.receive" and "text" in data:
                    try:
                        message = json.loads(data["text"])
                        await handle_text_message(websocket, message, client_id)
                    except json.JSONDecodeError as e:
                        logger.error(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {data['text'][:100]} | {e}")
                        await websocket.send_json({
                            "type": "error",
                            "message": "ë©”ì‹œì§€ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."
                        })
                
                # ë°”ì´ë„ˆë¦¬ ë©”ì‹œì§€ (ì˜¤ë””ì˜¤) ì²˜ë¦¬
                elif data["type"] == "websocket.receive" and "bytes" in data:
                    audio_data = data["bytes"]
                    await handle_audio_message(websocket, audio_data, client_id)
                    
            except asyncio.TimeoutError:
                # ì—°ê²° ìƒíƒœ í™•ì¸ (í•‘)
                try:
                    await websocket.send_json({
                        "type": "ping",
                        "timestamp": datetime.now().isoformat()
                    })
                except:
                    logger.warning(f"í´ë¼ì´ì–¸íŠ¸ {client_id} í•‘ ì‹¤íŒ¨ - ì—°ê²° ì¢…ë£Œ")
                    break
                
    except WebSocketDisconnect:
        logger.info(f"âŒ í´ë¼ì´ì–¸íŠ¸ {client_id} ì—°ê²° ëŠê¹€ (ì •ìƒ)")
    except Exception as e:
        logger.error(f"âš ï¸ WebSocket ì—ëŸ¬ {client_id}: {str(e)}")
    finally:
        # ì—°ê²° ì •ë¦¬
        if client_id in active_connections:
            del active_connections[client_id]
        if client_id in tutor_configs:
            del tutor_configs[client_id]
        response_in_progress.discard(client_id)
        logger.info(f"ğŸ”„ í´ë¼ì´ì–¸íŠ¸ {client_id} ì •ë¦¬ ì™„ë£Œ")

async def handle_text_message(websocket: WebSocket, message: dict, client_id: str):
    """í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬"""
    try:
        message_type = message.get("type")
        logger.info(f"ğŸ“¨ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ìˆ˜ì‹ : {message_type} from {client_id}")
        
        if message_type == "config_update":
            # íŠœí„° ì„¤ì • ì—…ë°ì´íŠ¸
            config = message.get("config", {})
            
            # ê¸°ë³¸ voice_settings ì¶”ê°€
            if "voice_settings" not in config:
                config["voice_settings"] = {
                    "auto_play": True,
                    "speed": 1.0,
                    "pitch": 1.0
                }
            
            tutor_configs[client_id] = config
            logger.info(f"ğŸ“‹ íŠœí„° ì„¤ì • ì—…ë°ì´íŠ¸: {config.get('name', 'Unknown')} ({config.get('subject', 'Unknown')})")
            
            await websocket.send_json({
                "type": "config_updated",
                "message": "íŠœí„° ì„¤ì •ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "config_summary": {
                    "name": config.get("name"),
                    "subject": config.get("subject"),
                    "level": config.get("level")
                }
            })
            
        elif message_type == "user_text":
            # ì‘ë‹µ ì§„í–‰ ì¤‘ ì²´í¬
            if client_id in response_in_progress:
                await websocket.send_json({
                    "type": "error",
                    "message": "ì´ì „ ì‘ë‹µì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."
                })
                return
            
            # ì‚¬ìš©ì í…ìŠ¤íŠ¸ ì…ë ¥ ì²˜ë¦¬
            user_text = message.get("text", "").strip()
            
            if not user_text:
                await websocket.send_json({
                    "type": "error",
                    "message": "í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
                })
                return
            
            if len(user_text) > 10000:
                await websocket.send_json({
                    "type": "error",
                    "message": "í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. 10,000ì ì´í•˜ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”."
                })
                return
            
            logger.info(f"ğŸ’¬ ì‚¬ìš©ì í…ìŠ¤íŠ¸ ì…ë ¥: '{user_text[:50]}...' from {client_id}")
            
            # AI ì‘ë‹µ ìƒì„±
            await generate_ai_response(websocket, user_text, client_id)
            
        elif message_type == "ping":
            # í•‘ ì‘ë‹µ
            await websocket.send_json({
                "type": "pong",
                "timestamp": datetime.now().isoformat()
            })
            
        else:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì‹œì§€ íƒ€ì…: {message_type}")
            await websocket.send_json({
                "type": "error",
                "message": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë©”ì‹œì§€ íƒ€ì…: {message_type}"
            })
            
    except Exception as e:
        logger.error(f"âš ï¸ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜ {client_id}: {str(e)}")
        await websocket.send_json({
            "type": "error",
            "message": f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        })

async def handle_audio_message(websocket: WebSocket, audio_data: bytes, client_id: str):
    """ì˜¤ë””ì˜¤ ë©”ì‹œì§€ ì²˜ë¦¬"""
    try:
        # ì‘ë‹µ ì§„í–‰ ì¤‘ ì²´í¬
        if client_id in response_in_progress:
            await websocket.send_json({
                "type": "error",
                "message": "ì´ì „ ì‘ë‹µì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."
            })
            return
        
        logger.info(f"ğŸ¤ ì˜¤ë””ì˜¤ ìˆ˜ì‹ : {len(audio_data)} bytes from {client_id}")
        
        # ì˜¤ë””ì˜¤ í¬ê¸° ê²€ì¦
        if len(audio_data) < 1000:
            await websocket.send_json({
                "type": "error", 
                "message": "ë…¹ìŒì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ì¡°ê¸ˆ ë” ê¸¸ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”."
            })
            return
        
        if len(audio_data) > 10 * 1024 * 1024:  # 10MB
            await websocket.send_json({
                "type": "error", 
                "message": "ë…¹ìŒì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ì§§ê²Œ ë‚˜ëˆ„ì–´ì„œ ë§ì”€í•´ì£¼ì„¸ìš”."
            })
            return
        
        # STT ì²˜ë¦¬
        transcript = await process_speech_to_text(audio_data)
        logger.info(f"ğŸ”¤ STT ê²°ê³¼: '{transcript}' from {client_id}")
        
        if not transcript or transcript.strip() == "":
            await websocket.send_json({
                "type": "error", 
                "message": "ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤. ëª…í™•í•˜ê²Œ ë§ì”€í•´ì£¼ì‹œê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            })
            return
        
        # STT ê²°ê³¼ ì „ì†¡
        await websocket.send_json({
            "type": "stt_result",
            "text": transcript,
            "timestamp": datetime.now().isoformat()
        })
        
        # AI ì‘ë‹µ ìƒì„±
        await generate_ai_response(websocket, transcript, client_id)
        
    except Exception as e:
        logger.error(f"âš ï¸ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜ {client_id}: {str(e)}")
        await websocket.send_json({
            "type": "error",
            "message": f"ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        })

async def process_speech_to_text(audio_data: bytes) -> str:
    """Google Speech-to-Text ì²˜ë¦¬"""
    if not speech_client:
        logger.error("STT í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return ""
    
    try:
        logger.info(f"ğŸ¤ STT ì²˜ë¦¬ ì‹œì‘: {len(audio_data)} bytes")
        
        # ë‹¤ì–‘í•œ STT ì„¤ì • (ìš°ì„ ìˆœìœ„ë³„)
        configs_to_try = [
            {
                "encoding": speech.RecognitionConfig.AudioEncoding.WEBM_OPUS,
                "sample_rate_hertz": 48000,
                "description": "WEBM_OPUS 48kHz"
            },
            {
                "encoding": speech.RecognitionConfig.AudioEncoding.WEBM_OPUS,
                "sample_rate_hertz": 16000,
                "description": "WEBM_OPUS 16kHz"
            },
            {
                "encoding": speech.RecognitionConfig.AudioEncoding.OGG_OPUS,
                "sample_rate_hertz": 48000,
                "description": "OGG_OPUS 48kHz"
            },
            {
                "encoding": speech.RecognitionConfig.AudioEncoding.ENCODING_UNSPECIFIED,
                "sample_rate_hertz": 48000,
                "description": "AUTO_DETECT"
            }
        ]
        
        for i, config_params in enumerate(configs_to_try):
            try:
                logger.info(f"ğŸ”„ STT ì‹œë„ {i+1}/4: {config_params['description']}")
                
                config = speech.RecognitionConfig(
                    encoding=config_params["encoding"],
                    sample_rate_hertz=config_params["sample_rate_hertz"],
                    language_code="ko-KR",
                    enable_automatic_punctuation=True,
                    model="latest_short",
                    enable_word_confidence=True,
                    use_enhanced=True,
                    alternative_language_codes=["en-US"]
                )
                
                audio = speech.RecognitionAudio(content=audio_data)
                
                # STT ìš”ì²­ (íƒ€ì„ì•„ì›ƒ 10ì´ˆ)
                response = await asyncio.wait_for(
                    asyncio.get_event_loop().run_in_executor(
                        None, 
                        lambda: speech_client.recognize(config=config, audio=audio)
                    ),
                    timeout=10.0
                )
                
                if response.results and len(response.results) > 0:
                    transcript = response.results[0].alternatives[0].transcript
                    confidence = response.results[0].alternatives[0].confidence
                    
                    logger.info(f"âœ… STT ì„±ê³µ: '{transcript}' (ì‹ ë¢°ë„: {confidence:.2f})")
                    
                    # ì‹ ë¢°ë„ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ë‹¤ìŒ ì„¤ì • ì‹œë„
                    if confidence < 0.3:
                        logger.warning(f"âš ï¸ ì‹ ë¢°ë„ ë‚®ìŒ ({confidence:.2f}), ë‹¤ìŒ ì„¤ì • ì‹œë„")
                        continue
                    
                    return transcript.strip()
                else:
                    logger.warning(f"âš ï¸ STT ê²°ê³¼ ì—†ìŒ: {config_params['description']}")
                    
            except asyncio.TimeoutError:
                logger.warning(f"â° STT íƒ€ì„ì•„ì›ƒ: {config_params['description']}")
                continue
            except Exception as e:
                logger.error(f"âš ï¸ STT ì„¤ì • {i+1} ì‹¤íŒ¨: {str(e)}")
                continue
        
        logger.error("âŒ ëª¨ë“  STT ì„¤ì • ì‹¤íŒ¨")
        return ""
        
    except Exception as e:
        logger.error(f"âš ï¸ STT ì „ì²´ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return ""

async def generate_ai_response(websocket: WebSocket, user_input: str, client_id: str):
    """AI ì‘ë‹µ ìƒì„± - ì¶©ëŒ ì—†ëŠ” ê°œì„ ëœ ìŠ¤íŠ¸ë¦¬ë°"""
    try:
        # ì‘ë‹µ ìƒíƒœ ì²´í¬
        if client_id in response_in_progress:
            logger.warning(f"ì‘ë‹µ ì§„í–‰ ì¤‘ - ìƒˆ ìš”ì²­ ë¬´ì‹œ: {client_id}")
            await websocket.send_json({
                "type": "error",
                "message": "ì´ì „ ì‘ë‹µì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            })
            return
        
        # ì‘ë‹µ ìƒíƒœ ì„¤ì •
        response_in_progress.add(client_id)
        
        try:
            tutor_config = tutor_configs.get(client_id, {})
            tutor_prompt = create_tutor_prompt(tutor_config, user_input)
            
            logger.info(f"ğŸ¤– AI ì‘ë‹µ ìƒì„± ì‹œì‘: '{user_input[:30]}...' for {tutor_config.get('name', 'Unknown')}")
            
            # ì‘ë‹µ ì‹œì‘ ì•Œë¦¼
            await websocket.send_json({
                "type": "response_start",
                "timestamp": datetime.now().isoformat()
            })
            
            # GPT ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­
            stream = await openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": tutor_prompt},
                    {"role": "user", "content": user_input}
                ],
                max_tokens=300,
                temperature=0.7,
                stream=True
            )
            
            response_text = ""
            word_buffer = ""
            
            # ê°œì„ ëœ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (ë‹¨ì–´ ë‹¨ìœ„)
            async for chunk in stream:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    response_text += content
                    word_buffer += content
                    
                    # ë‹¨ì–´ ë‹¨ìœ„ë¡œ ì „ì†¡ (ê³µë°±ì´ë‚˜ êµ¬ë‘ì ì—ì„œ)
                    if any(char in content for char in [' ', '\n', '\t']) or chunk.choices[0].finish_reason:
                        if word_buffer.strip():
                            await websocket.send_json({
                                "type": "text_chunk",
                                "content": word_buffer,
                                "timestamp": datetime.now().isoformat()
                            })
                            word_buffer = ""
                            # ìì—°ìŠ¤ëŸ¬ìš´ íƒ€ì´í•‘ íš¨ê³¼
                            await asyncio.sleep(0.05)
            
            # ë‚¨ì€ í…ìŠ¤íŠ¸ ì „ì†¡
            if word_buffer.strip():
                await websocket.send_json({
                    "type": "text_chunk",
                    "content": word_buffer,
                    "timestamp": datetime.now().isoformat()
                })
            
            # ì‘ë‹µ ì™„ë£Œ ì•Œë¦¼
            await websocket.send_json({
                "type": "response_complete",
                "total_length": len(response_text),
                "timestamp": datetime.now().isoformat()
            })
            
            # ì „ì²´ ì‘ë‹µ ì™„ë£Œ í›„ TTS ì²˜ë¦¬
            if response_text.strip():
                logger.info(f"ğŸ’¬ ì‘ë‹µ ì™„ë£Œ ({len(response_text)}ì), TTS ì²˜ë¦¬ ì‹œì‘")
                await process_and_send_tts(websocket, response_text.strip())
            
            logger.info(f"âœ… AI ì‘ë‹µ ì²˜ë¦¬ ì™„ë£Œ: {client_id}")
            
        finally:
            # ì‘ë‹µ ìƒíƒœ í•´ì œ
            response_in_progress.discard(client_id)
        
    except Exception as e:
        # ì—ëŸ¬ ì‹œì—ë„ ìƒíƒœ í•´ì œ
        response_in_progress.discard(client_id)
        logger.error(f"âš ï¸ AI ì‘ë‹µ ìƒì„± ì˜¤ë¥˜ {client_id}: {str(e)}")
        await websocket.send_json({
            "type": "error",
            "message": f"AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "timestamp": datetime.now().isoformat()
        })

def create_tutor_prompt(tutor_config: dict, user_input: str) -> str:
    """íŠœí„° ì„¤ì • ê¸°ë°˜ ê°œì¸í™” í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    # ê¸°ë³¸ ì •ë³´
    name = tutor_config.get("name", "AI íŠœí„°")
    subject = tutor_config.get("subject", "ì¼ë°˜")
    level = tutor_config.get("level", "ì¤‘í•™êµ")
    
    # ì„±ê²© ì„¤ì •
    personality = tutor_config.get("personality", {})
    friendliness = personality.get("friendliness", 70)
    humor_level = personality.get("humor_level", 30)
    encouragement = personality.get("encouragement", 80)
    explanation_detail = personality.get("explanation_detail", 70)
    
    # ì„±ê²© ê¸°ë°˜ ì§€ì‹œì‚¬í•­ ìƒì„±
    personality_instructions = []
    
    if friendliness >= 80:
        personality_instructions.append("ë§¤ìš° ì¹œê·¼í•˜ê³  ë‹¤ì •í•œ ë§íˆ¬ë¡œ ëŒ€í™”í•˜ì„¸ìš”.")
    elif friendliness >= 60:
        personality_instructions.append("ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ ë§íˆ¬ë¡œ ëŒ€í™”í•˜ì„¸ìš”.")
    else:
        personality_instructions.append("ì •ì¤‘í•˜ê³  ì°¨ë¶„í•œ ë§íˆ¬ë¡œ ëŒ€í™”í•˜ì„¸ìš”.")
    
    if humor_level >= 70:
        personality_instructions.append("ì ì ˆí•œ ìœ ë¨¸ì™€ ì¬ë¯¸ìˆëŠ” ë¹„ìœ ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
    elif humor_level >= 40:
        personality_instructions.append("ê°€ë” ìœ ë¨¸ë¥¼ ì„ì–´ì„œ ëŒ€í™”í•˜ì„¸ìš”.")
    
    if encouragement >= 80:
        personality_instructions.append("í•™ìƒì„ ì ê·¹ì ìœ¼ë¡œ ê²©ë ¤í•˜ê³  ì¹­ì°¬í•˜ì„¸ìš”.")
    elif encouragement >= 60:
        personality_instructions.append("í•™ìƒì„ ê²©ë ¤í•˜ëŠ” ë§ì„ í•´ì£¼ì„¸ìš”.")
    
    if explanation_detail >= 80:
        personality_instructions.append("ë§¤ìš° ìƒì„¸í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.")
    elif explanation_detail >= 60:
        personality_instructions.append("ì ì ˆí•œ ìˆ˜ì¤€ìœ¼ë¡œ ìì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”.")
    else:
        personality_instructions.append("ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.")
    
    # ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""ë‹¹ì‹ ì€ {name}ì´ë¼ëŠ” {subject} ì „ë¬¸ ì„ ìƒë‹˜ì…ë‹ˆë‹¤.
{level} ìˆ˜ì¤€ì˜ í•™ìƒë“¤ì„ ê°€ë¥´ì¹˜ëŠ” ê²½í—˜ì´ í’ë¶€í•œ êµìœ¡ìì…ë‹ˆë‹¤.

ì„±ê²© íŠ¹ì„±:
- ì¹œê·¼í•¨: {friendliness}%
- ìœ ë¨¸ ìˆ˜ì¤€: {humor_level}%
- ê²©ë ¤ ìˆ˜ì¤€: {encouragement}%
- ì„¤ëª… ìƒì„¸ë„: {explanation_detail}%

êµìœ¡ ì§€ì¹¨:
{chr(10).join(f"- {instruction}" for instruction in personality_instructions)}

ê¸°ë³¸ ê·œì¹™:
- í•­ìƒ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
- í•™ìƒì˜ ìˆ˜ì¤€({level})ì— ë§ì¶° ì„¤ëª…í•˜ì„¸ìš”.
- {subject} ë¶„ì•¼ì— ëŒ€í•œ ì „ë¬¸ ì§€ì‹ì„ í™œìš©í•˜ì„¸ìš”.
- ì§ˆë¬¸ì´ {subject}ì™€ ê´€ë ¨ ì—†ë‹¤ë©´ {subject}ì™€ ì—°ê´€ì§€ì–´ ì„¤ëª…í•´ë³´ì„¸ìš”.
- ë‹µë³€ì€ 300ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ í•´ì£¼ì„¸ìš”.
- ìì—°ìŠ¤ëŸ½ê³  ëŒ€í™”í•˜ëŠ” ë“¯í•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
- í•™ìƒì˜ ì´í•´ë„ë¥¼ í™•ì¸í•˜ê³  ì¶”ê°€ ì§ˆë¬¸ì„ ìœ ë„í•˜ì„¸ìš”.

í˜„ì¬ í•™ìƒì˜ ì§ˆë¬¸ì´ë‚˜ ìš”ì²­ì— ëŒ€í•´ ìœ„ íŠ¹ì„±ì„ ëª¨ë‘ ë°˜ì˜í•˜ì—¬ êµìœ¡ì ì´ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ í•´ì£¼ì„¸ìš”."""
    
    return prompt

async def process_and_send_tts(websocket: WebSocket, text: str):
    """TTS ì²˜ë¦¬ ë° ì „ì†¡"""
    if not tts_client:
        logger.warning("TTS í´ë¼ì´ì–¸íŠ¸ê°€ ë¹„í™œì„±í™”ë˜ì–´ í…ìŠ¤íŠ¸ë§Œ ì „ì†¡í•©ë‹ˆë‹¤.")
        await websocket.send_json({
            "type": "text_chunk",
            "content": text
        })
        return
    
    try:
        logger.info(f"ğŸ”Š TTS ì²˜ë¦¬ ì‹œì‘: {text[:30]}... ({len(text)}ì)")
        
        # TTS ì„¤ì •
        synthesis_input = texttospeech.SynthesisInput(text=text)
        
        voice = texttospeech.VoiceSelectionParams(
            language_code="ko-KR",
            name="ko-KR-Standard-A",
            ssml_gender=texttospeech.SsmlVoiceGender.FEMALE
        )
        
        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.MP3,
            speaking_rate=1.0,
            pitch=0.0
        )
        
        # TTS ìš”ì²­
        response = tts_client.synthesize_speech(
            input=synthesis_input,
            voice=voice,
            audio_config=audio_config
        )
        
        # Base64 ì¸ì½”ë”©
        audio_base64 = base64.b64encode(response.audio_content).decode('utf-8')
        
        # ë‹¨ì¼ ì˜¤ë””ì˜¤ ì²­í¬ë¡œ ì „ì†¡ (ì¤‘ì²© ë°©ì§€)
        await websocket.send_json({
            "type": "audio_chunk",
            "content": text,
            "audio": audio_base64,
            "audio_size": len(response.audio_content),
            "timestamp": datetime.now().isoformat()
        })
        
        logger.info(f"âœ… TTS ì „ì†¡ ì™„ë£Œ: {len(response.audio_content)} bytes")
        
    except Exception as e:
        logger.error(f"âš ï¸ TTS ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        # TTS ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ë§Œ ì „ì†¡
        await websocket.send_json({
            "type": "text_chunk",
            "content": text,
            "error": "TTS ì²˜ë¦¬ ì‹¤íŒ¨"
        })

# ì˜ˆì™¸ ì²˜ë¦¬ í•¸ë“¤ëŸ¬
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    logger.error(f"Global exception: {str(exc)}")
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal server error",
            "message": "ì„œë²„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        }
    )

# ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    port = int(os.getenv("PORT", 8080))
    log_level = os.getenv("LOG_LEVEL", "info")
    
    logger.info(f"ğŸš€ AI íŠœí„° ì„œë²„ ì‹œì‘")
    logger.info(f"ğŸ“¡ í¬íŠ¸: {port}")
    logger.info(f"ğŸ¤ ìŒì„± ì…ë ¥: {'âœ… í™œì„±í™”' if speech_client else 'âŒ ë¹„í™œì„±í™”'}")
    logger.info(f"ğŸ”Š ìŒì„± ì¶œë ¥: {'âœ… í™œì„±í™”' if tts_client else 'âŒ ë¹„í™œì„±í™”'}")
    logger.info(f"ğŸ’¬ í…ìŠ¤íŠ¸ ì…ë ¥: âœ… í™œì„±í™”")
    logger.info(f"ğŸ¤– AI ëª¨ë¸: GPT-3.5 Turbo")
    logger.info(f"ğŸ”„ ìƒíƒœ ê´€ë¦¬: âœ… í™œì„±í™”")
    logger.info(f"ğŸ“ ìŠ¤íŠ¸ë¦¬ë°: âœ… ë‹¨ì–´ ë‹¨ìœ„ ìì—°ìŠ¤ëŸ¬ìš´ ì²˜ë¦¬")
    
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=port,
        log_level=log_level,
        access_log=True
    )
