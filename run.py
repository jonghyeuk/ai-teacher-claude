#!/usr/bin/env python3
"""
AI íŠœí„° FastAPI ë°±ì—”ë“œ ì• í”Œë¦¬ì¼€ì´ì…˜ (v3.3 - ìŠ¤ë§ˆíŠ¸í•œ ê· í˜•)

ì™„ì „í•œ ì‹¤ì‹œê°„ AI íŠœí„° ì‹œìŠ¤í…œ ë°±ì—”ë“œì…ë‹ˆë‹¤.
- ğŸ”’ ì˜¤ë””ì˜¤ ì¤‘ì²© ì™„ì „ í•´ê²° (ê°•ë ¥í•œ ì§ë ¬í™”) â† ìµœìš°ì„ 
- ğŸ­ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” í’ˆì§ˆ ìœ ì§€ (í† í° ì ì ˆíˆ ë³´ì¡´) â† ì¤‘ìš”
- ğŸ’° ìŠ¤ë§ˆíŠ¸í•œ ë¹„ìš© ì ˆì•½ (í•µì‹¬ë§Œ ìµœì í™”) â† ê· í˜•
- ğŸ§  íŠœí„° ê¸°ëŠ¥ ì™„ì „ ë³´ì¡´ (í•™ìŠµ ì§„ë„, ê°œì¸í™”) â† í•„ìˆ˜
"""

import asyncio
import base64
import json
import os
import tempfile
import uuid
import time
from datetime import datetime
from typing import Dict, Any, Optional
import logging

import uvicorn
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from openai import AsyncOpenAI
from google.cloud import texttospeech
from google.cloud import speech
import httpx

# ğŸ¯ ìŠ¤ë§ˆíŠ¸í•œ ë¡œê¹…: ê°œë°œì‹œì—” INFO, ìš´ì˜ì‹œì—” WARNING
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
logging.basicConfig(level=getattr(logging, LOG_LEVEL))
logger = logging.getLogger(__name__)

# ğŸ’° ë¹„ìš© ì ˆì•½: ë¶ˆí•„ìš”í•œ ìƒì„¸ ë¡œê¹…ë§Œ ì œê±°
if LOG_LEVEL == "WARNING":
    # ìš´ì˜ í™˜ê²½ì—ì„œë§Œ Google í´ë¼ì´ì–¸íŠ¸ ë¡œê¹… ì œí•œ
    logging.getLogger("google").setLevel(logging.ERROR)
    logging.getLogger("urllib3").setLevel(logging.ERROR)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="AI Tutor Realtime System",
    description="ì‹¤ì‹œê°„ AI íŠœí„° ì‹œìŠ¤í…œ - v3.3 ìŠ¤ë§ˆíŠ¸í•œ ê· í˜• (ì¤‘ì²© í•´ê²° + ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”)",
    version="3.3.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS ì„¤ì • (ê¸°ì¡´ ìœ ì§€)
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://*.streamlit.app",
        "https://*.streamlit.io", 
        "http://localhost:8501",
        "http://localhost:3000",
        "http://localhost:8080",
        "*"
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

# í™˜ê²½ë³€ìˆ˜ ì„¤ì • (ê¸°ì¡´ ìœ ì§€)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    logger.error("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ê¸°ì¡´ ìœ ì§€)
openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)

try:
    tts_client = texttospeech.TextToSpeechClient()
    logger.info("Google TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
except Exception as e:
    logger.error(f"Google TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    tts_client = None

try:
    speech_client = speech.SpeechClient()
    logger.info("Google STT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
except Exception as e:
    logger.error(f"Google STT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    speech_client = None

# ì „ì—­ ë³€ìˆ˜ (ê¸°ì¡´ + ì¤‘ì²© ë°©ì§€ìš©)
active_connections: Dict[str, WebSocket] = {}
tutor_configs: Dict[str, Dict[str, Any]] = {}
response_in_progress: set = set()  
conversation_history: Dict[str, list] = {}

# ğŸ”’ ì¤‘ì²© ì™„ì „ ë°©ì§€ë¥¼ ìœ„í•œ ê°•ë ¥í•œ ì§ë ¬í™” ì‹œìŠ¤í…œ
client_locks: Dict[str, asyncio.Lock] = {}
client_tts_tasks: Dict[str, Optional[asyncio.Task]] = {}
response_queues: Dict[str, asyncio.Queue] = {}

# ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸ë“¤
@app.get("/")
async def root():
    """ë©”ì¸ í˜ì´ì§€ - ì‹œìŠ¤í…œ ì •ë³´"""
    return {
        "message": "ğŸ“ AI Tutor Realtime System",
        "version": "3.3.0",
        "status": "running",
        "updates": [
            "ğŸ”’ ì˜¤ë””ì˜¤ ì¤‘ì²© ì™„ì „ í•´ê²° (ê°•ë ¥í•œ ì§ë ¬í™”)",
            "ğŸ­ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” í’ˆì§ˆ ìœ ì§€ (ì ì ˆí•œ í† í°)",
            "ğŸ’° ìŠ¤ë§ˆíŠ¸í•œ ë¹„ìš© ì ˆì•½ (í•µì‹¬ë§Œ ìµœì í™”)",
            "ğŸ§  íŠœí„° ê¸°ëŠ¥ ì™„ì „ ë³´ì¡´ (í•™ìŠµ ì§„ë„, ê°œì¸í™”)"
        ],
        "philosophy": {
            "overlap_prevention": "100% í•´ê²° (ìµœìš°ì„ )",
            "conversation_quality": "ìì—°ìŠ¤ëŸ¬ì›€ ìœ ì§€ (í•„ìˆ˜)",
            "cost_optimization": "ìŠ¤ë§ˆíŠ¸í•œ ì ˆì•½ (ê· í˜•)",
            "tutor_intelligence": "í•™ìŠµ ê¸°ëŠ¥ ë³´ì¡´ (í•µì‹¬)"
        },
        "endpoints": {
            "websocket": "/ws/tutor/{client_id}",
            "health": "/health",
            "info": "/info",
            "docs": "/docs"
        },
        "timestamp": datetime.now().isoformat()
    }

@app.get("/health")
async def health_check():
    """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    try:
        openai_status = "âœ… ì—°ê²°ë¨" if OPENAI_API_KEY else "âŒ API í‚¤ ì—†ìŒ"
        
        tts_status = "âŒ ë¹„í™œì„±í™”"
        if tts_client:
            try:
                voices = tts_client.list_voices()
                tts_status = f"âœ… í™œì„±í™” ({len(voices.voices)}ê°œ ìŒì„±)"
            except Exception as e:
                tts_status = f"âš ï¸ ì˜¤ë¥˜: {str(e)[:50]}"
        
        stt_status = "âœ… í™œì„±í™”" if speech_client else "âŒ ë¹„í™œì„±í™”"
        
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "active_connections": len(active_connections),
            "active_tutors": len(tutor_configs),
            "active_responses": len(response_in_progress),
            "conversation_sessions": len(conversation_history),
            "client_locks": len(client_locks),
            "active_tts_tasks": len([t for t in client_tts_tasks.values() if t and not t.done()]),
            "services": {
                "openai_gpt": openai_status,
                "google_tts": tts_status,
                "google_stt": stt_status
            },
            "performance": {
                "target_response_time": "1000ms",
                "audio_overlap_prevention": "ì™„ì „ í•´ê²°",
                "conversation_quality": "ìì—°ìŠ¤ëŸ¬ì›€ ìœ ì§€",
                "cost_efficiency": "ìŠ¤ë§ˆíŠ¸í•œ ì ˆì•½"
            }
        }
    except Exception as e:
        logger.error(f"Health check ì˜¤ë¥˜: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "status": "unhealthy", 
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
        )

@app.get("/info")
async def system_info():
    """ìƒì„¸ ì‹œìŠ¤í…œ ì •ë³´"""
    return {
        "system": "AI Tutor Realtime System",
        "version": "3.3.0",
        "architecture": "ê³ ì„±ëŠ¥ ì‹¤ì‹œê°„ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤",
        "deployment": "Google Cloud Run",
        "core_improvements": {
            "audio_overlap_complete_prevention": "ê°•ë ¥í•œ Lock ê¸°ë°˜ ì§ë ¬í™”ë¡œ ì¤‘ì²© 100% ë°©ì§€",
            "natural_conversation_preservation": "ì ì ˆí•œ í† í° ë°°ë¶„ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ìœ ì§€",
            "smart_cost_optimization": "í•µì‹¬ ê¸°ëŠ¥ ë³´ì¡´í•˜ë©´ì„œ ë¶ˆí•„ìš”í•œ ë¹„ìš©ë§Œ ì œê±°",
            "tutor_intelligence_maintained": "í•™ìŠµ ì§„ë„ ì¶”ì , ê°œì¸í™”, ë§¥ë½ ì´í•´ ì™„ì „ ë³´ì¡´"
        },
        "balance_strategy": {
            "primary": "ì¤‘ì²© ë°©ì§€ (ì‚¬ìš©ì ê²½í—˜)",
            "secondary": "ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” (íŠœí„° í’ˆì§ˆ)",
            "tertiary": "ë¹„ìš© íš¨ìœ¨ì„± (ì§€ì† ê°€ëŠ¥ì„±)"
        }
    }

# WebSocket ì—”ë“œí¬ì¸íŠ¸ (ê¸°ì¡´ ë¡œì§ ìœ ì§€ + ì •ë¦¬ ê°•í™”)
@app.websocket("/ws/tutor/{client_id}")
async def websocket_endpoint(websocket: WebSocket, client_id: str):
    """ë©”ì¸ WebSocket ì—”ë“œí¬ì¸íŠ¸"""
    await websocket.accept()
    active_connections[client_id] = websocket
    
    if client_id not in conversation_history:
        conversation_history[client_id] = []
    
    # ğŸ”’ í´ë¼ì´ì–¸íŠ¸ë³„ ì§ë ¬í™” ìì› ì´ˆê¸°í™”
    if client_id not in client_locks:
        client_locks[client_id] = asyncio.Lock()
        client_tts_tasks[client_id] = None
        response_queues[client_id] = asyncio.Queue(maxsize=1)
    
    logger.info(f"âœ… í´ë¼ì´ì–¸íŠ¸ {client_id} ì—°ê²°ë¨")
    
    try:
        await websocket.send_json({
            "type": "connection_established",
            "message": "ğŸ“ AI íŠœí„°ì™€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤! (v3.3 - ì¤‘ì²© í•´ê²° + ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”)",
            "client_id": client_id,
            "timestamp": datetime.now().isoformat(),
            "features": [
                "voice_input", "text_input", "voice_output", 
                "real_time_streaming", "state_management",
                "instant_interrupt", "feedback_loop", "intent_analysis",
                "complete_overlap_prevention", "natural_conversation",
                "smart_cost_optimization", "tutor_intelligence"
            ]
        })
        
        while True:
            try:
                data = await asyncio.wait_for(websocket.receive(), timeout=60.0)
                
                if data["type"] == "websocket.disconnect":
                    logger.info(f"âŒ í´ë¼ì´ì–¸íŠ¸ {client_id} ì •ìƒ ì—°ê²° ì¢…ë£Œ")
                    break
                
                if data["type"] == "websocket.receive" and "text" in data:
                    try:
                        message = json.loads(data["text"])
                        await handle_text_message(websocket, message, client_id)
                    except json.JSONDecodeError as e:
                        logger.error(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {data['text'][:100]} | {e}")
                        await websocket.send_json({
                            "type": "error",
                            "message": "ë©”ì‹œì§€ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."
                        })
                
                elif data["type"] == "websocket.receive" and "bytes" in data:
                    audio_data = data["bytes"]
                    await handle_audio_message(websocket, audio_data, client_id)
                    
            except asyncio.TimeoutError:
                try:
                    await websocket.send_json({
                        "type": "ping",
                        "timestamp": datetime.now().isoformat()
                    })
                except:
                    logger.warning(f"í´ë¼ì´ì–¸íŠ¸ {client_id} í•‘ ì‹¤íŒ¨ - ì—°ê²° ì¢…ë£Œ")
                    break
                
    except WebSocketDisconnect:
        logger.info(f"âŒ í´ë¼ì´ì–¸íŠ¸ {client_id} ì—°ê²° ëŠê¹€ (ì •ìƒ)")
    except Exception as e:
        logger.error(f"âš ï¸ WebSocket ì—ëŸ¬ {client_id}: {str(e)}")
    finally:
        await cleanup_client_completely(client_id)

async def cleanup_client_completely(client_id: str):
    """ğŸ”’ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ ì‹œ ì™„ì „í•œ ì •ë¦¬"""
    try:
        if client_id in client_locks:
            await force_cleanup_previous_response(client_id)
            del client_locks[client_id]
            
        if client_id in client_tts_tasks:
            del client_tts_tasks[client_id]
            
        if client_id in response_queues:
            del response_queues[client_id]
        
        if client_id in active_connections:
            del active_connections[client_id]
        if client_id in tutor_configs:
            del tutor_configs[client_id]
        response_in_progress.discard(client_id)
        
        logger.info(f"ğŸ§¹ í´ë¼ì´ì–¸íŠ¸ ì™„ì „ ì •ë¦¬ ì™„ë£Œ: {client_id}")
        
    except Exception as e:
        logger.error(f"âš ï¸ í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬ ì˜¤ë¥˜: {e}")

async def handle_text_message(websocket: WebSocket, message: dict, client_id: str):
    """í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬"""
    try:
        message_type = message.get("type")
        logger.info(f"ğŸ“¨ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ìˆ˜ì‹ : {message_type} from {client_id}")
        
        if message_type == "config_update":
            config = message.get("config", {})
            
            if "voice_settings" not in config:
                config["voice_settings"] = {
                    "auto_play": True,
                    "speed": 1.0,
                    "pitch": 1.0
                }
            
            tutor_configs[client_id] = config
            logger.info(f"ğŸ“‹ íŠœí„° ì„¤ì • ì—…ë°ì´íŠ¸: {config.get('name', 'Unknown')} ({config.get('subject', 'Unknown')})")
            
            await websocket.send_json({
                "type": "config_updated",
                "message": "íŠœí„° ì„¤ì •ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "config_summary": {
                    "name": config.get("name"),
                    "subject": config.get("subject"),
                    "level": config.get("level")
                }
            })
            
        elif message_type == "user_text":
            user_text = message.get("text", "").strip()
            is_interrupt = message.get("interrupt", False)
            
            if not user_text:
                await websocket.send_json({
                    "type": "error",
                    "message": "í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
                })
                return
            
            if len(user_text) > 10000:
                await websocket.send_json({
                    "type": "error",
                    "message": "í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. 10,000ì ì´í•˜ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”."
                })
                return
            
            if is_interrupt and client_id in response_in_progress:
                await handle_response_interrupt(websocket, user_text, client_id)
                return
            
            logger.info(f"ğŸ’¬ ì‚¬ìš©ì í…ìŠ¤íŠ¸ ì…ë ¥: '{user_text[:50]}...' from {client_id}")
            
            add_to_conversation_history(client_id, "user", user_text)
            await generate_ai_response_completely_safe(websocket, user_text, client_id)
            
        elif message_type == "feedback_request":
            await handle_realtime_feedback(websocket, message, client_id)
            
        elif message_type == "interrupt_response":
            await interrupt_current_response(websocket, client_id)
            
        elif message_type == "ping":
            await websocket.send_json({
                "type": "pong",
                "timestamp": datetime.now().isoformat()
            })
            
        else:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì‹œì§€ íƒ€ì…: {message_type}")
            await websocket.send_json({
                "type": "error",
                "message": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë©”ì‹œì§€ íƒ€ì…: {message_type}"
            })
            
    except Exception as e:
        logger.error(f"âš ï¸ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜ {client_id}: {str(e)}")
        await websocket.send_json({
            "type": "error",
            "message": f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        })

async def handle_audio_message(websocket: WebSocket, audio_data: bytes, client_id: str):
    """ì˜¤ë””ì˜¤ ë©”ì‹œì§€ ì²˜ë¦¬"""
    try:
        logger.info(f"ğŸ¤ ì˜¤ë””ì˜¤ ìˆ˜ì‹ : {len(audio_data)} bytes from {client_id}")
        
        if len(audio_data) < 500:
            await websocket.send_json({
                "type": "error", 
                "message": "ë…¹ìŒì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ì¡°ê¸ˆ ë” ê¸¸ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”."
            })
            return
        
        if len(audio_data) > 10 * 1024 * 1024:
            await websocket.send_json({
                "type": "error", 
                "message": "ë…¹ìŒì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ì§§ê²Œ ë‚˜ëˆ„ì–´ì„œ ë§ì”€í•´ì£¼ì„¸ìš”."
            })
            return
        
        transcript = await process_speech_to_text_enhanced(audio_data)
        logger.info(f"ğŸ”¤ STT ê²°ê³¼: '{transcript}' from {client_id}")
        
        if not transcript or transcript.strip() == "":
            await websocket.send_json({
                "type": "error", 
                "message": "ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤. ë” ëª…í™•í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”."
            })
            return
        
        await websocket.send_json({
            "type": "stt_result",
            "text": transcript,
            "timestamp": datetime.now().isoformat()
        })
        
        add_to_conversation_history(client_id, "user", transcript)
        await generate_ai_response_completely_safe(websocket, transcript, client_id)
        
    except Exception as e:
        logger.error(f"âš ï¸ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜ {client_id}: {str(e)}")
        await websocket.send_json({
            "type": "error",
            "message": f"ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        })

async def process_speech_to_text_enhanced(audio_data: bytes) -> str:
    """STT ì²˜ë¦¬ (ê¸°ì¡´ ìœ ì§€)"""
    if not speech_client:
        logger.error("STT í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return ""
    
    try:
        logger.info(f"ğŸ¤ ê°œì„ ëœ STT ì²˜ë¦¬ ì‹œì‘: {len(audio_data)} bytes")
        
        configs_to_try = [
            {
                "encoding": speech.RecognitionConfig.AudioEncoding.WEBM_OPUS,
                "sample_rate_hertz": 48000,
                "description": "WEBM_OPUS 48kHz"
            },
            {
                "encoding": speech.RecognitionConfig.AudioEncoding.WEBM_OPUS,
                "sample_rate_hertz": 16000,
                "description": "WEBM_OPUS 16kHz"
            },
            {
                "encoding": speech.RecognitionConfig.AudioEncoding.ENCODING_UNSPECIFIED,
                "sample_rate_hertz": 16000,
                "description": "AUTO_DETECT 16kHz"
            },
            {
                "encoding": speech.RecognitionConfig.AudioEncoding.OGG_OPUS,
                "sample_rate_hertz": 16000,
                "description": "OGG_OPUS 16kHz"
            }
        ]
        
        for i, config_params in enumerate(configs_to_try):
            try:
                logger.info(f"ğŸ”„ STT ì‹œë„ {i+1}/4: {config_params['description']}")
                
                config = speech.RecognitionConfig(
                    encoding=config_params["encoding"],
                    sample_rate_hertz=config_params["sample_rate_hertz"],
                    language_code="ko-KR",
                    enable_automatic_punctuation=True,
                    model="latest_short",
                    enable_word_confidence=True,
                    use_enhanced=True,
                    alternative_language_codes=["en-US"],
                    profanity_filter=False,
                    enable_speaker_diarization=False,
                    max_alternatives=1
                )
                
                audio = speech.RecognitionAudio(content=audio_data)
                
                response = await asyncio.wait_for(
                    asyncio.get_event_loop().run_in_executor(
                        None, 
                        lambda: speech_client.recognize(config=config, audio=audio)
                    ),
                    timeout=15.0
                )
                
                if response.results and len(response.results) > 0:
                    transcript = response.results[0].alternatives[0].transcript
                    confidence = response.results[0].alternatives[0].confidence if response.results[0].alternatives[0].confidence else 0.0
                    
                    logger.info(f"âœ… STT ì„±ê³µ: '{transcript}' (ì‹ ë¢°ë„: {confidence:.2f})")
                    
                    if confidence < 0.1:
                        logger.warning(f"âš ï¸ ì‹ ë¢°ë„ ë‚®ìŒ ({confidence:.2f}), ë‹¤ìŒ ì„¤ì • ì‹œë„")
                        continue
                    
                    return transcript.strip()
                else:
                    logger.warning(f"âš ï¸ STT ê²°ê³¼ ì—†ìŒ: {config_params['description']}")
                    
            except asyncio.TimeoutError:
                logger.warning(f"â° STT íƒ€ì„ì•„ì›ƒ: {config_params['description']}")
                continue
            except Exception as e:
                logger.error(f"âš ï¸ STT ì„¤ì • {i+1} ì‹¤íŒ¨: {str(e)}")
                continue
        
        logger.error("âŒ ëª¨ë“  STT ì„¤ì • ì‹¤íŒ¨")
        return ""
        
    except Exception as e:
        logger.error(f"âš ï¸ STT ì „ì²´ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return ""

# ğŸ”’ ì™„ì „íˆ ì•ˆì „í•œ AI ì‘ë‹µ ìƒì„± (ì¤‘ì²© 100% ë°©ì§€)
async def generate_ai_response_completely_safe(websocket: WebSocket, user_input: str, client_id: str):
    """ğŸ”’ ì™„ì „íˆ ì•ˆì „í•œ AI ì‘ë‹µ ìƒì„± (ì¤‘ì²© 100% ë°©ì§€)"""
    
    if client_id not in client_locks:
        client_locks[client_id] = asyncio.Lock()
        client_tts_tasks[client_id] = None
        response_queues[client_id] = asyncio.Queue(maxsize=1)
    
    # ğŸ”’ ê°•ë ¥í•œ Lockìœ¼ë¡œ ì™„ì „íˆ ì§ë ¬í™”
    async with client_locks[client_id]:
        try:
            await force_cleanup_previous_response(client_id)
            
            logger.info(f"ğŸ”’ Lock íšë“ - ì•ˆì „í•œ ì‘ë‹µ ì‹œì‘: {client_id}")
            
            response_in_progress.add(client_id)
            start_time = time.time()
            
            # ğŸ­ ìì—°ìŠ¤ëŸ¬ìš´ ì˜ë„ ë¶„ì„ (ì ì ˆí•œ ë³µì¡ë„ ìœ ì§€)
            response_strategy = analyze_user_intent_for_natural_conversation(user_input, client_id)
            
            await websocket.send_json({
                "type": "response_start",
                "strategy": response_strategy,
                "lock_acquired": True,
                "timestamp": datetime.now().isoformat()
            })
            
            conversation_context = get_conversation_context(client_id)
            
            await process_completely_serialized_streaming(
                websocket, user_input, client_id, response_strategy, 
                start_time, conversation_context
            )
            
        except Exception as e:
            logger.error(f"âš ï¸ ì•ˆì „í•œ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜ {client_id}: {str(e)}")
            await websocket.send_json({
                "type": "error",
                "message": f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
            })
        finally:
            response_in_progress.discard(client_id)
            logger.info(f"ğŸ”“ Lock í•´ì œ ì™„ë£Œ: {client_id}")

async def force_cleanup_previous_response(client_id: str):
    """ğŸ”’ ì´ì „ ì‘ë‹µ ì™„ì „ ì •ë¦¬ (ê°•ì œ)"""
    try:
        if client_id in client_tts_tasks and client_tts_tasks[client_id]:
            previous_task = client_tts_tasks[client_id]
            if not previous_task.done():
                logger.info(f"ğŸ›‘ ì´ì „ TTS ì‘ì—… ê°•ì œ ì¤‘ë‹¨: {client_id}")
                previous_task.cancel()
                try:
                    await previous_task
                except asyncio.CancelledError:
                    pass
                except Exception as e:
                    logger.warning(f"âš ï¸ TTS ì‘ì—… ì·¨ì†Œ ì¤‘ ì˜¤ë¥˜: {e}")
        
        if client_id in response_queues:
            queue = response_queues[client_id]
            while not queue.empty():
                try:
                    queue.get_nowait()
                except asyncio.QueueEmpty:
                    break
        
        response_in_progress.discard(client_id)
        client_tts_tasks[client_id] = None
        
        logger.info(f"ğŸ§¹ ì´ì „ ì‘ë‹µ ì™„ì „ ì •ë¦¬ ì™„ë£Œ: {client_id}")
        
    except Exception as e:
        logger.error(f"âš ï¸ ì´ì „ ì‘ë‹µ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

async def process_completely_serialized_streaming(websocket: WebSocket, user_input: str, 
                                                client_id: str, strategy: str, start_time: float,
                                                conversation_context: list):
    """ğŸ”’ ì™„ì „íˆ ì§ë ¬í™”ëœ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬"""
    
    tutor_config = tutor_configs.get(client_id, {})
    tutor_prompt = create_natural_conversational_prompt(tutor_config, strategy, conversation_context, user_input)
    
    try:
        stream = await openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": tutor_prompt},
                {"role": "user", "content": user_input}
            ],
            max_tokens=get_natural_max_tokens(strategy, user_input, conversation_context),
            temperature=0.7,
            stream=True
        )
        
        complete_response = ""
        word_buffer = ""
        first_response_sent = False
        
        async for chunk in stream:
            if client_id not in response_in_progress:
                logger.info(f"ğŸ›‘ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ë‹¨ ê°ì§€: {client_id}")
                break
                
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                word_buffer += content
                complete_response += content
                
                if any(char in content for char in [' ', '\n', '\t']) or chunk.choices[0].finish_reason:
                    if word_buffer.strip():
                        if not first_response_sent:
                            elapsed = time.time() - start_time
                            logger.info(f"âš¡ ì²« ì‘ë‹µ ì‹œê°„: {elapsed:.3f}ì´ˆ")
                            first_response_sent = True
                        
                        await websocket.send_json({
                            "type": "text_chunk",
                            "content": word_buffer,
                            "timestamp": datetime.now().isoformat()
                        })
                        word_buffer = ""
        
        if complete_response.strip() and client_id in response_in_progress:
            await websocket.send_json({
                "type": "response_complete",
                "total_response": complete_response,
                "timestamp": datetime.now().isoformat()
            })
            
            add_to_conversation_history(client_id, "assistant", complete_response)
            await create_completely_safe_tts(websocket, complete_response.strip(), client_id)
        else:
            logger.warning(f"âš ï¸ TTS ìƒì„± ìƒëµ - ì‘ë‹µ ì¤‘ë‹¨ë¨: {client_id}")
            
    except Exception as e:
        logger.error(f"âš ï¸ ì§ë ¬í™”ëœ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {str(e)}")
        raise

async def create_completely_safe_tts(websocket: WebSocket, full_text: str, client_id: str):
    """ğŸ”’ ì™„ì „íˆ ì•ˆì „í•œ TTS ìƒì„± (ì¤‘ì²© ì ˆëŒ€ ë¶ˆê°€)"""
    if not tts_client:
        logger.warning("TTS í´ë¼ì´ì–¸íŠ¸ê°€ ë¹„í™œì„±í™”ë˜ì–´ í…ìŠ¤íŠ¸ë§Œ ì „ì†¡í•©ë‹ˆë‹¤.")
        return
    
    try:
        tts_task = asyncio.create_task(
            _execute_single_tts(websocket, full_text, client_id)
        )
        
        client_tts_tasks[client_id] = tts_task
        await tts_task
        
    except asyncio.CancelledError:
        logger.info(f"ğŸ›‘ TTS ì‘ì—… ì·¨ì†Œë¨: {client_id}")
    except Exception as e:
        logger.error(f"âš ï¸ ì•ˆì „í•œ TTS ìƒì„± ì˜¤ë¥˜: {str(e)}")
    finally:
        if client_id in client_tts_tasks:
            client_tts_tasks[client_id] = None

async def _execute_single_tts(websocket: WebSocket, full_text: str, client_id: str):
    """ì‹¤ì œ TTS ì‹¤í–‰"""
    logger.info(f"ğŸ”Š ì•ˆì „í•œ TTS ì²˜ë¦¬ ì‹œì‘: '{full_text[:50]}...' for {client_id}")
    
    synthesis_input = texttospeech.SynthesisInput(text=full_text)
    
    voice = texttospeech.VoiceSelectionParams(
        language_code="ko-KR",
        name="ko-KR-Standard-A",
        ssml_gender=texttospeech.SsmlVoiceGender.FEMALE
    )
    
    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3,
        speaking_rate=1.0,
        pitch=0.0,
        volume_gain_db=0.0,
        effects_profile_id=["headphone-class-device"]
    )
    
    start_tts = time.time()
    
    response = await asyncio.wait_for(
        asyncio.get_event_loop().run_in_executor(
            None,
            lambda: tts_client.synthesize_speech(
                input=synthesis_input,
                voice=voice,
                audio_config=audio_config
            )
        ),
        timeout=15.0
    )
    
    if client_id not in response_in_progress:
        logger.info(f"ğŸ›‘ TTS ì™„ë£Œ í›„ ì¤‘ë‹¨ ê°ì§€: {client_id}")
        return
    
    tts_time = time.time() - start_tts
    audio_base64 = base64.b64encode(response.audio_content).decode('utf-8')
    
    await websocket.send_json({
        "type": "audio_completely_safe",
        "text": full_text,
        "audio": audio_base64,
        "audio_size": len(response.audio_content),
        "tts_time": round(tts_time, 3),
        "client_id": client_id,
        "timestamp": datetime.now().isoformat()
    })
    
    logger.info(f"âœ… ì•ˆì „í•œ TTS ì™„ë£Œ: {len(response.audio_content)} bytes for {client_id}")

# ğŸ­ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ìœ„í•œ ê°œì„ ëœ í•¨ìˆ˜ë“¤
def analyze_user_intent_for_natural_conversation(user_input: str, client_id: str) -> str:
    """ğŸ­ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ìœ„í•œ ì˜ë„ ë¶„ì„ (ë§¥ë½ ê³ ë ¤)"""
    user_input_lower = user_input.lower()
    
    # ëŒ€í™” ë§¥ë½ ê³ ë ¤
    conversation_context = get_conversation_context(client_id)
    is_follow_up = len(conversation_context) > 0
    
    # 1. ì¸ì‚¬/í™•ì¸ â†’ very_short (í•˜ì§€ë§Œ ë„ˆë¬´ ì§§ì§€ ì•Šê²Œ)
    if len(user_input) < 5 or any(word in user_input_lower for word in ["ì‘", "ë„¤", "ì˜ˆ", "ì•„ë‹ˆ", "ë§ì•„", "í‹€ë ¤", "ì•ˆë…•", "ê°ì‚¬"]):
        return "very_short"
    
    # 2. ì •ì˜/ê°œë… ì§ˆë¬¸ â†’ short (ì ì ˆí•œ ì„¤ëª…)
    if any(word in user_input_lower for word in ["ë­ì˜ˆìš”", "ë¬´ì—‡", "ì •ì˜", "ëœ»", "ì˜ë¯¸"]):
        return "short" if not is_follow_up else "medium"  # í›„ì† ì§ˆë¬¸ì´ë©´ ë” ìì„¸íˆ
    
    # 3. ìš”ì•½ ìš”ì²­ â†’ short
    if any(word in user_input_lower for word in ["ì§§ê²Œ", "ê°„ë‹¨íˆ", "ìš”ì•½", "í•µì‹¬"]):
        return "short"
    
    # 4. ì˜ˆì‹œ ìš”ì²­ â†’ medium (ì¢‹ì€ ì˜ˆì‹œëŠ” ì„¤ëª…ì´ í•„ìš”)
    if any(word in user_input_lower for word in ["ì˜ˆì‹œ", "ì˜ˆë¥¼ ë“¤ì–´", "ì˜ˆ", "ì–´ë–¤", "ì‚¬ë¡€"]):
        return "medium"
    
    # 5. ë°©ë²•/ê³¼ì • ì§ˆë¬¸ â†’ medium (ë‹¨ê³„ë³„ ì„¤ëª… í•„ìš”)
    if any(word in user_input_lower for word in ["ì–´ë–»ê²Œ", "ë°©ë²•", "ê³¼ì •", "ì ˆì°¨", "ë‹¨ê³„"]):
        return "medium"
    
    # 6. ì´ìœ /ì›ë¦¬ ì§ˆë¬¸ â†’ medium (ì¶©ë¶„í•œ ì„¤ëª… í•„ìš”)
    if any(word in user_input_lower for word in ["ì™œ", "ì´ìœ ", "ì›ë¦¬", "ë•Œë¬¸"]):
        return "medium"
    
    # 7. ìì„¸í•œ ì„¤ëª… ìš”ì²­ â†’ long (ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ìš”ì²­)
    if any(word in user_input_lower for word in ["ìì„¸íˆ", "êµ¬ì²´ì ìœ¼ë¡œ", "ìƒì„¸íˆ", "ê¹Šì´"]):
        return "long"
    
    # 8. ë¬¸ì œ/í€´ì¦ˆ â†’ interactive
    if any(word in user_input_lower for word in ["ë¬¸ì œ", "í€´ì¦ˆ", "í…ŒìŠ¤íŠ¸", "í’€ì–´"]):
        return "interactive"
    
    # 9. ë³µì¡í•œ ì§ˆë¬¸ (ê¸´ ì…ë ¥) â†’ medium
    if len(user_input) > 50:
        return "medium"
    
    # 10. ê¸°ë³¸ê°’: ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”í˜•
    return "short"

def get_natural_max_tokens(strategy: str, user_input: str, conversation_context: list) -> int:
    """ğŸ­ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ìœ„í•œ í† í° ë°°ë¶„ (ì ì ˆí•œ ê¸¸ì´ ìœ ì§€)"""
    base_tokens = {
        "very_short": 25,   # "ë„¤, ë§ì•„ìš”! ë” ê¶ê¸ˆí•œ ê²Œ ìˆë‚˜ìš”?"
        "short": 60,        # "ë¯¸ë¶„ì€ ë³€í™”ìœ¨ì„ êµ¬í•˜ëŠ” ê±°ì˜ˆìš”! ìë™ì°¨ ì†ë„ ë³€í™” ê°™ì€ ê±°ì£ . ì˜ˆì‹œ í•˜ë‚˜ ë³¼ê¹Œìš”?"
        "medium": 120,      # 2-3ë¬¸ì¥ + ì˜ˆì‹œ + ì§ˆë¬¸ (ìì—°ìŠ¤ëŸ¬ìš´ ì„¤ëª…)
        "long": 200,        # ìƒì„¸í•œ ì„¤ëª…ì´ í•„ìš”í•  ë•Œ (ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ìš”ì²­)
        "interactive": 100  # ë¬¸ì œ + íŒíŠ¸ + ê²©ë ¤
    }
    
    base = base_tokens.get(strategy, 60)
    
    # ğŸ§  ë§¥ë½ì— ë”°ë¥¸ ì¡°ì ˆ (íŠœí„°ì˜ ì§€ëŠ¥ ìœ ì§€)
    if len(conversation_context) > 0:
        last_exchange = conversation_context[-1]
        # ì‚¬ìš©ìê°€ ì´í•´ ëª»í–ˆë‹¤ë©´ ë” ìì„¸íˆ
        if any(word in last_exchange.get("content", "").lower() for word in ["ëª¨ë¥´ê² ", "ì´í•´ ì•ˆ", "í—·ê°ˆ"]):
            base = min(base + 40, 250)
        # ì‚¬ìš©ìê°€ ì´í•´í–ˆë‹¤ë©´ ë‹¤ìŒ ë‹¨ê³„ë¡œ
        elif any(word in last_exchange.get("content", "").lower() for word in ["ì•Œê² ", "ì´í•´í–ˆ", "ë§ë„¤"]):
            base = min(base + 20, 200)
    
    # ì§ˆë¬¸ ë³µì¡ë„ì— ë”°ë¥¸ ì¡°ì ˆ
    if len(user_input) > 100:  # ë³µì¡í•œ ì§ˆë¬¸
        base = min(base + 30, 250)
    
    return base

def create_natural_conversational_prompt(tutor_config: dict, strategy: str, conversation_context: list, user_input: str) -> str:
    """ğŸ­ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸ ìƒì„± (ë§¥ë½ê³¼ ê°œì¸í™” ìœ ì§€)"""
    
    # ê¸°ì¡´ ì„±ê²© ì„¤ì • ì™„ì „ ìœ ì§€
    name = tutor_config.get("name", "AI íŠœí„°")
    subject = tutor_config.get("subject", "ì¼ë°˜")
    level = tutor_config.get("level", "ì¤‘í•™êµ")
    
    personality = tutor_config.get("personality", {})
    friendliness = personality.get("friendliness", 70)
    humor_level = personality.get("humor_level", 30)
    encouragement = personality.get("encouragement", 80)
    explanation_detail = personality.get("explanation_detail", 70)
    
    # ì„±ê²© ê¸°ë°˜ ë§íˆ¬ ì„¤ì • (ê¸°ì¡´ ìœ ì§€)
    personality_style = []
    
    if friendliness >= 80:
        personality_style.append("ë§¤ìš° ì¹œê·¼í•˜ê³  ë‹¤ì •í•œ ë§íˆ¬")
    elif friendliness >= 60:
        personality_style.append("ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ ë§íˆ¬")
    else:
        personality_style.append("ì •ì¤‘í•˜ê³  ì°¨ë¶„í•œ ë§íˆ¬")
    
    if humor_level >= 70:
        personality_style.append("ì ì ˆí•œ ìœ ë¨¸ì™€ ì¬ë¯¸ìˆëŠ” ë¹„ìœ  ì‚¬ìš©")
    elif humor_level >= 40:
        personality_style.append("ê°€ë” ìœ ë¨¸ë¥¼ ì„ì–´ì„œ ëŒ€í™”")
    
    if encouragement >= 80:
        personality_style.append("ì ê·¹ì ì¸ ê²©ë ¤ì™€ ì¹­ì°¬")
    elif encouragement >= 60:
        personality_style.append("ë”°ëœ»í•œ ê²©ë ¤")
    
    # ğŸ­ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ì „ëµë³„ ì§€ì¹¨
    conversation_guidelines = {
        "very_short": "1-2ë¬¸ì¥ìœ¼ë¡œ ê°„ë‹¨í•˜ê²Œ ë‹µí•˜ê³  ëŒ€í™” ì´ì–´ê°€ê¸°",
        "short": "í•µì‹¬ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì§ˆë¬¸ìœ¼ë¡œ ë§ˆë¬´ë¦¬",
        "medium": "ì ì ˆí•œ ê¸¸ì´ë¡œ ì„¤ëª…í•˜ë˜ ì¤‘ê°„ì¤‘ê°„ ì´í•´ë„ í™•ì¸ ë° ì˜ˆì‹œ í¬í•¨",
        "long": "ì¶©ë¶„íˆ ìì„¸í•˜ê²Œ ì„¤ëª…í•˜ë˜ ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ„ì–´ ê° ë‹¨ê³„ë§ˆë‹¤ ì´í•´ í™•ì¸",
        "interactive": "ë¬¸ì œë‚˜ ì˜ˆì‹œ ì œì‹œí•˜ê³  í•¨ê»˜ í’€ì–´ë³´ë„ë¡ ê²©ë ¤í•˜ë©° ìœ ë„"
    }
    
    # ğŸ§  ëŒ€í™” ë§¥ë½ ë¶„ì„ (í•™ìŠµ ì§„ë„ ì¶”ì )
    context_analysis = ""
    if conversation_context:
        recent_topics = []
        user_understanding_level = "ë³´í†µ"
        
        for msg in conversation_context[-3:]:
            if msg["role"] == "user":
                recent_topics.append(msg["content"][:30])
                # ì‚¬ìš©ì ì´í•´ë„ ë¶„ì„
                if any(word in msg["content"].lower() for word in ["ëª¨ë¥´ê² ", "ì–´ë ¤ì›Œ", "í—·ê°ˆ"]):
                    user_understanding_level = "ì–´ë ¤ì›Œí•¨"
                elif any(word in msg["content"].lower() for word in ["ì•Œê² ", "ì‰½ë„¤", "ì´í•´í–ˆ"]):
                    user_understanding_level = "ì˜ ì´í•´í•¨"
        
        context_analysis = f"""
**í•™ìŠµ ë§¥ë½ ë¶„ì„:**
- ìµœê·¼ ì£¼ì œ: {', '.join(recent_topics)}
- ì´í•´ ìˆ˜ì¤€: {user_understanding_level}
- ëŒ€í™” ì§„í–‰ë„: {len(conversation_context)}í„´"""
    
    # ğŸ¯ ë¹„ìš© íš¨ìœ¨ì ì´ë©´ì„œ ìì—°ìŠ¤ëŸ¬ìš´ í”„ë¡¬í”„íŠ¸
    prompt = f"""ë‹¹ì‹ ì€ {name}ì´ë¼ëŠ” {subject} ë¶„ì•¼ì˜ ì¹œê·¼í•œ AI íŠœí„°ì…ë‹ˆë‹¤.

**íŠœí„° ì„±ê²©:**
- ì¹œê·¼í•¨: {friendliness}% ({personality_style[0] if personality_style else 'ìì—°ìŠ¤ëŸ¬ìš´ ë§íˆ¬'})
- ìœ ë¨¸: {humor_level}% {'(ì ì ˆí•œ ìœ ë¨¸ ì‚¬ìš©)' if humor_level >= 40 else '(ì§„ì§€í•œ í†¤)'}
- ê²©ë ¤: {encouragement}% {'(ì ê·¹ì  ê²©ë ¤)' if encouragement >= 60 else '(ì°¨ë¶„í•œ ê²©ë ¤)'}

**ëŒ€í™” ì›ì¹™:**
1. {conversation_guidelines.get(strategy, "ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”")}
2. í•™ìƒì˜ ì´í•´ë„ì— ë§ì¶° ì„¤ëª… ì¡°ì ˆ
3. ì§ˆë¬¸ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•˜ì—¬ ìƒí˜¸ì‘ìš© ìœ ë„
4. í•™ìŠµì ì¤‘ì‹¬ì˜ ëŒ€í™” ì§„í–‰

**ì‘ë‹µ ìŠ¤íƒ€ì¼:**
- ìì—°ìŠ¤ëŸ½ê³  ëŒ€í™”í•˜ë“¯ì´
- ì ì ˆí•œ ê¸¸ì´ë¡œ (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸¸ì§€ ì•Šê²Œ)
- í•™ìŠµìì˜ ìˆ˜ì¤€ê³¼ ë§¥ë½ ê³ ë ¤
- ì˜ˆì‹œì™€ ë¹„ìœ ë¥¼ í™œìš©í•œ ì‰¬ìš´ ì„¤ëª…

**í•™ìŠµì ì •ë³´:**
- ìˆ˜ì¤€: {level}
- í˜„ì¬ ì „ëµ: {strategy}
{context_analysis}

í•™ìƒì˜ ì§ˆë¬¸ì— ëŒ€í•´ ìœ„ ì›ì¹™ì„ ì§€ì¼œ ìì—°ìŠ¤ëŸ½ê³  êµìœ¡ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”."""
    
    return prompt

# ë‚˜ë¨¸ì§€ í—¬í¼ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ìœ ì§€)
def add_to_conversation_history(client_id: str, role: str, content: str):
    """ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€ (í•™ìŠµ ì§„ë„ ì¶”ì  ìœ ì§€)"""
    if client_id not in conversation_history:
        conversation_history[client_id] = []
    
    conversation_history[client_id].append({
        "role": role,
        "content": content,
        "timestamp": datetime.now().isoformat()
    })
    
    # ğŸ§  ì ì ˆí•œ ê¸°ì–µ ìœ ì§€ (ë„ˆë¬´ ì§§ì§€ ì•Šê²Œ)
    if len(conversation_history[client_id]) > 25:  # 20 â†’ 25ë¡œ ì¦ê°€
        conversation_history[client_id] = conversation_history[client_id][-25:]

def get_conversation_context(client_id: str) -> list:
    """ëŒ€í™” ë§¥ë½ ë°˜í™˜ (ì¶©ë¶„í•œ ë§¥ë½ ìœ ì§€)"""
    if client_id not in conversation_history:
        return []
    
    # ğŸ§  ë” ë§ì€ ë§¥ë½ ìœ ì§€ (10 â†’ 12í„´)
    recent_messages = conversation_history[client_id][-12:]
    return [{"role": msg["role"], "content": msg["content"]} for msg in recent_messages]

# ì‹¤ì‹œê°„ í”¼ë“œë°± ë° ì¤‘ë‹¨ ì²˜ë¦¬ (ê¸°ì¡´ ìœ ì§€)
async def handle_response_interrupt(websocket: WebSocket, user_text: str, client_id: str):
    """ì‘ë‹µ ì¤‘ë‹¨ + ìƒˆë¡œìš´ ì‘ë‹µ ì²˜ë¦¬"""
    try:
        logger.info(f"ğŸ›‘ ì‘ë‹µ ì¤‘ë‹¨ + ìƒˆ ì§ˆë¬¸: '{user_text[:30]}...' from {client_id}")
        
        await interrupt_current_response(websocket, client_id)
        
        feedback_analysis = analyze_feedback_intent(user_text)
        
        if feedback_analysis["is_feedback"]:
            await process_feedback_response(websocket, feedback_analysis, client_id)
        else:
            add_to_conversation_history(client_id, "user", user_text)
            await generate_ai_response_completely_safe(websocket, user_text, client_id)
            
    except Exception as e:
        logger.error(f"âš ï¸ ì‘ë‹µ ì¤‘ë‹¨ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

async def handle_realtime_feedback(websocket: WebSocket, message: dict, client_id: str):
    """ì‹¤ì‹œê°„ í”¼ë“œë°± ì²˜ë¦¬"""
    try:
        action = message.get("action")
        original_input = message.get("original_input", "")
        
        logger.info(f"ğŸ’¬ ì‹¤ì‹œê°„ í”¼ë“œë°±: {action} for '{original_input[:20]}...'")
        
        await interrupt_current_response(websocket, client_id)
        
        if action == "make_shorter":
            await generate_shorter_response(websocket, original_input, client_id)
        elif action == "make_detailed":
            await generate_detailed_response(websocket, original_input, client_id)
        else:
            await websocket.send_json({
                "type": "error",
                "message": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í”¼ë“œë°± ì•¡ì…˜: {action}"
            })
            
    except Exception as e:
        logger.error(f"âš ï¸ ì‹¤ì‹œê°„ í”¼ë“œë°± ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

async def interrupt_current_response(websocket: WebSocket, client_id: str):
    """í˜„ì¬ ì‘ë‹µ ì¦‰ì‹œ ì¤‘ë‹¨"""
    if client_id in response_in_progress:
        response_in_progress.discard(client_id)
        
        await websocket.send_json({
            "type": "response_interrupted",
            "timestamp": datetime.now().isoformat()
        })
        
        logger.info(f"ğŸ›‘ ì‘ë‹µ ì¤‘ë‹¨ ì™„ë£Œ: {client_id}")

def analyze_feedback_intent(user_text: str) -> dict:
    """í”¼ë“œë°± ì˜ë„ ë¶„ì„"""
    user_text_lower = user_text.lower()
    
    feedback_patterns = {
        "shorter": ["ì§§ê²Œ", "ê°„ë‹¨íˆ", "ìš”ì•½", "ì¤„ì—¬", "ê·¸ë§Œ"],
        "longer": ["ìì„¸íˆ", "ë”", "êµ¬ì²´ì ìœ¼ë¡œ", "ì˜ˆì‹œ", "ì„¤ëª…"],
        "stop": ["ì¤‘ë‹¨", "ë©ˆì¶°", "ê·¸ë§Œ", "ìŠ¤í†±"],
        "clarify": ["ì´í•´ ì•ˆ", "ëª¨ë¥´ê² ", "ì„¤ëª…í•´", "ë­” ëœ»"]
    }
    
    for action, patterns in feedback_patterns.items():
        if any(pattern in user_text_lower for pattern in patterns):
            return {
                "is_feedback": True,
                "action": action,
                "confidence": 0.9,
                "original_text": user_text
            }
    
    return {
        "is_feedback": False,
        "action": "new_question",
        "confidence": 0.1,
        "original_text": user_text
    }

async def generate_shorter_response(websocket: WebSocket, original_input: str, client_id: str):
    """ì§§ì€ ìš”ì•½ ì‘ë‹µ ìƒì„±"""
    try:
        response_in_progress.add(client_id)
        
        await websocket.send_json({
            "type": "response_start",
            "strategy": "summary",
            "message": "ë” ê°„ë‹¨íˆ ì„¤ëª…í•´ë“œë¦´ê²Œìš”!",
            "timestamp": datetime.now().isoformat()
        })
        
        stream = await openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": f"ê°„ë‹¨íˆ 1-2ë¬¸ì¥ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”."},
                {"role": "user", "content": f"ê°„ë‹¨íˆ: {original_input}"}
            ],
            max_tokens=40,  # ìì—°ìŠ¤ëŸ¬ìš´ ì§§ì€ ë‹µë³€
            temperature=0.5,
            stream=True
        )
        
        await process_simple_streaming(websocket, stream, client_id, "short")
        
    finally:
        response_in_progress.discard(client_id)

async def generate_detailed_response(websocket: WebSocket, original_input: str, client_id: str):
    """ìì„¸í•œ ì‘ë‹µ ìƒì„±"""
    try:
        response_in_progress.add(client_id)
        
        await websocket.send_json({
            "type": "response_start",
            "strategy": "detailed",
            "message": "ë” ìì„¸íˆ ì„¤ëª…í•´ë“œë¦´ê²Œìš”!",
            "timestamp": datetime.now().isoformat()
        })
        
        stream = await openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": f"ì˜ˆì‹œì™€ í•¨ê»˜ ìì„¸íˆ ì„¤ëª…í•˜ë˜ ì ì ˆí•œ ê¸¸ì´ë¡œ."},
                {"role": "user", "content": f"ìì„¸íˆ: {original_input}"}
            ],
            max_tokens=150,  # ìì—°ìŠ¤ëŸ¬ìš´ ìì„¸í•œ ë‹µë³€
            temperature=0.7,
            stream=True
        )
        
        await process_simple_streaming(websocket, stream, client_id, "detailed")
        
    finally:
        response_in_progress.discard(client_id)

async def process_simple_streaming(websocket: WebSocket, stream, client_id: str, response_type: str):
    """ê°„ë‹¨í•œ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬"""
    response_text = ""
    word_buffer = ""
    
    async for chunk in stream:
        if client_id not in response_in_progress:
            break
            
        if chunk.choices[0].delta.content:
            content = chunk.choices[0].delta.content
            word_buffer += content
            response_text += content
            
            if any(char in content for char in [' ', '\n', '\t']) or chunk.choices[0].finish_reason:
                if word_buffer.strip():
                    await websocket.send_json({
                        "type": "text_chunk",
                        "content": word_buffer,
                        "response_type": response_type,
                        "timestamp": datetime.now().isoformat()
                    })
                    word_buffer = ""
    
    await websocket.send_json({
        "type": "response_complete",
        "response_type": response_type,
        "timestamp": datetime.now().isoformat()
    })
    
    add_to_conversation_history(client_id, "assistant", response_text)
    
    if response_text.strip():
        await create_completely_safe_tts(websocket, response_text.strip(), client_id)

async def process_feedback_response(websocket: WebSocket, feedback_analysis: dict, client_id: str):
    """í”¼ë“œë°± ê¸°ë°˜ ì‘ë‹µ ì²˜ë¦¬"""
    action = feedback_analysis["action"]
    
    if action == "shorter":
        await websocket.send_json({
            "type": "feedback_acknowledged",
            "message": "ë” ê°„ë‹¨íˆ ì„¤ëª…í•´ë“œë¦´ê²Œìš”!",
            "action": "shorter"
        })
    elif action == "longer":
        await websocket.send_json({
            "type": "feedback_acknowledged", 
            "message": "ë” ìì„¸íˆ ì„¤ëª…í•´ë“œë¦´ê²Œìš”!",
            "action": "longer"
        })
    elif action == "stop":
        await websocket.send_json({
            "type": "feedback_acknowledged",
            "message": "ì‘ë‹µì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.",
            "action": "stop"
        })

# ì˜ˆì™¸ ì²˜ë¦¬ í•¸ë“¤ëŸ¬
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    logger.error(f"Global exception: {str(exc)}")
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal server error",
            "message": "ì„œë²„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        }
    )

# ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    port = int(os.getenv("PORT", 8080))
    log_level = os.getenv("LOG_LEVEL", "info")
    
    logger.info(f"ğŸš€ AI íŠœí„° ì„œë²„ ì‹œì‘ (v3.3.0 - ìŠ¤ë§ˆíŠ¸í•œ ê· í˜•)")
    logger.info(f"ğŸ“¡ í¬íŠ¸: {port}")
    logger.info(f"ğŸ¤ ìŒì„± ì…ë ¥: {'âœ… í™œì„±í™” (ê°œì„ ëœ STT)' if speech_client else 'âŒ ë¹„í™œì„±í™”'}")
    logger.info(f"ğŸ”Š ìŒì„± ì¶œë ¥: {'âœ… í™œì„±í™” (ì¤‘ì²© ì™„ì „ ë°©ì§€)' if tts_client else 'âŒ ë¹„í™œì„±í™”'}")
    logger.info(f"ğŸ’¬ í…ìŠ¤íŠ¸ ì…ë ¥: âœ… í™œì„±í™”")
    logger.info(f"ğŸ¤– AI ëª¨ë¸: GPT-3.5 Turbo (ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”í˜•)")
    logger.info(f"ğŸ”„ ìƒíƒœ ê´€ë¦¬: âœ… í™œì„±í™”")
    logger.info(f"ğŸ“ ìŠ¤íŠ¸ë¦¬ë°: âœ… ì¤‘ì²© ì™„ì „ ë°©ì§€ + ë‹¨ì¼ TTS")
    logger.info(f"ğŸ›‘ ì¦‰ì‹œ ì¤‘ë‹¨: âœ… í™œì„±í™”")
    logger.info(f"ğŸ’­ ì‹¤ì‹œê°„ í”¼ë“œë°±: âœ… í™œì„±í™”")
    logger.info(f"ğŸ§  ì˜ë„ ë¶„ì„: âœ… ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ì§€í–¥")
    logger.info(f"ğŸ­ ëŒ€í™” ìŠ¤íƒ€ì¼: âœ… ì„±ê²© + ë§¥ë½ + ê°œì¸í™” ìœ ì§€")
    logger.info(f"ğŸ”’ ì¤‘ì²© ë°©ì§€: âœ… ê°•ë ¥í•œ ì§ë ¬í™”ë¡œ 100% í•´ê²°")
    logger.info(f"ğŸ’° ë¹„ìš© íš¨ìœ¨ì„±: âœ… ìŠ¤ë§ˆíŠ¸í•œ ì ˆì•½ (ìì—°ìŠ¤ëŸ¬ì›€ ìœ ì§€)")
    
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=port,
        log_level=log_level,
        access_log=True  # ë””ë²„ê¹…ì„ ìœ„í•´ ìœ ì§€
    )
