#!/usr/bin/env python3
"""
AI íŠœí„° FastAPI ë°±ì—”ë“œ ì• í”Œë¦¬ì¼€ì´ì…˜ (v3.1 - ì¤‘ì²© ë°©ì§€ + ëŒ€í™” ê°œì„ )

ì™„ì „í•œ ì‹¤ì‹œê°„ AI íŠœí„° ì‹œìŠ¤í…œ ë°±ì—”ë“œì…ë‹ˆë‹¤.
- ğŸ”§ ì˜¤ë””ì˜¤ ì¤‘ì²© ì™„ì „ í•´ê²°
- ğŸ­ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”í˜• íŠœí„°
- ğŸ§  ì •êµí•œ ì˜ë„ ë¶„ì„
- ğŸ¤ ê°œì„ ëœ STT ì„¤ì •
"""

import asyncio
import base64
import json
import os
import tempfile
import uuid
import time
from datetime import datetime
from typing import Dict, Any, Optional
import logging

import uvicorn
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from openai import AsyncOpenAI
from google.cloud import texttospeech
from google.cloud import speech
import httpx

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="AI Tutor Realtime System",
    description="ì‹¤ì‹œê°„ AI íŠœí„° ì‹œìŠ¤í…œ - v3.1 ì¤‘ì²© ë°©ì§€ + ëŒ€í™” ê°œì„ ",
    version="3.1.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS ì„¤ì • (ê¸°ì¡´ ìœ ì§€)
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://*.streamlit.app",
        "https://*.streamlit.io", 
        "http://localhost:8501",
        "http://localhost:3000",
        "http://localhost:8080",
        "*"  # ê°œë°œ í™˜ê²½ìš©
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

# í™˜ê²½ë³€ìˆ˜ ì„¤ì • (ê¸°ì¡´ ìœ ì§€)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    logger.error("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ê¸°ì¡´ ìœ ì§€)
openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)

try:
    tts_client = texttospeech.TextToSpeechClient()
    logger.info("Google TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
except Exception as e:
    logger.error(f"Google TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    tts_client = None

try:
    speech_client = speech.SpeechClient()
    logger.info("Google STT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
except Exception as e:
    logger.error(f"Google STT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    speech_client = None

# ì „ì—­ ë³€ìˆ˜ (ê¸°ì¡´ + ìƒˆë¡œ ì¶”ê°€)
active_connections: Dict[str, WebSocket] = {}
tutor_configs: Dict[str, Dict[str, Any]] = {}
response_in_progress: set = set()  # ì‘ë‹µ ìƒíƒœ ê´€ë¦¬
conversation_history: Dict[str, list] = {}  # ëŒ€í™” ê¸°ì–µ ê´€ë¦¬

# ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸ë“¤ (ê¸°ì¡´ ìœ ì§€)
@app.get("/")
async def root():
    """ë©”ì¸ í˜ì´ì§€ - ì‹œìŠ¤í…œ ì •ë³´"""
    return {
        "message": "ğŸ“ AI Tutor Realtime System",
        "version": "3.1.0",
        "status": "running",
        "updates": [
            "ğŸ”§ ì˜¤ë””ì˜¤ ì¤‘ì²© ì™„ì „ í•´ê²°",
            "ğŸ­ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”í˜• íŠœí„°",
            "ğŸ§  ì •êµí•œ ì˜ë„ ë¶„ì„", 
            "ğŸ¤ ê°œì„ ëœ STT ì„¤ì •"
        ],
        "performance": {
            "target_response_time": "< 1ì´ˆ",
            "audio_quality": "ìµœìš°ì„  (ì¤‘ì²© ë°©ì§€)",
            "interrupt_latency": "ì¦‰ì‹œ"
        },
        "endpoints": {
            "websocket": "/ws/tutor/{client_id}",
            "health": "/health",
            "info": "/info",
            "docs": "/docs"
        },
        "timestamp": datetime.now().isoformat()
    }

@app.get("/health")
async def health_check():
    """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    try:
        openai_status = "âœ… ì—°ê²°ë¨" if OPENAI_API_KEY else "âŒ API í‚¤ ì—†ìŒ"
        
        tts_status = "âŒ ë¹„í™œì„±í™”"
        if tts_client:
            try:
                voices = tts_client.list_voices()
                tts_status = f"âœ… í™œì„±í™” ({len(voices.voices)}ê°œ ìŒì„±)"
            except Exception as e:
                tts_status = f"âš ï¸ ì˜¤ë¥˜: {str(e)[:50]}"
        
        stt_status = "âœ… í™œì„±í™”" if speech_client else "âŒ ë¹„í™œì„±í™”"
        
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "active_connections": len(active_connections),
            "active_tutors": len(tutor_configs),
            "active_responses": len(response_in_progress),
            "conversation_sessions": len(conversation_history),
            "services": {
                "openai_gpt": openai_status,
                "google_tts": tts_status,
                "google_stt": stt_status
            },
            "performance": {
                "target_response_time": "1000ms",
                "audio_overlap_prevention": "enabled",
                "interrupt_support": "enabled"
            }
        }
    except Exception as e:
        logger.error(f"Health check ì˜¤ë¥˜: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "status": "unhealthy", 
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
        )

@app.get("/info")
async def system_info():
    """ìƒì„¸ ì‹œìŠ¤í…œ ì •ë³´"""
    return {
        "system": "AI Tutor Realtime System",
        "version": "3.1.0",
        "architecture": "ê³ ì„±ëŠ¥ ì‹¤ì‹œê°„ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤",
        "deployment": "Google Cloud Run",
        "improvements": {
            "audio_overlap_prevention": "ë¬¸ì¥ë³„ ìˆœì°¨ ì²˜ë¦¬ë¡œ ì¤‘ì²© ì™„ì „ ë°©ì§€",
            "conversational_tutor": "ì„±ê²© ìœ ì§€í•˜ë©´ì„œ ëŒ€í™”ì  ì‘ë‹µ",
            "smart_intent_analysis": "ì§ˆë¬¸ ì˜ë„ë³„ ìµœì  ê¸¸ì´ ì¡°ì ˆ",
            "enhanced_stt": "ë‹¤ì¤‘ ì„¤ì • + ì‹ ë¢°ë„ ê¸°ë°˜ ì¬ì‹œë„"
        }
    }

# WebSocket ì—”ë“œí¬ì¸íŠ¸ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
@app.websocket("/ws/tutor/{client_id}")
async def websocket_endpoint(websocket: WebSocket, client_id: str):
    """ë©”ì¸ WebSocket ì—”ë“œí¬ì¸íŠ¸"""
    await websocket.accept()
    active_connections[client_id] = websocket
    
    if client_id not in conversation_history:
        conversation_history[client_id] = []
    
    logger.info(f"âœ… í´ë¼ì´ì–¸íŠ¸ {client_id} ì—°ê²°ë¨")
    
    try:
        await websocket.send_json({
            "type": "connection_established",
            "message": "ğŸ“ AI íŠœí„°ì™€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤! (v3.1 - ì¤‘ì²© ë°©ì§€ + ëŒ€í™” ê°œì„ )",
            "client_id": client_id,
            "timestamp": datetime.now().isoformat(),
            "features": [
                "voice_input", "text_input", "voice_output", 
                "real_time_streaming", "state_management",
                "instant_interrupt", "feedback_loop", "intent_analysis",
                "overlap_prevention", "conversational_style"  # NEW
            ]
        })
        
        while True:
            try:
                data = await asyncio.wait_for(websocket.receive(), timeout=60.0)
                
                if data["type"] == "websocket.disconnect":
                    logger.info(f"âŒ í´ë¼ì´ì–¸íŠ¸ {client_id} ì •ìƒ ì—°ê²° ì¢…ë£Œ")
                    break
                
                if data["type"] == "websocket.receive" and "text" in data:
                    try:
                        message = json.loads(data["text"])
                        await handle_text_message(websocket, message, client_id)
                    except json.JSONDecodeError as e:
                        logger.error(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {data['text'][:100]} | {e}")
                        await websocket.send_json({
                            "type": "error",
                            "message": "ë©”ì‹œì§€ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."
                        })
                
                elif data["type"] == "websocket.receive" and "bytes" in data:
                    audio_data = data["bytes"]
                    await handle_audio_message(websocket, audio_data, client_id)
                    
            except asyncio.TimeoutError:
                try:
                    await websocket.send_json({
                        "type": "ping",
                        "timestamp": datetime.now().isoformat()
                    })
                except:
                    logger.warning(f"í´ë¼ì´ì–¸íŠ¸ {client_id} í•‘ ì‹¤íŒ¨ - ì—°ê²° ì¢…ë£Œ")
                    break
                
    except WebSocketDisconnect:
        logger.info(f"âŒ í´ë¼ì´ì–¸íŠ¸ {client_id} ì—°ê²° ëŠê¹€ (ì •ìƒ)")
    except Exception as e:
        logger.error(f"âš ï¸ WebSocket ì—ëŸ¬ {client_id}: {str(e)}")
    finally:
        if client_id in active_connections:
            del active_connections[client_id]
        if client_id in tutor_configs:
            del tutor_configs[client_id]
        response_in_progress.discard(client_id)
        logger.info(f"ğŸ”„ í´ë¼ì´ì–¸íŠ¸ {client_id} ì •ë¦¬ ì™„ë£Œ")

async def handle_text_message(websocket: WebSocket, message: dict, client_id: str):
    """í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬"""
    try:
        message_type = message.get("type")
        logger.info(f"ğŸ“¨ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ìˆ˜ì‹ : {message_type} from {client_id}")
        
        if message_type == "config_update":
            config = message.get("config", {})
            
            if "voice_settings" not in config:
                config["voice_settings"] = {
                    "auto_play": True,
                    "speed": 1.0,
                    "pitch": 1.0
                }
            
            tutor_configs[client_id] = config
            logger.info(f"ğŸ“‹ íŠœí„° ì„¤ì • ì—…ë°ì´íŠ¸: {config.get('name', 'Unknown')} ({config.get('subject', 'Unknown')})")
            
            await websocket.send_json({
                "type": "config_updated",
                "message": "íŠœí„° ì„¤ì •ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "config_summary": {
                    "name": config.get("name"),
                    "subject": config.get("subject"),
                    "level": config.get("level")
                }
            })
            
        elif message_type == "user_text":
            user_text = message.get("text", "").strip()
            is_interrupt = message.get("interrupt", False)
            
            if not user_text:
                await websocket.send_json({
                    "type": "error",
                    "message": "í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
                })
                return
            
            if len(user_text) > 10000:
                await websocket.send_json({
                    "type": "error",
                    "message": "í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. 10,000ì ì´í•˜ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”."
                })
                return
            
            if is_interrupt and client_id in response_in_progress:
                await handle_response_interrupt(websocket, user_text, client_id)
                return
            
            if client_id in response_in_progress:
                await interrupt_current_response(websocket, client_id)
            
            logger.info(f"ğŸ’¬ ì‚¬ìš©ì í…ìŠ¤íŠ¸ ì…ë ¥: '{user_text[:50]}...' from {client_id}")
            
            add_to_conversation_history(client_id, "user", user_text)
            await generate_ai_response_optimized(websocket, user_text, client_id)
            
        elif message_type == "feedback_request":
            await handle_realtime_feedback(websocket, message, client_id)
            
        elif message_type == "interrupt_response":
            await interrupt_current_response(websocket, client_id)
            
        elif message_type == "ping":
            await websocket.send_json({
                "type": "pong",
                "timestamp": datetime.now().isoformat()
            })
            
        else:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì‹œì§€ íƒ€ì…: {message_type}")
            await websocket.send_json({
                "type": "error",
                "message": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë©”ì‹œì§€ íƒ€ì…: {message_type}"
            })
            
    except Exception as e:
        logger.error(f"âš ï¸ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜ {client_id}: {str(e)}")
        await websocket.send_json({
            "type": "error",
            "message": f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        })

async def handle_audio_message(websocket: WebSocket, audio_data: bytes, client_id: str):
    """ì˜¤ë””ì˜¤ ë©”ì‹œì§€ ì²˜ë¦¬ (ê°œì„ ëœ STT)"""
    try:
        if client_id in response_in_progress:
            await interrupt_current_response(websocket, client_id)
        
        logger.info(f"ğŸ¤ ì˜¤ë””ì˜¤ ìˆ˜ì‹ : {len(audio_data)} bytes from {client_id}")
        
        # ì˜¤ë””ì˜¤ í¬ê¸° ê²€ì¦
        if len(audio_data) < 500:  # ë” ê´€ëŒ€í•˜ê²Œ (1000 â†’ 500)
            await websocket.send_json({
                "type": "error", 
                "message": "ë…¹ìŒì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ì¡°ê¸ˆ ë” ê¸¸ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”."
            })
            return
        
        if len(audio_data) > 10 * 1024 * 1024:  # 10MB
            await websocket.send_json({
                "type": "error", 
                "message": "ë…¹ìŒì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ì§§ê²Œ ë‚˜ëˆ„ì–´ì„œ ë§ì”€í•´ì£¼ì„¸ìš”."
            })
            return
        
        # ğŸ”§ ê°œì„ ëœ STT ì²˜ë¦¬
        transcript = await process_speech_to_text_enhanced(audio_data)
        logger.info(f"ğŸ”¤ STT ê²°ê³¼: '{transcript}' from {client_id}")
        
        if not transcript or transcript.strip() == "":
            await websocket.send_json({
                "type": "error", 
                "message": "ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤. ë” ëª…í™•í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”."
            })
            return
        
        await websocket.send_json({
            "type": "stt_result",
            "text": transcript,
            "timestamp": datetime.now().isoformat()
        })
        
        add_to_conversation_history(client_id, "user", transcript)
        await generate_ai_response_optimized(websocket, transcript, client_id)
        
    except Exception as e:
        logger.error(f"âš ï¸ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜ {client_id}: {str(e)}")
        await websocket.send_json({
            "type": "error",
            "message": f"ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        })

async def process_speech_to_text_enhanced(audio_data: bytes) -> str:
    """ğŸ”§ ê°œì„ ëœ Google Speech-to-Text ì²˜ë¦¬"""
    if not speech_client:
        logger.error("STT í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return ""
    
    try:
        logger.info(f"ğŸ¤ ê°œì„ ëœ STT ì²˜ë¦¬ ì‹œì‘: {len(audio_data)} bytes")
        
        # ğŸ”§ ë” ê´€ëŒ€í•˜ê³  íš¨ê³¼ì ì¸ STT ì„¤ì •
        configs_to_try = [
            # ì„¤ì • 1: WEBM_OPUS 48kHz (ìµœìš°ì„ )
            {
                "encoding": speech.RecognitionConfig.AudioEncoding.WEBM_OPUS,
                "sample_rate_hertz": 48000,
                "description": "WEBM_OPUS 48kHz"
            },
            # ì„¤ì • 2: WEBM_OPUS 16kHz (í˜¸í™˜ì„±)
            {
                "encoding": speech.RecognitionConfig.AudioEncoding.WEBM_OPUS,
                "sample_rate_hertz": 16000,
                "description": "WEBM_OPUS 16kHz"
            },
            # ì„¤ì • 3: ìë™ ê°ì§€ (ê´€ëŒ€í•œ ì„¤ì •)
            {
                "encoding": speech.RecognitionConfig.AudioEncoding.ENCODING_UNSPECIFIED,
                "sample_rate_hertz": 16000,
                "description": "AUTO_DETECT 16kHz"
            },
            # ì„¤ì • 4: OGG_OPUS (ëŒ€ì•ˆ)
            {
                "encoding": speech.RecognitionConfig.AudioEncoding.OGG_OPUS,
                "sample_rate_hertz": 16000,
                "description": "OGG_OPUS 16kHz"
            }
        ]
        
        for i, config_params in enumerate(configs_to_try):
            try:
                logger.info(f"ğŸ”„ STT ì‹œë„ {i+1}/4: {config_params['description']}")
                
                config = speech.RecognitionConfig(
                    encoding=config_params["encoding"],
                    sample_rate_hertz=config_params["sample_rate_hertz"],
                    language_code="ko-KR",
                    enable_automatic_punctuation=True,
                    model="latest_short",
                    enable_word_confidence=True,
                    use_enhanced=True,
                    alternative_language_codes=["en-US"],
                    # ğŸ”§ ë” ê´€ëŒ€í•œ ì„¤ì • ì¶”ê°€
                    profanity_filter=False,  # í•„í„° ë¹„í™œì„±í™”
                    enable_speaker_diarization=False,  # í™”ì ë¶„ë¦¬ ë¹„í™œì„±í™” (ì†ë„ í–¥ìƒ)
                    max_alternatives=1  # ëŒ€ì•ˆ ì¤„ì´ê¸° (ì†ë„ í–¥ìƒ)
                )
                
                audio = speech.RecognitionAudio(content=audio_data)
                
                # STT ìš”ì²­ (ë” ê¸´ íƒ€ì„ì•„ì›ƒ)
                response = await asyncio.wait_for(
                    asyncio.get_event_loop().run_in_executor(
                        None, 
                        lambda: speech_client.recognize(config=config, audio=audio)
                    ),
                    timeout=15.0  # 10ì´ˆ â†’ 15ì´ˆë¡œ ì¦ê°€
                )
                
                if response.results and len(response.results) > 0:
                    transcript = response.results[0].alternatives[0].transcript
                    confidence = response.results[0].alternatives[0].confidence if response.results[0].alternatives[0].confidence else 0.0
                    
                    logger.info(f"âœ… STT ì„±ê³µ: '{transcript}' (ì‹ ë¢°ë„: {confidence:.2f})")
                    
                    # ğŸ”§ ë” ê´€ëŒ€í•œ ì‹ ë¢°ë„ ê¸°ì¤€ (0.3 â†’ 0.1)
                    if confidence < 0.1:
                        logger.warning(f"âš ï¸ ì‹ ë¢°ë„ ë‚®ìŒ ({confidence:.2f}), ë‹¤ìŒ ì„¤ì • ì‹œë„")
                        continue
                    
                    return transcript.strip()
                else:
                    logger.warning(f"âš ï¸ STT ê²°ê³¼ ì—†ìŒ: {config_params['description']}")
                    
            except asyncio.TimeoutError:
                logger.warning(f"â° STT íƒ€ì„ì•„ì›ƒ: {config_params['description']}")
                continue
            except Exception as e:
                logger.error(f"âš ï¸ STT ì„¤ì • {i+1} ì‹¤íŒ¨: {str(e)}")
                continue
        
        logger.error("âŒ ëª¨ë“  STT ì„¤ì • ì‹¤íŒ¨")
        return ""
        
    except Exception as e:
        logger.error(f"âš ï¸ STT ì „ì²´ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return ""

async def generate_ai_response_optimized(websocket: WebSocket, user_input: str, client_id: str):
    """ğŸ”§ ìµœì í™”ëœ AI ì‘ë‹µ ìƒì„± (ì¤‘ì²© ë°©ì§€ + ëŒ€í™”í˜•)"""
    try:
        response_in_progress.add(client_id)
        start_time = time.time()
        
        # ğŸ§  ì •êµí•œ ì˜ë„ ë¶„ì„
        response_strategy = analyze_user_intent_enhanced(user_input)
        
        await websocket.send_json({
            "type": "response_start",
            "strategy": response_strategy,
            "timestamp": datetime.now().isoformat()
        })
        
        conversation_context = get_conversation_context(client_id)
        
        # ğŸ”§ ì¤‘ì²© ë°©ì§€ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
        await process_streaming_no_overlap(
            websocket, user_input, client_id, response_strategy, 
            start_time, conversation_context
        )
        
    finally:
        response_in_progress.discard(client_id)

async def process_streaming_no_overlap(websocket: WebSocket, user_input: str, 
                                     client_id: str, strategy: str, start_time: float,
                                     conversation_context: list):
    """ğŸ”§ ì¤‘ì²© ë°©ì§€ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (í•µì‹¬ ê°œì„ !)"""
    
    tutor_config = tutor_configs.get(client_id, {})
    tutor_prompt = create_conversational_prompt(tutor_config, strategy, conversation_context)
    
    # GPT ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
    stream = await openai_client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": tutor_prompt},
            {"role": "user", "content": user_input}
        ],
        max_tokens=get_smart_max_tokens(strategy, user_input),
        temperature=0.7,
        stream=True
    )
    
    # ğŸ”§ ì¤‘ì²© ë°©ì§€ë¥¼ ìœ„í•œ ìƒíƒœ ê´€ë¦¬
    complete_response = ""
    word_buffer = ""
    first_response_sent = False
    
    # ğŸ”§ ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° (TTSëŠ” ë‚˜ì¤‘ì— í•œë²ˆì—)
    async for chunk in stream:
        if client_id not in response_in_progress:
            logger.info(f"ğŸ›‘ ì‘ë‹µ ì¤‘ë‹¨ë¨: {client_id}")
            break
            
        if chunk.choices[0].delta.content:
            content = chunk.choices[0].delta.content
            word_buffer += content
            complete_response += content
            
            # ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ì „ì†¡ (ë‹¨ì–´ ë‹¨ìœ„)
            if any(char in content for char in [' ', '\n', '\t']) or chunk.choices[0].finish_reason:
                if word_buffer.strip():
                    # ì²« ì‘ë‹µ íƒ€ì´ë° ë¡œê¹…
                    if not first_response_sent:
                        elapsed = time.time() - start_time
                        logger.info(f"âš¡ ì²« ì‘ë‹µ ì‹œê°„: {elapsed:.3f}ì´ˆ")
                        first_response_sent = True
                    
                    await websocket.send_json({
                        "type": "text_chunk",
                        "content": word_buffer,
                        "timestamp": datetime.now().isoformat()
                    })
                    word_buffer = ""
    
    # ğŸ”§ í…ìŠ¤íŠ¸ ì™„ë£Œ í›„ í•œë²ˆì— TTS ì²˜ë¦¬ (ì¤‘ì²© ë°©ì§€!)
    if complete_response.strip():
        await websocket.send_json({
            "type": "response_complete",
            "total_response": complete_response,
            "timestamp": datetime.now().isoformat()
        })
        
        # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        add_to_conversation_history(client_id, "assistant", complete_response)
        
        # ğŸ”§ ì „ì²´ ì‘ë‹µì„ í•œë²ˆì— TTS ì²˜ë¦¬ (ì¤‘ì²© ì—†ìŒ!)
        await create_single_tts(websocket, complete_response.strip())
    else:
        logger.warning(f"âš ï¸ ë¹ˆ ì‘ë‹µ ìƒì„±ë¨: {client_id}")

async def create_single_tts(websocket: WebSocket, full_text: str):
    """ğŸ”§ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í•œë²ˆì— TTS ì²˜ë¦¬ (ì¤‘ì²© ì™„ì „ ë°©ì§€!)"""
    if not tts_client:
        logger.warning("TTS í´ë¼ì´ì–¸íŠ¸ê°€ ë¹„í™œì„±í™”ë˜ì–´ í…ìŠ¤íŠ¸ë§Œ ì „ì†¡í•©ë‹ˆë‹¤.")
        return
    
    try:
        logger.info(f"ğŸ”Š ë‹¨ì¼ TTS ì²˜ë¦¬ ì‹œì‘: '{full_text[:50]}...' ({len(full_text)}ì)")
        
        # ê³ í’ˆì§ˆ TTS ì„¤ì •
        synthesis_input = texttospeech.SynthesisInput(text=full_text)
        
        voice = texttospeech.VoiceSelectionParams(
            language_code="ko-KR",
            name="ko-KR-Standard-A",
            ssml_gender=texttospeech.SsmlVoiceGender.FEMALE
        )
        
        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.MP3,
            speaking_rate=1.0,
            pitch=0.0,
            volume_gain_db=0.0,
            effects_profile_id=["headphone-class-device"]
        )
        
        # TTS ìš”ì²­
        start_tts = time.time()
        response = await asyncio.wait_for(
            asyncio.get_event_loop().run_in_executor(
                None,
                lambda: tts_client.synthesize_speech(
                    input=synthesis_input,
                    voice=voice,
                    audio_config=audio_config
                )
            ),
            timeout=10.0
        )
        tts_time = time.time() - start_tts
        
        # Base64 ì¸ì½”ë”©
        audio_base64 = base64.b64encode(response.audio_content).decode('utf-8')
        
        # ğŸ”§ ë‹¨ì¼ ì˜¤ë””ì˜¤ ì „ì†¡ (ì¤‘ì²© ì—†ìŒ!)
        await websocket.send_json({
            "type": "audio_single",  # ìƒˆë¡œìš´ íƒ€ì…
            "text": full_text,
            "audio": audio_base64,
            "audio_size": len(response.audio_content),
            "tts_time": round(tts_time, 3),
            "timestamp": datetime.now().isoformat()
        })
        
        logger.info(f"âœ… ë‹¨ì¼ TTS ì „ì†¡ ì™„ë£Œ: {len(response.audio_content)} bytes")
        
    except asyncio.TimeoutError:
        logger.error(f"â° TTS íƒ€ì„ì•„ì›ƒ: {full_text[:30]}...")
        await websocket.send_json({
            "type": "text_fallback",
            "text": full_text,
            "error": "TTS íƒ€ì„ì•„ì›ƒ"
        })
    except Exception as e:
        logger.error(f"âš ï¸ TTS ì˜¤ë¥˜: {str(e)}")

def analyze_user_intent_enhanced(user_input: str) -> str:
    """ğŸ§  ì •êµí•œ ì˜ë„ ë¶„ì„ (ì§ˆë¬¸ ìœ í˜•ë³„ ìµœì  ëŒ€ì‘)"""
    user_input_lower = user_input.lower()
    
    # 1. ê°„ë‹¨í•œ ì¸ì‚¬/í™•ì¸ â†’ very_short
    if len(user_input) < 5 or any(word in user_input_lower for word in ["ì‘", "ë„¤", "ì˜ˆ", "ì•„ë‹ˆ", "ë§ì•„", "í‹€ë ¤", "ì•ˆë…•", "ê°ì‚¬"]):
        return "very_short"
    
    # 2. ì •ì˜/ê°œë… ì§ˆë¬¸ â†’ short (ê°„ë‹¨ ëª…í™•)
    if any(word in user_input_lower for word in ["ë­ì˜ˆìš”", "ë¬´ì—‡", "ì •ì˜", "ëœ»", "ì˜ë¯¸"]):
        return "short"
    
    # 3. ìš”ì•½ ìš”ì²­ â†’ short
    if any(word in user_input_lower for word in ["ì§§ê²Œ", "ê°„ë‹¨íˆ", "ìš”ì•½", "í•µì‹¬"]):
        return "short"
    
    # 4. ì˜ˆì‹œ ìš”ì²­ â†’ medium (ì˜ˆì‹œ+ì„¤ëª…)
    if any(word in user_input_lower for word in ["ì˜ˆì‹œ", "ì˜ˆë¥¼ ë“¤ì–´", "ì˜ˆ", "ì–´ë–¤", "ì‚¬ë¡€"]):
        return "medium"
    
    # 5. ë°©ë²•/ê³¼ì • ì§ˆë¬¸ â†’ medium (ë‹¨ê³„ë³„)
    if any(word in user_input_lower for word in ["ì–´ë–»ê²Œ", "ë°©ë²•", "ê³¼ì •", "ì ˆì°¨", "ë‹¨ê³„"]):
        return "medium"
    
    # 6. ì´ìœ /ì›ë¦¬ ì§ˆë¬¸ â†’ medium (ì„¤ëª… í•„ìš”)
    if any(word in user_input_lower for word in ["ì™œ", "ì´ìœ ", "ì›ë¦¬", "ë•Œë¬¸"]):
        return "medium"
    
    # 7. ìì„¸í•œ ì„¤ëª… ìš”ì²­ â†’ long
    if any(word in user_input_lower for word in ["ìì„¸íˆ", "êµ¬ì²´ì ìœ¼ë¡œ", "ìƒì„¸íˆ", "ê¹Šì´"]):
        return "long"
    
    # 8. ë¬¸ì œ/í€´ì¦ˆ â†’ interactive
    if any(word in user_input_lower for word in ["ë¬¸ì œ", "í€´ì¦ˆ", "í…ŒìŠ¤íŠ¸", "í’€ì–´"]):
        return "interactive"
    
    # 9. ê¸°ë³¸ê°’: ëŒ€í™”í˜• short
    return "short"

def get_smart_max_tokens(strategy: str, user_input: str) -> int:
    """ğŸ§  ìŠ¤ë§ˆíŠ¸ í† í° ì¡°ì ˆ (ì§ˆë¬¸ ë³µì¡ë„ ê³ ë ¤)"""
    base_tokens = {
        "very_short": 20,   # "ë„¤, ë§ì•„ìš”!"
        "short": 50,        # "ë¯¸ë¶„ì€ ë³€í™”ìœ¨ì´ì—ìš”. ë” ì•Œê³  ì‹¶ìœ¼ì„¸ìš”?"
        "medium": 100,      # 2-3ë¬¸ì¥ ì„¤ëª… + ì§ˆë¬¸
        "long": 150,        # ìƒì„¸ ì„¤ëª… (ê·¸ë˜ë„ ì ë‹¹íˆ)
        "interactive": 80   # ë¬¸ì œ + íŒíŠ¸
    }
    
    # ì§ˆë¬¸ ê¸¸ì´ì— ë”°ë¥¸ ì¡°ì ˆ
    base = base_tokens.get(strategy, 50)
    if len(user_input) > 100:  # ê¸´ ì§ˆë¬¸ì€ ì¡°ê¸ˆ ë” ìì„¸íˆ
        return min(base + 20, 200)
    return base

def create_conversational_prompt(tutor_config: dict, strategy: str, conversation_context: list) -> str:
    """ğŸ­ ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸ ìƒì„± (ì„±ê²© ìœ ì§€ + ëŒ€í™”ì )"""
    
    # ê¸°ì¡´ ì„±ê²© ì„¤ì • ìœ ì§€
    name = tutor_config.get("name", "AI íŠœí„°")
    subject = tutor_config.get("subject", "ì¼ë°˜")
    level = tutor_config.get("level", "ì¤‘í•™êµ")
    
    personality = tutor_config.get("personality", {})
    friendliness = personality.get("friendliness", 70)
    humor_level = personality.get("humor_level", 30)
    encouragement = personality.get("encouragement", 80)
    explanation_detail = personality.get("explanation_detail", 70)
    
    # ì„±ê²© ê¸°ë°˜ ë§íˆ¬ ì„¤ì • (ê¸°ì¡´ ìœ ì§€)
    personality_style = []
    
    if friendliness >= 80:
        personality_style.append("ë§¤ìš° ì¹œê·¼í•˜ê³  ë‹¤ì •í•œ ë§íˆ¬")
    elif friendliness >= 60:
        personality_style.append("ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ ë§íˆ¬")
    else:
        personality_style.append("ì •ì¤‘í•˜ê³  ì°¨ë¶„í•œ ë§íˆ¬")
    
    if humor_level >= 70:
        personality_style.append("ì ì ˆí•œ ìœ ë¨¸ì™€ ì¬ë¯¸ìˆëŠ” ë¹„ìœ  ì‚¬ìš©")
    elif humor_level >= 40:
        personality_style.append("ê°€ë” ìœ ë¨¸ë¥¼ ì„ì–´ì„œ ëŒ€í™”")
    
    if encouragement >= 80:
        personality_style.append("ì ê·¹ì ì¸ ê²©ë ¤ì™€ ì¹­ì°¬")
    elif encouragement >= 60:
        personality_style.append("ë”°ëœ»í•œ ê²©ë ¤")
    
    # ğŸ­ ëŒ€í™” ì „ëµë³„ ì§€ì¹¨
    conversation_guidelines = {
        "very_short": "1ë¬¸ì¥ìœ¼ë¡œ ê°„ë‹¨í•˜ê²Œ ë‹µí•˜ê³  ëŒ€í™” ì´ì–´ê°€ê¸°",
        "short": "í•µì‹¬ë§Œ 1-2ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•˜ê³  ì§ˆë¬¸ìœ¼ë¡œ ë§ˆë¬´ë¦¬",
        "medium": "2-3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•˜ë˜ ì¤‘ê°„ì¤‘ê°„ í™•ì¸ ì§ˆë¬¸ í¬í•¨",
        "long": "ìƒì„¸íˆ ì„¤ëª…í•˜ë˜ ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ„ì–´ ê° ë‹¨ê³„ë§ˆë‹¤ ì´í•´ í™•ì¸",
        "interactive": "ë¬¸ì œë‚˜ ì˜ˆì‹œ ì œì‹œí•˜ê³  í•¨ê»˜ í’€ì–´ë³´ë„ë¡ ìœ ë„"
    }
    
    # ëŒ€í™” ë§¥ë½ ìš”ì•½
    context_summary = ""
    if conversation_context:
        context_summary = f"\n\n**ìµœê·¼ ëŒ€í™”:**\n"
        for msg in conversation_context[-4:]:
            role = "í•™ìƒ" if msg["role"] == "user" else "ì„ ìƒë‹˜"
            context_summary += f"- {role}: {msg['content'][:80]}...\n"
    
    # ğŸ­ ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""ë‹¹ì‹ ì€ {name}ì´ë¼ëŠ” {subject} ë¶„ì•¼ì˜ ì¹œê·¼í•œ íŠœí„°ì…ë‹ˆë‹¤.

**ì„±ê²© íŠ¹ì„±:**
- ì¹œê·¼í•¨: {friendliness}% ({personality_style[0] if personality_style else 'ìì—°ìŠ¤ëŸ¬ìš´ ë§íˆ¬'})
- ìœ ë¨¸: {humor_level}% {'(ìœ ë¨¸ ì„ì–´ ëŒ€í™”)' if humor_level >= 40 else ''}
- ê²©ë ¤: {encouragement}% {'(ì ê·¹ ê²©ë ¤)' if encouragement >= 60 else ''}

**í•µì‹¬ ëŒ€í™” ì›ì¹™:**
1. {conversation_guidelines.get(strategy, "ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”")}
2. ê¸´ ì„¤ëª…ë³´ë‹¤ëŠ” ëŒ€í™”ë¡œ ì´í•´ë„ í™•ì¸
3. ì§ˆë¬¸ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•˜ì—¬ ìƒí˜¸ì‘ìš© ìœ ë„
4. í•™ìƒ ë°˜ì‘ ê¸°ë‹¤ë¦¬ê¸° (ì¼ë°©ì  ì„¤ëª… ê¸ˆì§€)

**ëŒ€í™” ìŠ¤íƒ€ì¼ ì˜ˆì‹œ:**
âŒ ë‚˜ìœ ì˜ˆ: "ë¯¸ë¶„ì€ í•¨ìˆ˜ì˜ ìˆœê°„ë³€í™”ìœ¨ì„ êµ¬í•˜ëŠ” ìˆ˜í•™ì  ë„êµ¬ë¡œì„œ..."
âœ… ì¢‹ì€ ì˜ˆ: "ë¯¸ë¶„ì€ ë³€í™”ëŸ‰ì„ êµ¬í•˜ëŠ” ê±°ì˜ˆìš”! ìë™ì°¨ ì†ë„ ë³€í™” ê°™ì€ ê±°ì£ . ì˜ˆì‹œ í•˜ë‚˜ ë³¼ê¹Œìš”?"

**ì ˆëŒ€ ê¸ˆì§€:**
- ê¸¸ê³  ì¼ë°©ì ì¸ ê°•ì˜
- ì™„ë²½í•œ ì„¤ëª…í•˜ë ¤ëŠ” ìš•ì‹¬
- ì§ˆë¬¸ ì—†ì´ ëë§ºê¸°
- í•™ìƒ ë°˜ì‘ ë¬´ì‹œí•˜ê³  ê³„ì† ì„¤ëª…

**í•™ìŠµì:** {level} ìˆ˜ì¤€
**í˜„ì¬ ì „ëµ:** {strategy} ({conversation_guidelines.get(strategy)}){context_summary}

í•™ìƒì˜ ì§ˆë¬¸ì— ëŒ€í•´ ìœ„ ì›ì¹™ì„ ì§€ì¼œ ìì—°ìŠ¤ëŸ½ê³  ëŒ€í™”ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”."""
    
    return prompt

# ë‚˜ë¨¸ì§€ í—¬í¼ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ìœ ì§€)
def add_to_conversation_history(client_id: str, role: str, content: str):
    """ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€ (ìµœê·¼ 10í„´ ìœ ì§€)"""
    if client_id not in conversation_history:
        conversation_history[client_id] = []
    
    conversation_history[client_id].append({
        "role": role,
        "content": content,
        "timestamp": datetime.now().isoformat()
    })
    
    if len(conversation_history[client_id]) > 20:
        conversation_history[client_id] = conversation_history[client_id][-20:]

def get_conversation_context(client_id: str) -> list:
    """ëŒ€í™” ë§¥ë½ ë°˜í™˜ (ìµœê·¼ 5í„´)"""
    if client_id not in conversation_history:
        return []
    
    recent_messages = conversation_history[client_id][-10:]
    return [{"role": msg["role"], "content": msg["content"]} for msg in recent_messages]

async def handle_response_interrupt(websocket: WebSocket, user_text: str, client_id: str):
    """ì‘ë‹µ ì¤‘ë‹¨ + ìƒˆë¡œìš´ ì‘ë‹µ ì²˜ë¦¬"""
    try:
        logger.info(f"ğŸ›‘ ì‘ë‹µ ì¤‘ë‹¨ + ìƒˆ ì§ˆë¬¸: '{user_text[:30]}...' from {client_id}")
        
        await interrupt_current_response(websocket, client_id)
        
        feedback_analysis = analyze_feedback_intent(user_text)
        
        if feedback_analysis["is_feedback"]:
            await process_feedback_response(websocket, feedback_analysis, client_id)
        else:
            add_to_conversation_history(client_id, "user", user_text)
            await generate_ai_response_optimized(websocket, user_text, client_id)
            
    except Exception as e:
        logger.error(f"âš ï¸ ì‘ë‹µ ì¤‘ë‹¨ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

async def handle_realtime_feedback(websocket: WebSocket, message: dict, client_id: str):
    """ì‹¤ì‹œê°„ í”¼ë“œë°± ì²˜ë¦¬"""
    try:
        action = message.get("action")
        original_input = message.get("original_input", "")
        
        logger.info(f"ğŸ’¬ ì‹¤ì‹œê°„ í”¼ë“œë°±: {action} for '{original_input[:20]}...'")
        
        await interrupt_current_response(websocket, client_id)
        
        if action == "make_shorter":
            await generate_shorter_response(websocket, original_input, client_id)
        elif action == "make_detailed":
            await generate_detailed_response(websocket, original_input, client_id)
        else:
            await websocket.send_json({
                "type": "error",
                "message": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í”¼ë“œë°± ì•¡ì…˜: {action}"
            })
            
    except Exception as e:
        logger.error(f"âš ï¸ ì‹¤ì‹œê°„ í”¼ë“œë°± ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

async def interrupt_current_response(websocket: WebSocket, client_id: str):
    """í˜„ì¬ ì‘ë‹µ ì¦‰ì‹œ ì¤‘ë‹¨"""
    if client_id in response_in_progress:
        response_in_progress.discard(client_id)
        
        await websocket.send_json({
            "type": "response_interrupted",
            "timestamp": datetime.now().isoformat()
        })
        
        logger.info(f"ğŸ›‘ ì‘ë‹µ ì¤‘ë‹¨ ì™„ë£Œ: {client_id}")

def analyze_feedback_intent(user_text: str) -> dict:
    """ì‚¬ìš©ì ì…ë ¥ì´ í”¼ë“œë°±ì¸ì§€ ìƒˆ ì§ˆë¬¸ì¸ì§€ ë¶„ì„"""
    user_text_lower = user_text.lower()
    
    feedback_patterns = {
        "shorter": ["ì§§ê²Œ", "ê°„ë‹¨íˆ", "ìš”ì•½", "ì¤„ì—¬", "ê·¸ë§Œ"],
        "longer": ["ìì„¸íˆ", "ë”", "êµ¬ì²´ì ìœ¼ë¡œ", "ì˜ˆì‹œ", "ì„¤ëª…"],
        "stop": ["ì¤‘ë‹¨", "ë©ˆì¶°", "ê·¸ë§Œ", "ìŠ¤í†±"],
        "clarify": ["ì´í•´ ì•ˆ", "ëª¨ë¥´ê² ", "ì„¤ëª…í•´", "ë­” ëœ»"]
    }
    
    for action, patterns in feedback_patterns.items():
        if any(pattern in user_text_lower for pattern in patterns):
            return {
                "is_feedback": True,
                "action": action,
                "confidence": 0.9,
                "original_text": user_text
            }
    
    return {
        "is_feedback": False,
        "action": "new_question",
        "confidence": 0.1,
        "original_text": user_text
    }

async def generate_shorter_response(websocket: WebSocket, original_input: str, client_id: str):
    """ì§§ì€ ìš”ì•½ ì‘ë‹µ ìƒì„±"""
    try:
        response_in_progress.add(client_id)
        
        await websocket.send_json({
            "type": "response_start",
            "strategy": "summary",
            "message": "ë” ê°„ë‹¨íˆ ì„¤ëª…í•´ë“œë¦´ê²Œìš”!",
            "timestamp": datetime.now().isoformat()
        })
        
        tutor_config = tutor_configs.get(client_id, {})
        
        stream = await openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": f"ê°„ë‹¨íˆ 1ë¬¸ì¥ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”."},
                {"role": "user", "content": f"ê°„ë‹¨íˆ: {original_input}"}
            ],
            max_tokens=30,
            temperature=0.5,
            stream=True
        )
        
        await process_simple_streaming(websocket, stream, client_id, "short")
        
    finally:
        response_in_progress.discard(client_id)

async def generate_detailed_response(websocket: WebSocket, original_input: str, client_id: str):
    """ìì„¸í•œ ì‘ë‹µ ìƒì„±"""
    try:
        response_in_progress.add(client_id)
        
        await websocket.send_json({
            "type": "response_start",
            "strategy": "detailed",
            "message": "ë” ìì„¸íˆ ì„¤ëª…í•´ë“œë¦´ê²Œìš”!",
            "timestamp": datetime.now().isoformat()
        })
        
        tutor_config = tutor_configs.get(client_id, {})
        
        stream = await openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": f"ì˜ˆì‹œì™€ í•¨ê»˜ ìì„¸íˆ ì„¤ëª…í•˜ë˜ 3-4ë¬¸ì¥ìœ¼ë¡œ."},
                {"role": "user", "content": f"ìì„¸íˆ: {original_input}"}
            ],
            max_tokens=120,
            temperature=0.7,
            stream=True
        )
        
        await process_simple_streaming(websocket, stream, client_id, "detailed")
        
    finally:
        response_in_progress.discard(client_id)

async def process_simple_streaming(websocket: WebSocket, stream, client_id: str, response_type: str):
    """ê°„ë‹¨í•œ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (í”¼ë“œë°± ì „ìš©)"""
    response_text = ""
    word_buffer = ""
    
    async for chunk in stream:
        if client_id not in response_in_progress:
            break
            
        if chunk.choices[0].delta.content:
            content = chunk.choices[0].delta.content
            word_buffer += content
            response_text += content
            
            if any(char in content for char in [' ', '\n', '\t']) or chunk.choices[0].finish_reason:
                if word_buffer.strip():
                    await websocket.send_json({
                        "type": "text_chunk",
                        "content": word_buffer,
                        "response_type": response_type,
                        "timestamp": datetime.now().isoformat()
                    })
                    word_buffer = ""
    
    await websocket.send_json({
        "type": "response_complete",
        "response_type": response_type,
        "timestamp": datetime.now().isoformat()
    })
    
    add_to_conversation_history(client_id, "assistant", response_text)
    
    if response_text.strip():
        await create_single_tts(websocket, response_text.strip())

async def process_feedback_response(websocket: WebSocket, feedback_analysis: dict, client_id: str):
    """í”¼ë“œë°± ê¸°ë°˜ ì‘ë‹µ ì²˜ë¦¬"""
    action = feedback_analysis["action"]
    
    if action == "shorter":
        await websocket.send_json({
            "type": "feedback_acknowledged",
            "message": "ë” ê°„ë‹¨íˆ ì„¤ëª…í•´ë“œë¦´ê²Œìš”!",
            "action": "shorter"
        })
    elif action == "longer":
        await websocket.send_json({
            "type": "feedback_acknowledged", 
            "message": "ë” ìì„¸íˆ ì„¤ëª…í•´ë“œë¦´ê²Œìš”!",
            "action": "longer"
        })
    elif action == "stop":
        await websocket.send_json({
            "type": "feedback_acknowledged",
            "message": "ì‘ë‹µì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.",
            "action": "stop"
        })

# ì˜ˆì™¸ ì²˜ë¦¬ í•¸ë“¤ëŸ¬
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    logger.error(f"Global exception: {str(exc)}")
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal server error",
            "message": "ì„œë²„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        }
    )

# ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    port = int(os.getenv("PORT", 8080))
    log_level = os.getenv("LOG_LEVEL", "info")
    
    logger.info(f"ğŸš€ AI íŠœí„° ì„œë²„ ì‹œì‘ (v3.1.0 - ì¤‘ì²© ë°©ì§€ + ëŒ€í™” ê°œì„ )")
    logger.info(f"ğŸ“¡ í¬íŠ¸: {port}")
    logger.info(f"ğŸ¤ ìŒì„± ì…ë ¥: {'âœ… í™œì„±í™” (ê°œì„ ëœ STT)' if speech_client else 'âŒ ë¹„í™œì„±í™”'}")
    logger.info(f"ğŸ”Š ìŒì„± ì¶œë ¥: {'âœ… í™œì„±í™” (ì¤‘ì²© ë°©ì§€)' if tts_client else 'âŒ ë¹„í™œì„±í™”'}")
    logger.info(f"ğŸ’¬ í…ìŠ¤íŠ¸ ì…ë ¥: âœ… í™œì„±í™”")
    logger.info(f"ğŸ¤– AI ëª¨ë¸: GPT-3.5 Turbo (ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸)")
    logger.info(f"ğŸ”„ ìƒíƒœ ê´€ë¦¬: âœ… í™œì„±í™”")
    logger.info(f"ğŸ“ ìŠ¤íŠ¸ë¦¬ë°: âœ… ì¤‘ì²© ë°©ì§€ + ë‹¨ì¼ TTS")
    logger.info(f"ğŸ›‘ ì¦‰ì‹œ ì¤‘ë‹¨: âœ… í™œì„±í™”")
    logger.info(f"ğŸ’­ ì‹¤ì‹œê°„ í”¼ë“œë°±: âœ… í™œì„±í™”")
    logger.info(f"ğŸ§  ì˜ë„ ë¶„ì„: âœ… ì •êµí™” ì™„ë£Œ")
    logger.info(f"ğŸ­ ëŒ€í™” ìŠ¤íƒ€ì¼: âœ… ì„±ê²© ìœ ì§€ + ëŒ€í™”í˜•")
    
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=port,
        log_level=log_level,
        access_log=True
    )
