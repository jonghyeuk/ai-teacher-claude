#!/usr/bin/env python3
"""
AI íŠœí„° FastAPI ë°±ì—”ë“œ ì• í”Œë¦¬ì¼€ì´ì…˜

ì™„ì „í•œ ì‹¤ì‹œê°„ AI íŠœí„° ì‹œìŠ¤í…œ ë°±ì—”ë“œì…ë‹ˆë‹¤.
- ìŒì„± ì…ë ¥ (STT) + í…ìŠ¤íŠ¸ ì…ë ¥ ì§€ì›
- ì‹¤ì‹œê°„ WebSocket í†µì‹ 
- GPT-3.5 Turbo ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
- Google TTS ìŒì„± ì¶œë ¥
- ìŒì„± ì¤‘ì²© ë¬¸ì œ í•´ê²°
- íŠœí„° ê°œì„±í™” ì‹œìŠ¤í…œ
- 1ì´ˆ ì´ë‚´ ì‘ë‹µ ì‹œì‘
- ì¦‰ì‹œ ìŒì„± ì¤‘ë‹¨ ê¸°ëŠ¥
- ì‹¤ì‹œê°„ í”¼ë“œë°± ë£¨í”„
- ìŠ¤ë§ˆíŠ¸ ì˜ë„ ë¶„ì„
"""

import asyncio
import base64
import json
import os
import tempfile
import uuid
import time
from datetime import datetime
from typing import Dict, Any, Optional
import logging

import uvicorn
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from openai import AsyncOpenAI
from google.cloud import texttospeech
from google.cloud import speech
import httpx

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="AI Tutor Realtime System",
    description="ì‹¤ì‹œê°„ AI íŠœí„° ì‹œìŠ¤í…œ - 1ì´ˆ ì‘ë‹µ + ì¦‰ì‹œ ì¤‘ë‹¨ + ì‹¤ì‹œê°„ í”¼ë“œë°±",
    version="3.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS ì„¤ì • (ê¸°ì¡´ ìœ ì§€)
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://*.streamlit.app",
        "https://*.streamlit.io", 
        "http://localhost:8501",
        "http://localhost:3000",
        "http://localhost:8080",
        "*"  # ê°œë°œ í™˜ê²½ìš©
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

# í™˜ê²½ë³€ìˆ˜ ì„¤ì • (ê¸°ì¡´ ìœ ì§€)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    logger.error("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ê¸°ì¡´ ìœ ì§€)
openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)

try:
    tts_client = texttospeech.TextToSpeechClient()
    logger.info("Google TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
except Exception as e:
    logger.error(f"Google TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    tts_client = None

try:
    speech_client = speech.SpeechClient()
    logger.info("Google STT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
except Exception as e:
    logger.error(f"Google STT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    speech_client = None

# ì „ì—­ ë³€ìˆ˜ (ê¸°ì¡´ + ìƒˆë¡œ ì¶”ê°€)
active_connections: Dict[str, WebSocket] = {}
tutor_configs: Dict[str, Dict[str, Any]] = {}
response_in_progress: set = set()  # ì‘ë‹µ ìƒíƒœ ê´€ë¦¬
conversation_history: Dict[str, list] = {}  # ëŒ€í™” ê¸°ì–µ ê´€ë¦¬ (NEW)

# ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸ë“¤ (ê¸°ì¡´ ìœ ì§€ + ì •ë³´ ì¶”ê°€)
@app.get("/")
async def root():
    """ë©”ì¸ í˜ì´ì§€ - ì‹œìŠ¤í…œ ì •ë³´"""
    return {
        "message": "ğŸ“ AI Tutor Realtime System",
        "version": "3.0.0",
        "status": "running",
        "features": [
            "ìŒì„± ì…ë ¥ (STT)",
            "í…ìŠ¤íŠ¸ ì…ë ¥", 
            "ìŒì„± ì¶œë ¥ (TTS)",
            "ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°",
            "íŠœí„° ê°œì„±í™”",
            "ë‹¤ì¤‘ ì…ë ¥ ë°©ì‹",
            "1ì´ˆ ì´ë‚´ ì‘ë‹µ",        # NEW
            "ì¦‰ì‹œ ìŒì„± ì¤‘ë‹¨",        # NEW
            "ì‹¤ì‹œê°„ í”¼ë“œë°± ë£¨í”„",     # NEW
            "ìŠ¤ë§ˆíŠ¸ ì˜ë„ ë¶„ì„",      # NEW
            "ëŒ€í™” ê¸°ì–µ ê´€ë¦¬"        # NEW
        ],
        "performance": {
            "target_response_time": "< 1ì´ˆ",
            "audio_quality": "ìµœìš°ì„ ",
            "interrupt_latency": "ì¦‰ì‹œ"
        },
        "config": "1ì´ˆ ì‘ë‹µ + ê³ í’ˆì§ˆ ìŒì„± + ì¦‰ì‹œ ì¤‘ë‹¨",
        "endpoints": {
            "websocket": "/ws/tutor/{client_id}",
            "health": "/health",
            "info": "/info",
            "docs": "/docs"
        },
        "timestamp": datetime.now().isoformat()
    }

@app.get("/health")
async def health_check():
    """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ (ê¸°ì¡´ + ìƒˆë¡œìš´ ë©”íŠ¸ë¦­ ì¶”ê°€)"""
    try:
        # OpenAI API ìƒíƒœ í™•ì¸
        openai_status = "âœ… ì—°ê²°ë¨" if OPENAI_API_KEY else "âŒ API í‚¤ ì—†ìŒ"
        
        # Google TTS ìƒíƒœ í™•ì¸
        tts_status = "âŒ ë¹„í™œì„±í™”"
        if tts_client:
            try:
                voices = tts_client.list_voices()
                tts_status = f"âœ… í™œì„±í™” ({len(voices.voices)}ê°œ ìŒì„±)"
            except Exception as e:
                tts_status = f"âš ï¸ ì˜¤ë¥˜: {str(e)[:50]}"
        
        # Google STT ìƒíƒœ í™•ì¸
        stt_status = "âœ… í™œì„±í™”" if speech_client else "âŒ ë¹„í™œì„±í™”"
        
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "active_connections": len(active_connections),
            "active_tutors": len(tutor_configs),
            "active_responses": len(response_in_progress),
            "conversation_sessions": len(conversation_history),  # NEW
            "services": {
                "openai_gpt": openai_status,
                "google_tts": tts_status,
                "google_stt": stt_status
            },
            "performance": {  # NEW
                "target_response_time": "1000ms",
                "audio_buffer_allowed": "200-300ms",
                "interrupt_support": "enabled"
            },
            "system": {
                "python_version": f"{os.sys.version_info.major}.{os.sys.version_info.minor}.{os.sys.version_info.micro}",
                "environment": os.getenv("ENVIRONMENT", "production")
            }
        }
    except Exception as e:
        logger.error(f"Health check ì˜¤ë¥˜: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "status": "unhealthy", 
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
        )

@app.get("/info")
async def system_info():
    """ìƒì„¸ ì‹œìŠ¤í…œ ì •ë³´ (ê¸°ì¡´ + ìƒˆë¡œìš´ ê¸°ëŠ¥ ì •ë³´ ì¶”ê°€)"""
    return {
        "system": "AI Tutor Realtime System",
        "version": "3.0.0",
        "architecture": "ê³ ì„±ëŠ¥ ì‹¤ì‹œê°„ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤",
        "deployment": "Google Cloud Run",
        "input_methods": {
            "voice": {
                "engine": "Google Cloud Speech-to-Text",
                "supported_formats": ["WEBM_OPUS", "OGG_OPUS"],
                "languages": ["ko-KR", "en-US"],
                "features": ["ìë™ êµ¬ë‘ì ", "ì‹ ë¢°ë„ ì ìˆ˜", "ë‹¤ì¤‘ ì„¤ì • ì‹œë„", "ì‹¤ì‹œê°„ ì¤‘ë‹¨ ê°ì§€"]  # NEW
            },
            "text": {
                "method": "WebSocket ì‹¤ì‹œê°„ ì „ì†¡",
                "encoding": "UTF-8",
                "max_length": "10000ì",
                "features": ["ì‹¤ì‹œê°„ í”¼ë“œë°±", "ì˜ë„ ë¶„ì„", "ì¦‰ì‹œ ì¤‘ë‹¨"]  # NEW
            }
        },
        "output_methods": {
            "text": {
                "streaming": True,
                "real_time": True,
                "format": "1ì´ˆ ì´ë‚´ ì‹œì‘ + ìì—°ìŠ¤ëŸ¬ìš´ ë‹¨ì–´ ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°"  # NEW
            },
            "voice": {
                "engine": "Google Cloud Text-to-Speech",
                "voice": "ko-KR-Standard-A",
                "format": "MP3",
                "features": ["ê³ í’ˆì§ˆ ìš°ì„ ", "200-300ms ë²„í¼ë§", "ì¦‰ì‹œ ì¤‘ë‹¨", "ë¬¸ì¥ë³„ ìŠ¤íŠ¸ë¦¬ë°"]  # NEW
            }
        },
        "ai_model": {
            "provider": "OpenAI",
            "model": "GPT-3.5 Turbo",
            "streaming": True,
            "max_tokens": "ì˜ë„ë³„ ì ì‘í˜• (50-400)",  # NEW
            "temperature": 0.7,
            "response_strategies": ["very_short", "short", "medium", "long", "interactive"]  # NEW
        },
        "communication": {
            "protocol": "WebSocket",
            "real_time": True,
            "auto_reconnect": True,
            "timeout": "60ì´ˆ",
            "interrupt_support": True,  # NEW
            "feedback_loop": True       # NEW
        },
        "tutor_system": {
            "personalization": True,
            "personality_traits": [
                "ì¹œê·¼í•¨", "ìœ ë¨¸ ìˆ˜ì¤€", "ê²©ë ¤ ìˆ˜ì¤€", 
                "ì„¤ëª… ìƒì„¸ë„", "ìƒí˜¸ì‘ìš© ë¹ˆë„"
            ],
            "subjects": "ë¬´ì œí•œ",
            "education_levels": ["ì¤‘í•™êµ", "ê³ ë“±í•™êµ", "ëŒ€í•™êµ", "ëŒ€í•™ì›"],
            "conversation_memory": "5-10í„´ + ì„¸ì…˜ ìš”ì•½",  # NEW
            "intent_analysis": "ì‹¤ì‹œê°„ ì˜ë„ íŒŒì•… ë° ì‘ë‹µ ìµœì í™”"  # NEW
        }
    }

@app.get("/stats")
async def get_statistics():
    """ì‹¤ì‹œê°„ í†µê³„ (ê¸°ì¡´ + ìƒˆë¡œìš´ ë©”íŠ¸ë¦­ ì¶”ê°€)"""
    return {
        "connections": {
            "active": len(active_connections),
            "total_connected": len(active_connections)
        },
        "tutors": {
            "active": len(tutor_configs),
            "configurations": list(tutor_configs.keys())
        },
        "responses": {
            "in_progress": len(response_in_progress),
            "active_clients": list(response_in_progress)
        },
        "conversations": {  # NEW
            "active_sessions": len(conversation_history),
            "total_messages": sum(len(msgs) for msgs in conversation_history.values())
        },
        "timestamp": datetime.now().isoformat()
    }

# WebSocket ì—”ë“œí¬ì¸íŠ¸ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
@app.websocket("/ws/tutor/{client_id}")
async def websocket_endpoint(websocket: WebSocket, client_id: str):
    """ë©”ì¸ WebSocket ì—”ë“œí¬ì¸íŠ¸ (ê¸°ì¡´ ë¡œì§ ë³´ì¡´)"""
    await websocket.accept()
    active_connections[client_id] = websocket
    
    # NEW: ëŒ€í™” ì„¸ì…˜ ì´ˆê¸°í™”
    if client_id not in conversation_history:
        conversation_history[client_id] = []
    
    logger.info(f"âœ… í´ë¼ì´ì–¸íŠ¸ {client_id} ì—°ê²°ë¨")
    
    try:
        # ì—°ê²° í™•ì¸ ë©”ì‹œì§€ ì „ì†¡ (ê¸°ì¡´ + ìƒˆ ê¸°ëŠ¥ ì •ë³´ ì¶”ê°€)
        await websocket.send_json({
            "type": "connection_established",
            "message": "ğŸ“ AI íŠœí„°ì™€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤! (1ì´ˆ ì‘ë‹µ + ì¦‰ì‹œ ì¤‘ë‹¨ + ì‹¤ì‹œê°„ í”¼ë“œë°±)",
            "client_id": client_id,
            "timestamp": datetime.now().isoformat(),
            "features": [
                "voice_input", "text_input", "voice_output", 
                "real_time_streaming", "state_management",
                "instant_interrupt", "feedback_loop", "intent_analysis"  # NEW
            ],
            "performance": {  # NEW
                "response_target": "1ì´ˆ ì´ë‚´",
                "audio_quality": "ìµœìš°ì„ ",
                "interrupt_latency": "ì¦‰ì‹œ"
            }
        })
        
        # ë©”ì¸ ë©”ì‹œì§€ ë£¨í”„ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        while True:
            try:
                data = await asyncio.wait_for(websocket.receive(), timeout=60.0)
                
                if data["type"] == "websocket.disconnect":
                    logger.info(f"âŒ í´ë¼ì´ì–¸íŠ¸ {client_id} ì •ìƒ ì—°ê²° ì¢…ë£Œ")
                    break
                
                # JSON ë©”ì‹œì§€ ì²˜ë¦¬
                if data["type"] == "websocket.receive" and "text" in data:
                    try:
                        message = json.loads(data["text"])
                        await handle_text_message(websocket, message, client_id)
                    except json.JSONDecodeError as e:
                        logger.error(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {data['text'][:100]} | {e}")
                        await websocket.send_json({
                            "type": "error",
                            "message": "ë©”ì‹œì§€ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."
                        })
                
                # ë°”ì´ë„ˆë¦¬ ë©”ì‹œì§€ (ì˜¤ë””ì˜¤) ì²˜ë¦¬
                elif data["type"] == "websocket.receive" and "bytes" in data:
                    audio_data = data["bytes"]
                    await handle_audio_message(websocket, audio_data, client_id)
                    
            except asyncio.TimeoutError:
                # ì—°ê²° ìƒíƒœ í™•ì¸ (í•‘) - ê¸°ì¡´ ë¡œì§
                try:
                    await websocket.send_json({
                        "type": "ping",
                        "timestamp": datetime.now().isoformat()
                    })
                except:
                    logger.warning(f"í´ë¼ì´ì–¸íŠ¸ {client_id} í•‘ ì‹¤íŒ¨ - ì—°ê²° ì¢…ë£Œ")
                    break
                
    except WebSocketDisconnect:
        logger.info(f"âŒ í´ë¼ì´ì–¸íŠ¸ {client_id} ì—°ê²° ëŠê¹€ (ì •ìƒ)")
    except Exception as e:
        logger.error(f"âš ï¸ WebSocket ì—ëŸ¬ {client_id}: {str(e)}")
    finally:
        # ì—°ê²° ì •ë¦¬ (ê¸°ì¡´ + ìƒˆë¡œìš´ ì •ë¦¬ í•­ëª© ì¶”ê°€)
        if client_id in active_connections:
            del active_connections[client_id]
        if client_id in tutor_configs:
            del tutor_configs[client_id]
        response_in_progress.discard(client_id)
        # NEW: ëŒ€í™” ê¸°ë¡ì€ ìœ ì§€ (ì¬ì—°ê²° ì‹œ ë³µì› ê°€ëŠ¥)
        logger.info(f"ğŸ”„ í´ë¼ì´ì–¸íŠ¸ {client_id} ì •ë¦¬ ì™„ë£Œ")

async def handle_text_message(websocket: WebSocket, message: dict, client_id: str):
    """í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ë³´ì¡´ + ìƒˆ ê¸°ëŠ¥ ì¶”ê°€)"""
    try:
        message_type = message.get("type")
        logger.info(f"ğŸ“¨ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ìˆ˜ì‹ : {message_type} from {client_id}")
        
        if message_type == "config_update":
            # íŠœí„° ì„¤ì • ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ë¡œì§ ì™„ì „ ë³´ì¡´)
            config = message.get("config", {})
            
            # ê¸°ë³¸ voice_settings ì¶”ê°€
            if "voice_settings" not in config:
                config["voice_settings"] = {
                    "auto_play": True,
                    "speed": 1.0,
                    "pitch": 1.0
                }
            
            tutor_configs[client_id] = config
            logger.info(f"ğŸ“‹ íŠœí„° ì„¤ì • ì—…ë°ì´íŠ¸: {config.get('name', 'Unknown')} ({config.get('subject', 'Unknown')})")
            
            await websocket.send_json({
                "type": "config_updated",
                "message": "íŠœí„° ì„¤ì •ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "config_summary": {
                    "name": config.get("name"),
                    "subject": config.get("subject"),
                    "level": config.get("level")
                }
            })
            
        elif message_type == "user_text":
            user_text = message.get("text", "").strip()
            is_interrupt = message.get("interrupt", False)  # NEW
            
            if not user_text:
                await websocket.send_json({
                    "type": "error",
                    "message": "í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
                })
                return
            
            if len(user_text) > 10000:
                await websocket.send_json({
                    "type": "error",
                    "message": "í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. 10,000ì ì´í•˜ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”."
                })
                return
            
            # NEW: í˜„ì¬ ì‘ë‹µ ì¤‘ì´ê³  ì¤‘ë‹¨ í”Œë˜ê·¸ê°€ ìˆìœ¼ë©´ í”¼ë“œë°±/ì¤‘ë‹¨ ì²˜ë¦¬
            if is_interrupt and client_id in response_in_progress:
                await handle_response_interrupt(websocket, user_text, client_id)
                return
            
            # NEW: ì¼ë°˜ ì‘ë‹µì´ì§€ë§Œ í˜„ì¬ ì§„í–‰ ì¤‘ì´ë©´ ì¤‘ë‹¨ í›„ ìƒˆ ì‘ë‹µ
            if client_id in response_in_progress:
                await interrupt_current_response(websocket, client_id)
            
            logger.info(f"ğŸ’¬ ì‚¬ìš©ì í…ìŠ¤íŠ¸ ì…ë ¥: '{user_text[:50]}...' from {client_id}")
            
            # NEW: ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
            add_to_conversation_history(client_id, "user", user_text)
            
            # NEW: ìµœì í™”ëœ AI ì‘ë‹µ ìƒì„± (1ì´ˆ ëª©í‘œ)
            await generate_ai_response_optimized(websocket, user_text, client_id)
            
        elif message_type == "feedback_request":
            # NEW: ì‹¤ì‹œê°„ í”¼ë“œë°± ì²˜ë¦¬
            await handle_realtime_feedback(websocket, message, client_id)
            
        elif message_type == "interrupt_response":
            # NEW: ì‘ë‹µ ì¤‘ë‹¨ ìš”ì²­
            await interrupt_current_response(websocket, client_id)
            
        elif message_type == "ping":
            # í•‘ ì‘ë‹µ (ê¸°ì¡´ ë¡œì§)
            await websocket.send_json({
                "type": "pong",
                "timestamp": datetime.now().isoformat()
            })
            
        else:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì‹œì§€ íƒ€ì…: {message_type}")
            await websocket.send_json({
                "type": "error",
                "message": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë©”ì‹œì§€ íƒ€ì…: {message_type}"
            })
            
    except Exception as e:
        logger.error(f"âš ï¸ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜ {client_id}: {str(e)}")
        await websocket.send_json({
            "type": "error",
            "message": f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        })

async def handle_audio_message(websocket: WebSocket, audio_data: bytes, client_id: str):
    """ì˜¤ë””ì˜¤ ë©”ì‹œì§€ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ë³´ì¡´ + ì¤‘ë‹¨ ì²´í¬ ì¶”ê°€)"""
    try:
        # NEW: ì‘ë‹µ ì§„í–‰ ì¤‘ ì²´í¬
        if client_id in response_in_progress:
            await interrupt_current_response(websocket, client_id)
        
        logger.info(f"ğŸ¤ ì˜¤ë””ì˜¤ ìˆ˜ì‹ : {len(audio_data)} bytes from {client_id}")
        
        # ì˜¤ë””ì˜¤ í¬ê¸° ê²€ì¦ (ê¸°ì¡´ ë¡œì§)
        if len(audio_data) < 1000:
            await websocket.send_json({
                "type": "error", 
                "message": "ë…¹ìŒì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ì¡°ê¸ˆ ë” ê¸¸ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”."
            })
            return
        
        if len(audio_data) > 10 * 1024 * 1024:  # 10MB
            await websocket.send_json({
                "type": "error", 
                "message": "ë…¹ìŒì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ì§§ê²Œ ë‚˜ëˆ„ì–´ì„œ ë§ì”€í•´ì£¼ì„¸ìš”."
            })
            return
        
        # STT ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ì™„ì „ ë³´ì¡´)
        transcript = await process_speech_to_text(audio_data)
        logger.info(f"ğŸ”¤ STT ê²°ê³¼: '{transcript}' from {client_id}")
        
        if not transcript or transcript.strip() == "":
            await websocket.send_json({
                "type": "error", 
                "message": "ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤. ëª…í™•í•˜ê²Œ ë§ì”€í•´ì£¼ì‹œê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            })
            return
        
        # STT ê²°ê³¼ ì „ì†¡ (ê¸°ì¡´ ë¡œì§)
        await websocket.send_json({
            "type": "stt_result",
            "text": transcript,
            "timestamp": datetime.now().isoformat()
        })
        
        # NEW: ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        add_to_conversation_history(client_id, "user", transcript)
        
        # NEW: ìµœì í™”ëœ AI ì‘ë‹µ ìƒì„±
        await generate_ai_response_optimized(websocket, transcript, client_id)
        
    except Exception as e:
        logger.error(f"âš ï¸ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜ {client_id}: {str(e)}")
        await websocket.send_json({
            "type": "error",
            "message": f"ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        })

async def process_speech_to_text(audio_data: bytes) -> str:
    """Google Speech-to-Text ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ì™„ì „ ë³´ì¡´)"""
    if not speech_client:
        logger.error("STT í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return ""
    
    try:
        logger.info(f"ğŸ¤ STT ì²˜ë¦¬ ì‹œì‘: {len(audio_data)} bytes")
        
        # ë‹¤ì–‘í•œ STT ì„¤ì • (ìš°ì„ ìˆœìœ„ë³„) - ê¸°ì¡´ ë¡œì§
        configs_to_try = [
            {
                "encoding": speech.RecognitionConfig.AudioEncoding.WEBM_OPUS,
                "sample_rate_hertz": 48000,
                "description": "WEBM_OPUS 48kHz"
            },
            {
                "encoding": speech.RecognitionConfig.AudioEncoding.WEBM_OPUS,
                "sample_rate_hertz": 16000,
                "description": "WEBM_OPUS 16kHz"
            },
            {
                "encoding": speech.RecognitionConfig.AudioEncoding.OGG_OPUS,
                "sample_rate_hertz": 48000,
                "description": "OGG_OPUS 48kHz"
            },
            {
                "encoding": speech.RecognitionConfig.AudioEncoding.ENCODING_UNSPECIFIED,
                "sample_rate_hertz": 48000,
                "description": "AUTO_DETECT"
            }
        ]
        
        for i, config_params in enumerate(configs_to_try):
            try:
                logger.info(f"ğŸ”„ STT ì‹œë„ {i+1}/4: {config_params['description']}")
                
                config = speech.RecognitionConfig(
                    encoding=config_params["encoding"],
                    sample_rate_hertz=config_params["sample_rate_hertz"],
                    language_code="ko-KR",
                    enable_automatic_punctuation=True,
                    model="latest_short",
                    enable_word_confidence=True,
                    use_enhanced=True,
                    alternative_language_codes=["en-US"]
                )
                
                audio = speech.RecognitionAudio(content=audio_data)
                
                # STT ìš”ì²­ (íƒ€ì„ì•„ì›ƒ 10ì´ˆ) - ê¸°ì¡´ ë¡œì§
                response = await asyncio.wait_for(
                    asyncio.get_event_loop().run_in_executor(
                        None, 
                        lambda: speech_client.recognize(config=config, audio=audio)
                    ),
                    timeout=10.0
                )
                
                if response.results and len(response.results) > 0:
                    transcript = response.results[0].alternatives[0].transcript
                    confidence = response.results[0].alternatives[0].confidence
                    
                    logger.info(f"âœ… STT ì„±ê³µ: '{transcript}' (ì‹ ë¢°ë„: {confidence:.2f})")
                    
                    # ì‹ ë¢°ë„ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ë‹¤ìŒ ì„¤ì • ì‹œë„
                    if confidence < 0.3:
                        logger.warning(f"âš ï¸ ì‹ ë¢°ë„ ë‚®ìŒ ({confidence:.2f}), ë‹¤ìŒ ì„¤ì • ì‹œë„")
                        continue
                    
                    return transcript.strip()
                else:
                    logger.warning(f"âš ï¸ STT ê²°ê³¼ ì—†ìŒ: {config_params['description']}")
                    
            except asyncio.TimeoutError:
                logger.warning(f"â° STT íƒ€ì„ì•„ì›ƒ: {config_params['description']}")
                continue
            except Exception as e:
                logger.error(f"âš ï¸ STT ì„¤ì • {i+1} ì‹¤íŒ¨: {str(e)}")
                continue
        
        logger.error("âŒ ëª¨ë“  STT ì„¤ì • ì‹¤íŒ¨")
        return ""
        
    except Exception as e:
        logger.error(f"âš ï¸ STT ì „ì²´ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return ""

# NEW: ìµœì í™”ëœ AI ì‘ë‹µ ìƒì„± (1ì´ˆ ëª©í‘œ + ê³ í’ˆì§ˆ ìŒì„±)
async def generate_ai_response_optimized(websocket: WebSocket, user_input: str, client_id: str):
    """AI ì‘ë‹µ ìƒì„± - 1ì´ˆ ì´ë‚´ ì‘ë‹µ + ìŒì„± í’ˆì§ˆ ìµœìš°ì„ """
    try:
        response_in_progress.add(client_id)
        start_time = time.time()
        
        # ì˜ë„ ë¶„ì„ ë° ì‘ë‹µ ì „ëµ ê²°ì • (50ms ì´ë‚´)
        response_strategy = analyze_user_intent_fast(user_input)
        
        # ì‘ë‹µ ì‹œì‘ ì•Œë¦¼ (ì¦‰ì‹œ ì „ì†¡)
        await websocket.send_json({
            "type": "response_start",
            "strategy": response_strategy,
            "timestamp": datetime.now().isoformat()
        })
        
        # ëŒ€í™” ë§¥ë½ êµ¬ì„±
        conversation_context = get_conversation_context(client_id)
        
        # GPT ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
        await process_streaming_with_quality_priority(
            websocket, user_input, client_id, response_strategy, 
            start_time, conversation_context
        )
        
    finally:
        response_in_progress.discard(client_id)

async def process_streaming_with_quality_priority(websocket: WebSocket, user_input: str, 
                                                client_id: str, strategy: str, start_time: float,
                                                conversation_context: list):
    """ìŠ¤íŠ¸ë¦¬ë° + TTS í’ˆì§ˆ ìµœìš°ì„  ì²˜ë¦¬"""
    
    tutor_config = tutor_configs.get(client_id, {})
    tutor_prompt = create_adaptive_prompt(tutor_config, strategy, conversation_context)
    
    # GPT ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
    stream = await openai_client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": tutor_prompt},
            {"role": "user", "content": user_input}
        ],
        max_tokens=get_max_tokens(strategy),
        temperature=0.7,
        stream=True
    )
    
    # ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ê´€ë¦¬
    sentence_buffer = ""
    word_buffer = ""
    sentence_count = 0
    first_response_sent = False
    response_text = ""
    
    # TTS íƒœìŠ¤í¬ ê´€ë¦¬
    tts_tasks = []
    
    async for chunk in stream:
        # ì¤‘ë‹¨ ì²´í¬
        if client_id not in response_in_progress:
            logger.info(f"ğŸ›‘ ì‘ë‹µ ì¤‘ë‹¨ë¨: {client_id}")
            break
            
        if chunk.choices[0].delta.content:
            content = chunk.choices[0].delta.content
            word_buffer += content
            sentence_buffer += content
            response_text += content
            
            # ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ì „ì†¡ (ë‹¨ì–´ ë‹¨ìœ„)
            if any(char in content for char in [' ', '\n', '\t']) or chunk.choices[0].finish_reason:
                if word_buffer.strip():
                    # ì²« ì‘ë‹µ íƒ€ì´ë° ë¡œê¹…
                    if not first_response_sent:
                        elapsed = time.time() - start_time
                        logger.info(f"âš¡ ì²« ì‘ë‹µ ì‹œê°„: {elapsed:.3f}ì´ˆ")
                        first_response_sent = True
                    
                    await websocket.send_json({
                        "type": "text_chunk",
                        "content": word_buffer,
                        "timestamp": datetime.now().isoformat()
                    })
                    word_buffer = ""
            
            # ë¬¸ì¥ ì™„ë£Œ ì‹œ ê³ í’ˆì§ˆ TTS ì²˜ë¦¬ (200-300ms ë²„í¼ë§ í—ˆìš©)
            if any(punct in content for punct in ['.', '!', '?', 'ë‹¤', 'ìš”', 'ì£ ', 'ë‹ˆë‹¤', 'ìŠµë‹ˆë‹¤']):
                if sentence_buffer.strip() and len(sentence_buffer.strip()) > 3:
                    sentence_count += 1
                    
                    # ë¹„ë™ê¸° TTS íƒœìŠ¤í¬ ìƒì„± (ë¸”ë¡œí‚¹í•˜ì§€ ì•ŠìŒ)
                    tts_task = asyncio.create_task(
                        create_quality_tts_with_buffer(websocket, sentence_buffer.strip(), sentence_count)
                    )
                    tts_tasks.append(tts_task)
                    sentence_buffer = ""
    
    # ë‚¨ì€ í…ìŠ¤íŠ¸ ì²˜ë¦¬
    if sentence_buffer.strip():
        sentence_count += 1
        tts_task = asyncio.create_task(
            create_quality_tts_with_buffer(websocket, sentence_buffer.strip(), sentence_count)
        )
        tts_tasks.append(tts_task)
    
    # ì‘ë‹µ ì™„ë£Œ ì•Œë¦¼
    await websocket.send_json({
        "type": "response_complete",
        "total_sentences": sentence_count,
        "timestamp": datetime.now().isoformat()
    })
    
    # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    add_to_conversation_history(client_id, "assistant", response_text)
    
    # ëª¨ë“  TTS íƒœìŠ¤í¬ ì™„ë£Œ ëŒ€ê¸° (ë³‘ë ¬ ì²˜ë¦¬)
    if tts_tasks:
        await asyncio.gather(*tts_tasks, return_exceptions=True)
    
    # ëª¨ë“  ì˜¤ë””ì˜¤ ì™„ë£Œ ì•Œë¦¼
    await websocket.send_json({
        "type": "all_audio_complete",
        "timestamp": datetime.now().isoformat()
    })

async def create_quality_tts_with_buffer(websocket: WebSocket, sentence: str, sequence: int):
    """ê³ í’ˆì§ˆ TTS (200-300ms ë²„í¼ë§ í—ˆìš©) - ê¸°ì¡´ TTS ë¡œì§ ê¸°ë°˜"""
    if not tts_client:
        logger.warning("TTS í´ë¼ì´ì–¸íŠ¸ê°€ ë¹„í™œì„±í™”ë˜ì–´ í…ìŠ¤íŠ¸ë§Œ ì „ì†¡í•©ë‹ˆë‹¤.")
        return
    
    try:
        logger.info(f"ğŸ”Š TTS ì²˜ë¦¬ ì‹œì‘: {sentence[:30]}... ({len(sentence)}ì)")
        
        # í’ˆì§ˆ ìš°ì„  TTS ì„¤ì •
        synthesis_input = texttospeech.SynthesisInput(text=sentence)
        
        voice = texttospeech.VoiceSelectionParams(
            language_code="ko-KR",
            name="ko-KR-Standard-A",  # ê³ í’ˆì§ˆ ìŒì„±
            ssml_gender=texttospeech.SsmlVoiceGender.FEMALE
        )
        
        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.MP3,
            speaking_rate=1.0,  # ìì—°ìŠ¤ëŸ¬ìš´ ì†ë„
            pitch=0.0,
            volume_gain_db=0.0,
            effects_profile_id=["headphone-class-device"]  # ê³ í’ˆì§ˆ í”„ë¡œíŒŒì¼
        )
        
        # TTS ìš”ì²­ (200-300ms í—ˆìš©)
        start_tts = time.time()
        response = await asyncio.wait_for(
            asyncio.get_event_loop().run_in_executor(
                None,
                lambda: tts_client.synthesize_speech(
                    input=synthesis_input,
                    voice=voice,
                    audio_config=audio_config
                )
            ),
            timeout=1.0  # 1ì´ˆ íƒ€ì„ì•„ì›ƒ
        )
        tts_time = time.time() - start_tts
        
        # Base64 ì¸ì½”ë”©
        audio_base64 = base64.b64encode(response.audio_content).decode('utf-8')
        
        # ìˆœì„œê°€ ìˆëŠ” ê³ í’ˆì§ˆ ì˜¤ë””ì˜¤ ì „ì†¡
        await websocket.send_json({
            "type": "audio_stream_quality",
            "sequence": sequence,
            "sentence": sentence,
            "audio": audio_base64,
            "audio_size": len(response.audio_content),
            "tts_time": round(tts_time, 3),
            "timestamp": datetime.now().isoformat()
        })
        
        logger.info(f"âœ… TTS ì „ì†¡ ì™„ë£Œ: {len(response.audio_content)} bytes")
        
    except asyncio.TimeoutError:
        logger.error(f"â° TTS íƒ€ì„ì•„ì›ƒ: {sentence[:20]}...")
        # íƒ€ì„ì•„ì›ƒ ì‹œ í…ìŠ¤íŠ¸ë§Œ ì „ì†¡
        await websocket.send_json({
            "type": "text_fallback",
            "sequence": sequence,
            "sentence": sentence,
            "error": "TTS íƒ€ì„ì•„ì›ƒ"
        })
    except Exception as e:
        logger.error(f"âš ï¸ TTS ì˜¤ë¥˜: {str(e)}")

# NEW: ë¹ ë¥¸ ì˜ë„ ë¶„ì„
def analyze_user_intent_fast(user_input: str) -> str:
    """ë¹ ë¥¸ ì˜ë„ ë¶„ì„ (50ms ì´ë‚´)"""
    user_input_lower = user_input.lower()
    
    # ë‹¨ìˆœí•˜ê³  ë¹ ë¥¸ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„
    if len(user_input) < 5 or any(word in user_input_lower for word in ["ì‘", "ë„¤", "ì˜ˆ", "ì•„ë‹ˆ", "ë§ì•„", "í‹€ë ¤"]):
        return "very_short"
    elif any(word in user_input_lower for word in ["ì§§ê²Œ", "ê°„ë‹¨íˆ", "ìš”ì•½"]):
        return "short"
    elif any(word in user_input_lower for word in ["ìì„¸íˆ", "ì„¤ëª…", "êµ¬ì²´ì ìœ¼ë¡œ", "ì˜ˆì‹œ"]):
        return "long"
    elif any(word in user_input_lower for word in ["ë¬¸ì œ", "í€´ì¦ˆ", "í…ŒìŠ¤íŠ¸"]):
        return "interactive"
    else:
        return "medium"

def get_max_tokens(strategy: str) -> int:
    """ì „ëµë³„ ìµœëŒ€ í† í° (ì‘ë‹µ ì†ë„ ìµœì í™”)"""
    return {
        "very_short": 50,
        "short": 100,
        "medium": 200,
        "long": 300,
        "interactive": 150
    }.get(strategy, 150)

# NEW: ëŒ€í™” ê¸°ì–µ ê´€ë¦¬
def add_to_conversation_history(client_id: str, role: str, content: str):
    """ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€ (ìµœê·¼ 10í„´ ìœ ì§€)"""
    if client_id not in conversation_history:
        conversation_history[client_id] = []
    
    conversation_history[client_id].append({
        "role": role,
        "content": content,
        "timestamp": datetime.now().isoformat()
    })
    
    # ìµœê·¼ 10í„´ (20ê°œ ë©”ì‹œì§€)ë§Œ ìœ ì§€
    if len(conversation_history[client_id]) > 20:
        conversation_history[client_id] = conversation_history[client_id][-20:]

def get_conversation_context(client_id: str) -> list:
    """ëŒ€í™” ë§¥ë½ ë°˜í™˜ (ìµœê·¼ 5í„´)"""
    if client_id not in conversation_history:
        return []
    
    # ìµœê·¼ 10ê°œ ë©”ì‹œì§€ (5í„´) ë°˜í™˜
    recent_messages = conversation_history[client_id][-10:]
    return [{"role": msg["role"], "content": msg["content"]} for msg in recent_messages]

# NEW: ì‹¤ì‹œê°„ í”¼ë“œë°± ì²˜ë¦¬
async def handle_response_interrupt(websocket: WebSocket, user_text: str, client_id: str):
    """ì‘ë‹µ ì¤‘ë‹¨ + ìƒˆë¡œìš´ ì‘ë‹µ ì²˜ë¦¬"""
    try:
        logger.info(f"ğŸ›‘ ì‘ë‹µ ì¤‘ë‹¨ + ìƒˆ ì§ˆë¬¸: '{user_text[:30]}...' from {client_id}")
        
        # ê¸°ì¡´ ì‘ë‹µ ì¤‘ë‹¨
        await interrupt_current_response(websocket, client_id)
        
        # í”¼ë“œë°±ì¸ì§€ ìƒˆ ì§ˆë¬¸ì¸ì§€ íŒë‹¨
        feedback_analysis = analyze_feedback_intent(user_text)
        
        if feedback_analysis["is_feedback"]:
            # í”¼ë“œë°± ì²˜ë¦¬
            await process_feedback_response(websocket, feedback_analysis, client_id)
        else:
            # ìƒˆë¡œìš´ ì§ˆë¬¸ìœ¼ë¡œ ì²˜ë¦¬
            add_to_conversation_history(client_id, "user", user_text)
            await generate_ai_response_optimized(websocket, user_text, client_id)
            
    except Exception as e:
        logger.error(f"âš ï¸ ì‘ë‹µ ì¤‘ë‹¨ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

async def handle_realtime_feedback(websocket: WebSocket, message: dict, client_id: str):
    """ì‹¤ì‹œê°„ í”¼ë“œë°± ì²˜ë¦¬"""
    try:
        action = message.get("action")
        original_input = message.get("original_input", "")
        
        logger.info(f"ğŸ’¬ ì‹¤ì‹œê°„ í”¼ë“œë°±: {action} for '{original_input[:20]}...'")
        
        # í˜„ì¬ ì‘ë‹µ ì¤‘ë‹¨
        await interrupt_current_response(websocket, client_id)
        
        if action == "make_shorter":
            await generate_shorter_response(websocket, original_input, client_id)
        elif action == "make_detailed":
            await generate_detailed_response(websocket, original_input, client_id)
        else:
            await websocket.send_json({
                "type": "error",
                "message": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í”¼ë“œë°± ì•¡ì…˜: {action}"
            })
            
    except Exception as e:
        logger.error(f"âš ï¸ ì‹¤ì‹œê°„ í”¼ë“œë°± ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

async def interrupt_current_response(websocket: WebSocket, client_id: str):
    """í˜„ì¬ ì‘ë‹µ ì¦‰ì‹œ ì¤‘ë‹¨"""
    if client_id in response_in_progress:
        response_in_progress.discard(client_id)
        
        # í´ë¼ì´ì–¸íŠ¸ì— ì¤‘ë‹¨ ì‹ í˜¸ ì „ì†¡
        await websocket.send_json({
            "type": "response_interrupted",
            "timestamp": datetime.now().isoformat()
        })
        
        logger.info(f"ğŸ›‘ ì‘ë‹µ ì¤‘ë‹¨ ì™„ë£Œ: {client_id}")

def analyze_feedback_intent(user_text: str) -> dict:
    """ì‚¬ìš©ì ì…ë ¥ì´ í”¼ë“œë°±ì¸ì§€ ìƒˆ ì§ˆë¬¸ì¸ì§€ ë¶„ì„"""
    user_text_lower = user_text.lower()
    
    feedback_patterns = {
        "shorter": ["ì§§ê²Œ", "ê°„ë‹¨íˆ", "ìš”ì•½", "ì¤„ì—¬", "ê·¸ë§Œ"],
        "longer": ["ìì„¸íˆ", "ë”", "êµ¬ì²´ì ìœ¼ë¡œ", "ì˜ˆì‹œ", "ì„¤ëª…"],
        "stop": ["ì¤‘ë‹¨", "ë©ˆì¶°", "ê·¸ë§Œ", "ìŠ¤í†±"],
        "clarify": ["ì´í•´ ì•ˆ", "ëª¨ë¥´ê² ", "ì„¤ëª…í•´", "ë­” ëœ»"]
    }
    
    for action, patterns in feedback_patterns.items():
        if any(pattern in user_text_lower for pattern in patterns):
            return {
                "is_feedback": True,
                "action": action,
                "confidence": 0.9,
                "original_text": user_text
            }
    
    return {
        "is_feedback": False,
        "action": "new_question",
        "confidence": 0.1,
        "original_text": user_text
    }

async def generate_shorter_response(websocket: WebSocket, original_input: str, client_id: str):
    """ì§§ì€ ìš”ì•½ ì‘ë‹µ ìƒì„±"""
    try:
        response_in_progress.add(client_id)
        
        await websocket.send_json({
            "type": "response_start",
            "strategy": "summary",
            "message": "ë” ê°„ë‹¨íˆ ì„¤ëª…í•´ë“œë¦´ê²Œìš”!",
            "timestamp": datetime.now().isoformat()
        })
        
        tutor_config = tutor_configs.get(client_id, {})
        summary_prompt = create_summary_prompt(tutor_config)
        
        stream = await openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": summary_prompt},
                {"role": "user", "content": f"ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ 1-2ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ë§Œ ê°„ë‹¨íˆ ë‹µë³€í•´ì£¼ì„¸ìš”: {original_input}"}
            ],
            max_tokens=100,
            temperature=0.5,
            stream=True
        )
        
        await process_simple_streaming(websocket, stream, client_id, "short")
        
    finally:
        response_in_progress.discard(client_id)

async def generate_detailed_response(websocket: WebSocket, original_input: str, client_id: str):
    """ìì„¸í•œ ì‘ë‹µ ìƒì„±"""
    try:
        response_in_progress.add(client_id)
        
        await websocket.send_json({
            "type": "response_start",
            "strategy": "detailed",
            "message": "ë” ìì„¸íˆ ì„¤ëª…í•´ë“œë¦´ê²Œìš”!",
            "timestamp": datetime.now().isoformat()
        })
        
        tutor_config = tutor_configs.get(client_id, {})
        detailed_prompt = create_detailed_prompt(tutor_config)
        
        stream = await openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": detailed_prompt},
                {"role": "user", "content": f"ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ì˜ˆì‹œì™€ í•¨ê»˜ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”: {original_input}"}
            ],
            max_tokens=400,
            temperature=0.7,
            stream=True
        )
        
        await process_simple_streaming(websocket, stream, client_id, "detailed")
        
    finally:
        response_in_progress.discard(client_id)

async def process_simple_streaming(websocket: WebSocket, stream, client_id: str, response_type: str):
    """ê°„ë‹¨í•œ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (í”¼ë“œë°± ì „ìš©)"""
    response_text = ""
    word_buffer = ""
    
    async for chunk in stream:
        if client_id not in response_in_progress:
            break
            
        if chunk.choices[0].delta.content:
            content = chunk.choices[0].delta.content
            word_buffer += content
            response_text += content
            
            # ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ì „ì†¡
            if any(char in content for char in [' ', '\n', '\t']) or chunk.choices[0].finish_reason:
                if word_buffer.strip():
                    await websocket.send_json({
                        "type": "text_chunk",
                        "content": word_buffer,
                        "response_type": response_type,
                        "timestamp": datetime.now().isoformat()
                    })
                    word_buffer = ""
    
    # ì‘ë‹µ ì™„ë£Œ
    await websocket.send_json({
        "type": "response_complete",
        "response_type": response_type,
        "timestamp": datetime.now().isoformat()
    })
    
    # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    add_to_conversation_history(client_id, "assistant", response_text)
    
    # ë‹¨ì¼ TTS ì²˜ë¦¬
    if response_text.strip():
        await create_quality_tts_with_buffer(websocket, response_text.strip(), 1)

def create_adaptive_prompt(tutor_config: dict, strategy: str, conversation_context: list) -> str:
    """ì‘ë‹µ ì „ëµê³¼ ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í•œ ì ì‘í˜• í”„ë¡¬í”„íŠ¸"""
    # ê¸°ë³¸ ì •ë³´ (ê¸°ì¡´ ë¡œì§ ë³´ì¡´)
    name = tutor_config.get("name", "AI íŠœí„°")
    subject = tutor_config.get("subject", "ì¼ë°˜")
    level = tutor_config.get("level", "ì¤‘í•™êµ")
    
    # ì„±ê²© ì„¤ì • (ê¸°ì¡´ ë¡œì§ ë³´ì¡´)
    personality = tutor_config.get("personality", {})
    friendliness = personality.get("friendliness", 70)
    humor_level = personality.get("humor_level", 30)
    encouragement = personality.get("encouragement", 80)
    explanation_detail = personality.get("explanation_detail", 70)
    
    # ì„±ê²© ê¸°ë°˜ ì§€ì‹œì‚¬í•­ ìƒì„± (ê¸°ì¡´ ë¡œì§)
    personality_instructions = []
    
    if friendliness >= 80:
        personality_instructions.append("ë§¤ìš° ì¹œê·¼í•˜ê³  ë‹¤ì •í•œ ë§íˆ¬ë¡œ ëŒ€í™”í•˜ì„¸ìš”.")
    elif friendliness >= 60:
        personality_instructions.append("ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ ë§íˆ¬ë¡œ ëŒ€í™”í•˜ì„¸ìš”.")
    else:
        personality_instructions.append("ì •ì¤‘í•˜ê³  ì°¨ë¶„í•œ ë§íˆ¬ë¡œ ëŒ€í™”í•˜ì„¸ìš”.")
    
    if humor_level >= 70:
        personality_instructions.append("ì ì ˆí•œ ìœ ë¨¸ì™€ ì¬ë¯¸ìˆëŠ” ë¹„ìœ ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
    elif humor_level >= 40:
        personality_instructions.append("ê°€ë” ìœ ë¨¸ë¥¼ ì„ì–´ì„œ ëŒ€í™”í•˜ì„¸ìš”.")
    
    if encouragement >= 80:
        personality_instructions.append("í•™ìƒì„ ì ê·¹ì ìœ¼ë¡œ ê²©ë ¤í•˜ê³  ì¹­ì°¬í•˜ì„¸ìš”.")
    elif encouragement >= 60:
        personality_instructions.append("í•™ìƒì„ ê²©ë ¤í•˜ëŠ” ë§ì„ í•´ì£¼ì„¸ìš”.")
    
    if explanation_detail >= 80:
        personality_instructions.append("ë§¤ìš° ìƒì„¸í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.")
    elif explanation_detail >= 60:
        personality_instructions.append("ì ì ˆí•œ ìˆ˜ì¤€ìœ¼ë¡œ ìì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”.")
    else:
        personality_instructions.append("ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.")
    
    # NEW: ì „ëµë³„ ì¶”ê°€ ì§€ì¹¨
    strategy_instructions = {
        "very_short": "1ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ë§Œ ê°„ë‹¨íˆ ë‹µë³€í•˜ì„¸ìš”.",
        "short": "1-2ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.",
        "medium": "2-3ë¬¸ì¥ìœ¼ë¡œ ì ì ˆíˆ ì„¤ëª…í•˜ì„¸ìš”.",
        "long": "3-5ë¬¸ì¥ìœ¼ë¡œ ìì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”.",
        "interactive": "2-3ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•˜ê³  ì¶”ê°€ ì§ˆë¬¸ì„ ìœ ë„í•˜ì„¸ìš”."
    }
    
    # NEW: ëŒ€í™” ë§¥ë½ ìš”ì•½
    context_summary = ""
    if conversation_context:
        context_summary = f"\n\nìµœê·¼ ëŒ€í™” ë§¥ë½:\n"
        for msg in conversation_context[-4:]:  # ìµœê·¼ 2í„´
            role = "í•™ìƒ" if msg["role"] == "user" else "ì„ ìƒë‹˜"
            context_summary += f"- {role}: {msg['content'][:100]}...\n"
    
    # ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ê¸°ì¡´ + ìƒˆë¡œìš´ ìš”ì†Œ)
    prompt = f"""ë‹¹ì‹ ì€ {name}ì´ë¼ëŠ” {subject} ì „ë¬¸ ì„ ìƒë‹˜ì…ë‹ˆë‹¤.
{level} ìˆ˜ì¤€ì˜ í•™ìƒë“¤ì„ ê°€ë¥´ì¹˜ëŠ” ê²½í—˜ì´ í’ë¶€í•œ êµìœ¡ìì…ë‹ˆë‹¤.

ì„±ê²© íŠ¹ì„±:
- ì¹œê·¼í•¨: {friendliness}%
- ìœ ë¨¸ ìˆ˜ì¤€: {humor_level}%
- ê²©ë ¤ ìˆ˜ì¤€: {encouragement}%
- ì„¤ëª… ìƒì„¸ë„: {explanation_detail}%

êµìœ¡ ì§€ì¹¨:
{chr(10).join(f"- {instruction}" for instruction in personality_instructions)}

ì‘ë‹µ ì „ëµ ({strategy}):
- {strategy_instructions.get(strategy, "ì ì ˆí•œ ê¸¸ì´ë¡œ ë‹µë³€í•˜ì„¸ìš”.")}

ê¸°ë³¸ ê·œì¹™:
- í•­ìƒ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
- í•™ìƒì˜ ìˆ˜ì¤€({level})ì— ë§ì¶° ì„¤ëª…í•˜ì„¸ìš”.
- {subject} ë¶„ì•¼ì— ëŒ€í•œ ì „ë¬¸ ì§€ì‹ì„ í™œìš©í•˜ì„¸ìš”.
- ì§ˆë¬¸ì´ {subject}ì™€ ê´€ë ¨ ì—†ë‹¤ë©´ {subject}ì™€ ì—°ê´€ì§€ì–´ ì„¤ëª…í•´ë³´ì„¸ìš”.
- ìì—°ìŠ¤ëŸ½ê³  ëŒ€í™”í•˜ëŠ” ë“¯í•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
- ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì—°ì†ì„± ìˆëŠ” ë‹µë³€ì„ í•˜ì„¸ìš”.{context_summary}

í˜„ì¬ í•™ìƒì˜ ì§ˆë¬¸ì´ë‚˜ ìš”ì²­ì— ëŒ€í•´ ìœ„ íŠ¹ì„±ì„ ëª¨ë‘ ë°˜ì˜í•˜ì—¬ êµìœ¡ì ì´ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ í•´ì£¼ì„¸ìš”."""
    
    return prompt

def create_summary_prompt(tutor_config: dict) -> str:
    """ìš”ì•½ ì „ìš© í”„ë¡¬í”„íŠ¸"""
    name = tutor_config.get("name", "AI íŠœí„°")
    subject = tutor_config.get("subject", "ì¼ë°˜")
    
    return f"""ë‹¹ì‹ ì€ {name}ì´ë¼ëŠ” {subject} ì „ë¬¸ íŠœí„°ì…ë‹ˆë‹¤.

**í•µì‹¬ ì§€ì¹¨:**
- 1-2ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ë§Œ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
- ë¶ˆí•„ìš”í•œ ë¶€ì—°ì„¤ëª…ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”
- ê°€ì¥ ì¤‘ìš”í•œ í¬ì¸íŠ¸ë§Œ ì „ë‹¬í•˜ì„¸ìš”
- "ë” ìì„¸í•œ ì„¤ëª…ì´ í•„ìš”í•˜ë©´ ë§ì”€í•´ì£¼ì„¸ìš”"ë¼ê³  ë§ˆë¬´ë¦¬í•˜ì„¸ìš”

ì§ˆë¬¸ì˜ í•µì‹¬ì„ íŒŒì•…í•˜ê³  ê°€ì¥ ì¤‘ìš”í•œ ë‹µë³€ë§Œ ì œê³µí•´ì£¼ì„¸ìš”."""

def create_detailed_prompt(tutor_config: dict) -> str:
    """ìƒì„¸ ì„¤ëª… í”„ë¡¬í”„íŠ¸"""
    name = tutor_config.get("name", "AI íŠœí„°")
    subject = tutor_config.get("subject", "ì¼ë°˜")
    
    return f"""ë‹¹ì‹ ì€ {name}ì´ë¼ëŠ” {subject} ì „ë¬¸ íŠœí„°ì…ë‹ˆë‹¤.

**ìƒì„¸ ì„¤ëª… ì§€ì¹¨:**
- êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ ìì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”
- ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ„ì–´ ì„¤ëª…í•˜ì„¸ìš”
- í•™ìƒì´ ì´í•´í•˜ê¸° ì‰¬ìš´ ë¹„ìœ ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
- 3-5ë¬¸ì¥ìœ¼ë¡œ ì¶©ë¶„íˆ ì„¤ëª…í•˜ì„¸ìš”
- ì¶”ê°€ ì§ˆë¬¸ì„ ìœ ë„í•˜ëŠ” ë¬¸ì¥ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”

í•™ìƒì˜ ì´í•´ë„ë¥¼ ë†’ì´ëŠ” ê²ƒì„ ëª©í‘œë¡œ ìì„¸í•˜ê³  êµìœ¡ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

async def process_feedback_response(websocket: WebSocket, feedback_analysis: dict, client_id: str):
    """í”¼ë“œë°± ê¸°ë°˜ ì‘ë‹µ ì²˜ë¦¬"""
    action = feedback_analysis["action"]
    
    if action == "shorter":
        await websocket.send_json({
            "type": "feedback_acknowledged",
            "message": "ë” ê°„ë‹¨íˆ ì„¤ëª…í•´ë“œë¦´ê²Œìš”!",
            "action": "shorter"
        })
    elif action == "longer":
        await websocket.send_json({
            "type": "feedback_acknowledged", 
            "message": "ë” ìì„¸íˆ ì„¤ëª…í•´ë“œë¦´ê²Œìš”!",
            "action": "longer"
        })
    elif action == "stop":
        await websocket.send_json({
            "type": "feedback_acknowledged",
            "message": "ì‘ë‹µì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.",
            "action": "stop"
        })

# ì˜ˆì™¸ ì²˜ë¦¬ í•¸ë“¤ëŸ¬ (ê¸°ì¡´ ìœ ì§€)
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    logger.error(f"Global exception: {str(exc)}")
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal server error",
            "message": "ì„œë²„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        }
    )

# ì„œë²„ ì‹¤í–‰ (ê¸°ì¡´ ìœ ì§€ + ìƒˆë¡œìš´ ê¸°ëŠ¥ ì •ë³´ ì¶”ê°€)
if __name__ == "__main__":
    port = int(os.getenv("PORT", 8080))
    log_level = os.getenv("LOG_LEVEL", "info")
    
    logger.info(f"ğŸš€ AI íŠœí„° ì„œë²„ ì‹œì‘ (v3.0.0)")
    logger.info(f"ğŸ“¡ í¬íŠ¸: {port}")
    logger.info(f"ğŸ¤ ìŒì„± ì…ë ¥: {'âœ… í™œì„±í™”' if speech_client else 'âŒ ë¹„í™œì„±í™”'}")
    logger.info(f"ğŸ”Š ìŒì„± ì¶œë ¥: {'âœ… í™œì„±í™” (ê³ í’ˆì§ˆ ìš°ì„ )' if tts_client else 'âŒ ë¹„í™œì„±í™”'}")
    logger.info(f"ğŸ’¬ í…ìŠ¤íŠ¸ ì…ë ¥: âœ… í™œì„±í™”")
    logger.info(f"ğŸ¤– AI ëª¨ë¸: GPT-3.5 Turbo (ìŠ¤íŠ¸ë¦¬ë°)")
    logger.info(f"ğŸ”„ ìƒíƒœ ê´€ë¦¬: âœ… í™œì„±í™”")
    logger.info(f"ğŸ“ ìŠ¤íŠ¸ë¦¬ë°: âœ… 1ì´ˆ ì´ë‚´ ì‹œì‘ + ë‹¨ì–´ ë‹¨ìœ„")
    logger.info(f"ğŸ›‘ ì¦‰ì‹œ ì¤‘ë‹¨: âœ… í™œì„±í™”")
    logger.info(f"ğŸ’­ ì‹¤ì‹œê°„ í”¼ë“œë°±: âœ… í™œì„±í™”")
    logger.info(f"ğŸ§  ì˜ë„ ë¶„ì„: âœ… í™œì„±í™”")
    logger.info(f"ğŸ’¾ ëŒ€í™” ê¸°ì–µ: âœ… 5-10í„´ ê´€ë¦¬")
    
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=port,
        log_level=log_level,
        access_log=True
    )
